% ----------------------------------
% 1-Preambulo.
% ----------------------------------
\documentclass[12pt,a4paper]{article}
\usepackage[spanish]{babel}
\usepackage[T1]{fontenc}
\usepackage{textcomp}
\usepackage{lmodern}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage[procnames]{listings} 	%Para escribir códigos.
% OJO: se agregaron procnames para usarlos en Python (VER).

\usepackage[bottom]{footmisc} 	 	%Para poner las footnote al final de cada página.
\usepackage[hidelinks]{hyperref} 	%Para que el indice pueda ser linkeado.
\usepackage{amssymb}			 	%Para ecuaciones matemáticas.
\usepackage{amsmath}				%Para matrices.
\usepackage{mathtools}
\usepackage{amsfonts} 
\usepackage{verbatim}				%Para usar comentarios.
\parskip 0.1in 						%Distancia parrafos.

%Biliografías:
%\usepackage[style=authoryear]{biblatex}
%\addbibresource{bibliografias.bib}

\usepackage{float} 							%Para que no se muevan las imágenes de lugar.

\usepackage[
  separate-uncertainty = true,
  multi-part-units = repeat
]{siunitx} 									%Para el \SI del +- .

\usepackage[margin=0.984252in]{geometry} 	%Para los márgenes.
\usepackage{subcaption}
\usepackage{appendix} 						%Para los anexos.

% ----------------------------------
% 1.1-Anexos.
% ----------------------------------

%begin anexos
\makeatletter
\def\@seccntformat#1{\@ifundefined{#1@cntformat}  	%"\@seccntformat" es un comando auxiliar.
   {\csname the#1\endcsname\quad}  					%Default.
   {\csname #1@cntformat\endcsname}					%Enable individual control.
}

\let\oldappendix\appendix 							%Guarda la definicion vigente de \appendix
\renewcommand\appendix{%
    \oldappendix
    \newcommand{\section@cntformat}{\appendixname~\thesection\quad}
}
\makeatother
%\renewcommand{\appendixname}{Anexos}
%\renewcommand{\appendixtocname}{Anexos}
%\renewcommand{\appendixpagename}{Anexos}
%end anexos

% ----------------------------------
% 1.2-Para código Python. 
% ----------------------------------
\usepackage{color}
\definecolor{keywords}{RGB}{255,0,90}
\definecolor{comments}{RGB}{0,0,113}
\definecolor{red}{RGB}{160,0,0}
\definecolor{green}{RGB}{0,150,0}
 
\lstset{language=Python, 
        basicstyle=\ttfamily\small, 
        keywordstyle=\color{keywords},
        commentstyle=\color{comments},
        stringstyle=\color{red},
        showstringspaces=false,
        identifierstyle=\color{green},
        procnamekeys={def,class}}

% ----------------------------------
% 1.3-Índice. 
% ----------------------------------

\setcounter{secnumdepth}{3} 		%Para que ponga 1.1.1.1.
\setcounter{tocdepth}{4} 			%Para que añadir las secciones en el Índice.
\usepackage{chngcntr}				%Para que el número de las figuras esten acordes a la sección.
\counterwithin{figure}{section}

\author{
  Calonge, Federico Matias\\
  \text{calongefederico@gmail.com}
}

\title{
  Tesis \\
  \large Automatización de lectura de Curriculum Vitae  \\
    para selección de personal en el Sector IT}
    
%Para modificar los parrafos y para que se pueda poner subsections:
\makeatletter
\renewcommand\paragraph{\@startsection{paragraph}{4}{\z@}
            {-2.5ex\@plus -1ex \@minus -.25ex}
            {1.25ex \@plus .25ex}
            {\normalfont\normalsize\bfseries}}
\makeatother
\setcounter{secnumdepth}{4} 	%How many sectioning levels to assign numbers to.
\setcounter{tocdepth}{4}    	%How many sectioning levels to show in ToC.
% ----------------------------------
% 2-Documento
% ----------------------------------

\begin{document}

\begin{figure}
  \centering
  \includegraphics[width=0.2\textwidth]{images/undav-logo.png} 	%Incluyendo logo de la Undav.
  \label{fig:undav-logo}
\end{figure}
\maketitle       		%Para generar el título definido arriba.

\cleardoublepage    %Nueva página

\begin{center}
    \Large
    \vspace{0.9cm}
    \textbf{Resumen}
    
\end{center}

En la Tesis de Ingeniería en Informática que se presenta, se diseña un \textit{sistema de lectura automática de Curriculum Vitae} accesible vía Web. La finalidad del mismo es ayudar al reclutador laboral a elegir a los mejores candidatos para los puestos laborales de IT que tenga disponible. Esta elección se realiza mediante el uso de algoritmos de \textit{machine learning} y basándose, principalmente, en una medición de similitud entre textos: Curriculum Vitae de los candidatos por un lado, y descripciones de los puestos laborales de IT por el otro.
El sistema esta desarrollado utilizando el lenguaje de programación Python, permitiendo verificar la teoría desarrollada.

\begin{center}
    \Large
    \vspace{0.9cm}
    \textbf{Abstract}
\end{center}

This Computer Engineering Thesis introduces an \textit{automatic Curriculum Vitae reading system} accesible via the Web. The purpose of it is to help the job recruiter to choose the best candidates for the available IT job positions. This choice is made through the use of \textit{machine learning} algorithms and based mainly on a measurement of similarity between texts: Curriculum Vitae of the candidates on the one hand, and IT job descriptions on the other hand.
The system is developed using the Python programming language allowing to verify the developed theory.

\cleardoublepage    %Nueva página

\tableofcontents 	%Para insertar el índice general.

\cleardoublepage    %Nueva página

\section{Introducción.}
El proceso de \textbf{selección de personal} se ha vuelto crucial para el manejo de recursos humanos en el mundo laboral moderno. Con la transformación digital de las empresas y del mercado laboral en general, identificar los perfiles más acordes a las necesidades de la empresa se convirtió en uno de los retos más ambiciosos de Recursos Humanos, en especial cuando hablamos del \textbf{Sector IT}, donde año a año se van generando nuevos puestos de trabajo. 

En estos últimos años se implementaron una gran cantidad de \textbf{herramientas de Software que permiten automatizar y gestionar información de los candidatos de una manera mucho más intuitiva e inteligente}. Gracias a la ayuda de este tipo de sistemas, el reclutador consigue a los candidatos más cualificados para cada puesto.

El tema de este Proyecto de Tesis será desarrollar un \textit{sistema de lectura automática de Curriculum Vitae} accesible vía Web. La finalidad del mismo es ayudar al reclutador laboral a elegir a los mejores candidatos para los puestos laborales de IT que tenga disponible. Esta elección se realiza mediante el uso de algoritmos de Machine Learning y basándose, principalmente, en una medición de similitud entre textos: Curriculum Vitae de los candidatos por un lado, y descripciones de los puestos laborales de IT por el otro.

La medición de similitudes de documentos es uno de los problemas más cruciales del \textbf{Procesamiento del Lenguaje Natural (NLP)}. Encontrar similitudes entre documentos se utiliza en varios dominios, tales como recomendación de películas, libros o artículos similares, identificación de documentos plagiados o documentos legales, etc. 

Para que las máquinas puedan descubrir esta similitud entre documentos, se necesita definir una forma de medir matemáticamente la similitud, la cual debe ser comparable para que la máquina pueda identificar qué documentos son más similares (o menos). Previamente a esto necesitamos representar el texto de los documentos en una forma cuantificable (que suele ser en forma vectorial), de modo que podamos realizar cálculos de similitud sobre él.

Por lo tanto, los pasos necesarios para que las máquinas puedan medir la similitud entre documentos son:
\begin{enumerate}
\item Convertir un documento en un objeto matemático (vector).
\item Definir y emplear una medida de similitud.
\end{enumerate}

Para el primer paso se utilizarán los algoritmos de vectorización \textbf{TF-IDF} y \textbf{Word Embeddings}; y para el segundo paso se emplearán las técnicas \textbf{Cosine Similarity} y \textbf{Word Mover's Distance -WMD-}.

Una vez obtenidas estas mediciones de similitud entre los Curriculum Vitae de los candidatos y las descripciones de los puestos laborales de IT, estos valores se utilizarán para alimentar un algoritmo de clustering K-means que a su vez, con sus datos de salida (4 clusters), alimentará a un modelo de clasificación KNN. Finalmente este modelo KNN nos servirá para lograr, en base a los valores de similitud de nuevos candidatos, clasificar qué tan similares son dichos candidatos con respecto a la descripción de un puesto de IT: similitud escasa, similitud media, similitud alta, similitud muy alta.

\cleardoublepage    %Nueva página

\subsection{Objetivos del Proyecto.}

\subsubsection{Objetivo general.}

El objetivo de este Proyecto de Tesis es lograr un desarrollo, tanto teórico como práctico, de un \textit{sistema de lectura automática de Curriculum Vitae} accesible vía Web. La finalidad del mismo es ayudar al reclutador laboral a elegir a los mejores candidatos para los puestos laborales de IT que tenga disponible. Esta elección se realiza mediante el uso de algoritmos de Machine Learning y basándose, principalmente, en una medición de similitud entre textos:  
\begin{itemize}
\item los Curriculum Vitae de los candidatos por un lado, 
\item y descripciones de los puestos laborales de IT por el otro.
\end{itemize} 

\subsubsection{Objetivos específicos.}
Los objetivos específicos de este Proyecto de Tesis son:
\begin{itemize}
\item Describir el estado del arte actual de los Sistemas de lectura y análisis de Curriculum Vitae en Recruiting. 
\item Implementar un Sistema de lectura automática de Curriculum Vitae basado en la comparación entre textos, para finalmente obtener una visualización de los mejores candidatos para un puesto laboral de IT determinado.  
\item Aprender los conceptos y técnicas principales utilizadas dentro del procesamiento de lenguaje natural (NLP) aplicando técnicas de preprocesamiento y limpieza de textos.
\item Implementar diferentes técnicas para medir similitudes entre los textos (Cosine Similarity y  Word Mover's Distance -WMD-) y diferentes algoritmos de vectorización (TF-IDF y Word Embeddings), analizando su funcionamiento tanto teórica como matemáticamente, ventajas y desventajas.
\item Conocer, implementar e integrar el algoritmo de clustering K-means junto al algoritmo de clasificación KNN para obtener un modelo de clasificación de candidatos en base a las medidas de similitud entre los textos.
\item Evaluar los Frameworks disponibles para tener una UI accesible vía web e integrar el mismo al Sistema.
\item Almacenar datos de candidatos, reclutadores y puestos laborales en una base de datos; contando con un sistema de login y registración para los mismos.
\end{itemize} 

\cleardoublepage    %Nueva página

\subsection{Alcance del Proyecto.}
El alcance de esta Tesis de Grado de Ingeniería incluye el desarrollo de conceptos de análisis de datos y machine learning, procesamiento de lenguaje natural, técnicas de preprocesamiento y limpieza de los datos, algoritmos de vectorización y técnicas para medir la similitud entre textos, algoritmos de clasificación y clustering, integración con frameworks, visualización de datos, y gestión de Base de Datos, de acuerdo a lo enunciado en los objetivos específicos.

\subsection{Organización.}
Este Proyecto de Tesis fue organizado para trabajarlo en tres secciones:

\begin{enumerate}
\item Análisis e investigación inicial. 

Esta sección abarca principalmente la parte teórica del trabajo, haciendo hincapié en el análisis e investigación de:
\begin{itemize}
	\item El estado del arte (actual y pasado) de los sistemas de lectura y análisis de Curriculum Vitae.
	\item Técnicas usadas para el procesamiento del lenguaje natural (NLP).
	\item Técnicas para medir similitudes entre textos: Cosine Similarity y WMD.
	\item Algoritmos de Vectorización: TF-IDF y Word Embeddings.
	\item Algoritmos de Machine Learning para tareas de clasificación (KNN) y clustering (K-means).
\end{itemize} 

Esta primera sección abarca los capítulos \textit{\nameref{2.ReclutamientolaboralenIT}}, \textit{\nameref{3.AlgoritmosdeMachineLearning}} y \textit{\nameref{4.NaturalLanguageProcessing}} de este Informe de Tesis. \\

\item Investigación e implementación de distintas técnicas y algoritmos para la obtención del modelo de clasificación KNN. 

Esta sección hace referencia a la aplicación práctica dentro del marco teórico desarrollado en la primera sección, mediante la realización de una serie de análisis en documentos de Jupyter Notebook \footnote{Aplicación cliente-servidor que permite crear documentos web en formato JSON que siguen un esquema versionado y una lista ordenada de celdas de entrada y de salida. Estas celdas albergan, entre otras cosas, código, texto (en formato Markdown), fórmulas y ecuaciones matemáticas. Estos documentos que se generan funcionan en cualquier navegador estándar.} utilizando Python \footnote{Lenguaje de programación interpretado y multiplataforma de código abierto, popularizado en los últimos años por su facilidad para trabajar con inteligencia artificial, big data, machine learning y data science, entre muchos otros campos en auge.}, para la obtención final de nuestro modelo de clasificación KNN capaz de clasificar, en base a los valores de similitud de nuevos candidatos, qué tan similares son dichos candidatos con respecto a la descripción de un puesto de IT: similitud escasa, similitud media, similitud alta, similitud muy alta. 

Los items que abarca esta sección son:

\begin{itemize}
	\item Obtención de sets de datos: curriculums vitaes y descripciones laborales. 
	\item Preprocesamiento de los textos.
	\item Comparación entre textos y obtención de similitudes entre los mismos mediante el uso de las técnicas para medir distancias y obtener dichas similitudes (WMD y Cosine Similarity) y los algoritmos de vectorización (TF-IDF y Word Embeddings).
	\item Obtención del modelo de clasificación KNN utilizando como datos de entrada los clusters devueltos por el algoritmo K-means obtenidos en base a las mediciones de similitud previamente realizadas.
	\item Análisis y primeras visualizaciones de los resultados.
\end{itemize} 
 
Esta sección abarca el capítulo \textit{\nameref{5.Implementacion}} (desde \textit{\nameref{5.1.Obtenciondelmodelopredictivo}} hasta \textit{\nameref{5.4.Predicciondenuevasmuestrasyresultadosobtenidos}}) de este Informe de Tesis. \\

\item Investigación e integración al sistema web.

Esta última sección hace referencia a la reutilización de las funciones que contenian la lógica de los distintos algoritmos utilizados junto con el modelo de clasificación KNN obtenidos previamente en la sección 2, para integrar todo esto en el sistema Web que, a su vez, esta integrado a una base de datos relacional. De esta manera, el sistema cuenta con una interfaz gráfica permitiendo interactuar entre candidatos y reclutadores y, principalmente, permitiendo que el reclutador sea capaz de obtener un listado con todos los candidatos que aplicaron a un puesto determinado, ordenados de mayor a menor en cuanto a su \textit{similitud} con dicho puesto. Esta \textit{similitud} representa el resultado obtenido de la clasificación por nuestro modelo KNN. 

Los items principales de esta sección son:
\begin{itemize}
	\item Definición de los usuarios que accederán al sistema.
	\item Definición de los datos que se almacenarán.
	\item Integración de frameworks y bases de datos.  
	\item Modelado, filtrado y visualización de los datos.
	\item Reutilización e integración al sistema de los algoritmos y del modelo KNN utilizados en la fase previa.	
	\item Evaluación del funcionamiento de todo el Sistema integrado.
\end{itemize} 

Esta última sección abarca el capítulo \textit{\nameref{5.Implementacion}} (desde \textit{\nameref{5.5.IntegracionalSistemaWeb}} hasta el final del capítulo) de este Informe de Tesis.
\end{enumerate}

\cleardoublepage    %Nueva página

\section{Reclutamiento laboral en IT.}\label{2.ReclutamientolaboralenIT}

En este capítulo se va a realizar una introducción a la historia del Reclutamiento laboral, especialmente en el sector de IT, sus etapas y problemáticas.
Luego se realizará un análisis del Estado de Arte actual de los Sistemas de lectura y análisis de CV actuales.

\subsection{Introducción.}
\colorbox{red}{FALTA}

El proceso de contratación fue evolucionando a lo largo del tiempo. En el modelo de contratación de primera generación, las empresas anunciaban sus vacantes de puestos laborales en diarios, revistas, radio y televisión. Los candidatos enviaban sus currículums por correo postal y sus currículums se clasificaban manualmente. Una vez preseleccionados los candidatos, el equipo de contratación llamaba a los mismos para realizar rondas de entrevistas. Este fue un procedimiento que llevó mucho tiempo.
Luego de esto pasamos a la segunda generación. En esta época las empresas comenzaron a crecer y también lo hicieron las necesidades de contratación. Las empresas empezaron a subcontratar su proceso de contratación naciendo de esta manera las consultoras o agencias de contratación. Estas consultoras requerían que los solicitantes cargaran sus currículums en sus sitios web en formatos particulares. Luego, las consultoras revisaban los datos de los candidatos y preseleccionaban a los mismos para la empresa. El gran inconveniente de este proceso fue que habían numerosas consultoras y cada una tenía su propia y única forma de selección.
Para superar todos los problemas anteriores, se llegó a una tercera generación, en la que estamos actualmente. En esta generación se crearon y siguen creándose sistemas con algoritmos inteligentes que ayudan a las empresas y consultoras a analizar la información de cualquier curriculum vitae y clasificarla en función de los puestos laborales disponibles. De esta manera, cuando el empleador publica una oferta de trabajo, estos sistemas clasifican a los currículums basándose en distintas métricas (por ejemplo palabras clave) mostrando así los candidatos más relevantes para el empleador.

\subsection{Sistemas de lectura y análisis de CV : Estado del arte.}
\colorbox{red}{FALTA}

Las empresas y agencias de contratación procesan diariamente una gran cantidad de Curriculum Vitae. Esta no es una tarea para humanos: se requiere de un sistema automatizado e inteligente que sea capaz detectar a los mejores candidatos y con ello realizar una clasificación para los distintos puestos laborales disponibles.

Hay varios enfoques para realizar esta tarea:
	-Métodos simples: 
	-Sistemas de recomendación.
    -Extracción de keywords y comparaciones:...
    -
    -Comparaciones simples entre los textos de los curriculums y las descripciones de puestos.
    -Comparación de similitudes entre textos. / Sistemas que utilicen algoritmos de similitud entre documentos:
    
El enfoque número 2 será el utilizado para el sistema desarrollado para este Proyecto de Tesis.
Se decidió utilizar este enfoque...

\cleardoublepage

\subsubsection{Problemáticas.}

\colorbox{red}{FALTA}
Habiendo realizado la comparación con cualquiera de los enfoques previamente descriptos, los currículums son difíciles de analizar. Esto se debe a que varían en los tipos de información, su orden, estilo de escritura, etc.

-Diferentes técnicas para medir similitud de textos. 

\subsubsection{Trabajos relacionados.}

A su vez, hay varios trabajos realizados en este campo. Estos sistemas incluyen:
-
-
-
-

La diferencia de este trabajo con el resto de los trabajos anteriormente mencionados es principalmente que se agrega WMD como una de las medidas de similitud entre los textos. WMD es una .... muy reciente y en el futuro puede llegar a .....
Además, se integró el sistema a una interfaz web, cosa que la mayorpía no realizó.
Por último, cabe destacar que estos trabajos no tienen un fácil acceso a los datasets ni al código que utilizaron para dichos sistemas, por lo que seguir el trabajo de ellos aplicando las mejoras que mencionan en sus trabajos es una tarea casi imposible. En cambio, este sistema será de código abierto:  los datasets y códigos utilizados estarán disponibles en Github y Git LFS.


A su vez, en el enfoque utilizado, pueden haber muchos más sub-enfoques?: (ver https://towardsdatascience.com/the-best-document-similarity-algorithm-in-2020-a-beginners-guide-a01b9ef8cf05).
            -1er enfoque (traditional statistical approach): TF-IDF and Cosine Sim. -> you can easily start your own document similarity on your local laptop. No fancy GPU is necessary. No large memory is                 necessary. With high-quality data, you will still get competitive results.
            -Enfoque Deep Learning: USE y  BERT... y aca tambien entraría el word movers.--> Granted, if you want to do other tasks such as sentiment analysis or classification, deep learning should suit your job.


\cleardoublepage

\section{Algoritmos de Machine Learning.}\label{3.AlgoritmosdeMachineLearning}

Para comenzar el marco teórico de esta tesis, es necesario explicar qué es Machine Learning y cómo se pueden clasificar a los distintos algoritmos según su tipo de aprendizaje. 
En este capítulo se va a explicar el objetivo del aprendizaje supervisado y no supervisado en Machine Learning haciendo énfasis en los algoritmos K-Nearest Neighbor (KNN) y K-means.

\subsection{Introducción.}
\colorbox{red}{FALTA}
Los métodos que utilizaremos en este Proyecto de Tesis serán...

\subsection{K-Nearest Neighbor (KNN).}
\colorbox{red}{FALTA}
K-Nearest Neighbor (o K Vecinos más Próximos en español), blablabal....

\cleardoublepage

\subsection{K-Means.}
\colorbox{red}{FALTA}
K-Means (o K-Medias en español), blablaba...

\cleardoublepage

\subsubsection{Elbow Method.}
\colorbox{red}{FALTA}
Elbow Method (o Método del codo en español), blablaba...

\cleardoublepage

\section{Natural Language Processing.}\label{4.NaturalLanguageProcessing}

\colorbox{red}{FALTA}

\cleardoublepage

\subsection{Introducción.}
\colorbox{red}{FALTA}

\cleardoublepage

\subsection{Preprocesamiento de textos.}
\colorbox{red}{FALTA}

\cleardoublepage

\subsection{Similitud entre textos.}
\colorbox{red}{FALTA}

\cleardoublepage

\subsection{Técnicas para medir Similitud entre textos.}
\colorbox{red}{FALTA}

\subsubsection{Cosine Similarity.}
\colorbox{red}{FALTA}

Cosine Similarity se basa en la medición del coseno del ángulo entre dos vectores proyectados en un espacio multidimensional para lograr medir la similitud de los documentos (un menor ángulo indica una mayor similitud). En este contexto, estos dos vectores representan matrices que contienen el recuento de palabras de dos documentos. Una de sus limitaciones es que  no tiene la habilidad de reconocer si las palabras que compara son semánticamente similares.

\cleardoublepage

\subsubsection{Word Mover's Distance (WMD).}
\colorbox{red}{FALTA}

Anteriormente, mencionamos que una de las limitaciones de Cosine Similarity es que no tiene habilidad de reconocer si las palabras que compara son semánticamente similares. En cambio, Word Mover's Distance (WMD) es un algoritmo más complejo que sí permite reconocer las relaciones semánticas; su limitación son las relaciones sintácticas (VER.........). WMD se basa en word embeddings y permite medir la distancia entre documentos (una menor distancia indica una mayor similitud).

\cleardoublepage

\subsection{Algoritmos de vectorización.}
\colorbox{red}{FALTA}

Previamente a utilizar Cosine Similarity y WDM para (-----completar-----) se debe emplear algún algoritmo de vectorización que permita representar las palabras de nuestros textos a un espacio vectorial. De esta forma Cosine Similarity y WMD podrán interpretarlos de la mejor manera. 
Como algoritmos de vectorización se utilizarán TF-IDF y Word Embeddings.

\subsubsection{TF-IDF.}
\colorbox{red}{FALTA}

El algoritmo TF-IDF asigna valores numéricos a las palabras en función de la frecuencia con que aparecen en los textos para medir la frecuencia de ocurrencia de un término en la colección de documentos, expresando  cuán relevante es una palabra para un documento en una colección. 

\cleardoublepage

\subsubsection{Word Embeddings.}
\colorbox{red}{FALTA}

Los Word Embeddings son necesarios para utilizar WMD.
Los Word Embeddings son una de las variantes más populares para representar textos.  Son vectores previamente entrenados y generados mediante un modelo de red neuronal secuencial; de esta manera son capaces de capturar los contextos de una palabra en el documento llegando a poder contener información semántica y sintáctica. 

\cleardoublepage

\paragraph{¿Cómo entrenar Word Embeddings?}
\colorbox{red}{FALTA}

\cleardoublepage

\section{Implementación.}\label{5.Implementacion}

La implementación de este Sistema se trabajó en dos grandes partes:
\begin{enumerate}
\item Obtención del modelo de clasificación. 

En esta primera parte se obtuvieron y preprocesaron datasets de Curriculum Vitae de distintos candidatos y descripciones de puestos de trabajo de IT publicados por distintas empresas, para luego ser comparados y obtener similitudes entre los textos utilizando las técnicas para medir distancias y obtener dichas similitudes (WMD y Cosine Similarity) y los algoritmos de vectorización (TF-IDF y Word Embeddings).

Una vez obtenidas estas mediciones de similitud entre los Curriculum Vitae de los candidatos y las descripciones de los puestos laborales de IT, estos valores se utilizaron para alimentar un algoritmo de clustering K-means que a su vez, con sus datos de salida (4 clusters), alimentan a un modelo de clasificación KNN. Finalmente, con este modelo KNN logramos, en base a los valores de similitud de nuevos candidatos, clasificar qué tan similares son dichos candidatos con respecto a la descripción de un puesto de IT: similitud escasa, similitud media, similitud alta, similitud muy alta.

Estos análisis se realizaron en documentos de Jupyter Notebook utilizando Python; y sirvieron para evaluar el comportamiento del modelo de clasificación y los distintos algoritmos de medición de similitudes para luego ser utilizados en la siguiente etapa. \\

\item Integración al Sistema Web. 

Etapa posterior a la primera parte. Una vez observado que los resultados fueron los esperables, lo que se hizo fue reutilizar las funciones que contenian la lógica de los distintos algoritmos utilizados junto con el modelo de clasificación KNN obtenidos previamente en la parte 1, para integrar todo esto en el sistema Web. Este sistema web está realizado en Django \footnote{Framework de desarrollo web de código abierto, escrito en Python, que respeta el patrón de diseño conocido como modelo–vista–controlador.}, y cuenta con una base de datos relacional que contiene la información de los candidatos y reclutadores junto con los Curiculum Vitae y puestos que hayan cargado. 

De esta manera, nuestro sistema cuenta con una interfaz gráfica permitiendo interactuar entre candidatos y reclutadores y, principalmente, permitiendo que el reclutador sea capaz de obtener un listado con todos los candidatos que aplicaron a un puesto determinado, ordenados de mayor a menor en cuanto a su \textit{similitud} con dicho puesto. Esta \textit{similitud} representa el resultado obtenido de la clasificación por nuestro modelo KNN.

\end{enumerate}

\cleardoublepage

\subsection{Obtención del modelo de clasificación.}\label{5.1.Obtenciondelmodelopredictivo}

\subsubsection{Introducción.}
Como inicio definamos qué es un modelo. En nuestro caso, un modelo representa ....
Este modelo se construyó en base a ...
La implementación de este Sistema se realizó en Python...

\subsubsection{Esquema.}
Como podemos ver la figura \ref{fig:FlowCoreSystem} representa el procedimiento utilizado para la obtención de nuestro modelo de clasificación. 

\begin{figure}[H]    %[H] es para que se ubique justo debajo del texto anterior. 
  \centering
  \includegraphics[width=1\textwidth]{images/flow-core.png} 	%Incluyendo imagen Flow Core.
  \caption{Pipeline Flow para la obtención del modelo de clasificación KNN}  
  \label{fig:FlowCoreSystem}
\end{figure}

\cleardoublepage

\subsubsection{Obtención de sets de datos.}
En primer lugar debemos definir qué es un set o conjunto de datos.
Un set o conjunto de datos es una tabla de una base de datos o, matemáticamente, una matriz estadística de datos. Cada columna de la tabla representa una variable del set de datos; y cada fila representa a un miembro determinado del mismo.

Para este Proyecto utilizamos dos grandes sets de datos que se obtuvieron mediante la recolección de distintos archivos alojados en la Web, los cuales estan descriptos a continuación.

\paragraph{Curriculum Vitae.}
Los set de datos de Curriculum Vitae de los candidatos se obtuvieron de las siguientes fuentes:

\begin{enumerate}
\item 228 Curriculums en formato docx y posteriormente convertidos a pdf, obtenidos del sitio Kaggle\footnote{https://www.kaggle.com/palaksood97/resume-dataset}. Estos pdfs son candidatos de la India con experiencia en el rubro de IT.
\item 2484 Curriculums en formato CSV, obtenidos del sitio Kagle\footnote{https://www.kaggle.com/snehaanbhawal/resume-dataset}. Este CSV cuenta con CVs obtenidos del sitio web de postulación de trabajos 'livecareer.com'.
\item 962 Curriculumns en formato CSV, obtenidos del sitio Kaggle\footnote{https://www.kaggle.com/gauravduttakiit/resume-dataset}. Este CSV cuenta con CVs repartidos en distintas categorías de IT.
\item 10 Curriculums en formato PDF, los cuales los cuales fueron obtenidos como ejemplos mediante una recolección propia de distintos sitios web. 
\end{enumerate}

\paragraph{Descripciones Puestos Laborales.}

Los set de datos de descripciones de puestos laborales se obtuvieron de las siguientes fuentes:

\begin{enumerate}
\item 22.000 descripciones en formato CSV; obtenido del sitio Kaggle\footnote{https://www.kaggle.com/PromptCloudHQ/us-technology-jobs-on-dicecom}. El CSV cuenta con descripciones de puestos obtenidos del sitio web de USA de postulación de trabajos del rubro de IT 'Dice.com'.
\item 10 descripciones en formato CSV; obtenidas como ejemplos mediante una recolección propia del sitio Indeed\footnote{https://www.indeed.com/q-USA-jobs.html} para puestos de trabajo de IT.
\end{enumerate}

\cleardoublepage

\subsubsection{Preprocesamiento y limpieza de datos.}
Previamente a utilizar las técnicas para medir distancias y obtener similitudes entre textos (WMD y Cosine Similarity) y los algoritmos de aprendizaje (KNN y K-Means) necesitamos que los datos que comparemos e introduzcamos en los algoritmos estén lo más limpios posible; ya que de lo contrario las mismos podrían clasificar o predecir de forma errónea. Este análisis previo sobre los datos debe ser minucioso ya que puede haber valores incoherentes o absurdos.

El procedimiento para la Limpieza de los Curriculum Vitae y las descripciones de los puestos laborales fue el siguiente:

\begin{enumerate}
\item Convertimos todo a minúscula.
\item Eliminamos datos no relevantes para nuestros análisis (mails y páginas web).
\item Eliminamos signos de puntuación y caracterés especiales (incluyendo números).
\item Eliminamos stop words.
\item Eliminamos common words no relevantes para nuestros análisis.
\item Aplicamos Lematización y Tokenización.
\item Eliminamos repetidos.
\item Obtenemos y usamos bi-gramas.
\end{enumerate}

Luego de aplicar preprocesamiento y limpieza de datos nos quedarán los siguientes tamaños de nuestros datasets:
\begin{itemize}
\item 624 CVs de candidatos (en formato pdf y csv).
\item 20593 descripciones de puestos de IT (en formato csv).
\end{itemize}

\cleardoublepage

\subsubsection{Cantidad final del set de datos y su uso en las distintas etapas.}

El total de 624 CVs de candidatos y 20593 descripciones de duestos de IT que mencionamos previamente, serán utilizados para el entrenamiento y obtención de vectores mediante TF-IDF (para el posterior cálculo de Cosine Similarity) y para el entrenamiento de Word2Vec y obtención de los Word Embeddings (para el posterior cálculo de WMD).

Por otro lado, para calcular Cosine Similarity y WMD, para utilizarlos en K-means y para entrenar a nuestro algoritmo KNN, utilizaremos únicamente una porción de nuestros datasets:

1-Para el cálculo de Cosine Similarity y WMD:
\begin{itemize}
\item 301 CVs de candidatos.
\item 201 descripciones de puestos de IT.
\end{itemize}
Nota: No obstante, al realizar los cálculos de distancias compararemos cada CV con cada Job Description, obteniendo un dataframe total de 3131 filas con sus respectivo valores de WMD y Cosine Sim.

2-Para el uso de K-means y entrenamiento con KNN (eliminamos un CV y una descripción de puesto IT que los utilizamos en '3-'):
\begin{itemize}
\item 300 CVs de candidatos.
\item 200 descripciones de puestos de IT.
\end{itemize}        
Nota: como se comentó previamente, nos quedarán 3000 filas / puntos para usar en K-means y entrenar KNN; llegando a representar estos 3000 puntos en un plano de 2 dimensiones.

3-Para la clasificación de nuevas muestras mediante KNN:
\begin{itemize}
\item 1 CV de candidatos.
\item 1 descripción de puesto de IT.
\end{itemize}
Nota: como se comentó previamente, nos quedarán 131 filas para clasificar.

¿Por qué utilizamos solo una porción de nuestros datasets?: Esto es debido a los drawbacks de WMD y KNN.
\begin{itemize}
\item WMD: posee una alta complejidad en el cálculo de la distancia, teniendo un tiempo de ejecución muy elevado. Como ejemplo, al correrlo localmente, el cálculo de WMD para 3131 filas tardó 7 horas; frente a los 3 segundos que tardó el cálculo de Cosine Similarity para la misma cantidad de filas.
\item KNN: KNN es una gran opción para datasets pequeños con pocas variables de entrada; pero tiene problemas cuando la cantidad de entradas es muy grande. Cada variable de entrada puede considerarse una dimensión de un espacio de entrada p-dimensional. En grandes dimensiones, los puntos que pueden ser similares pueden tener distancias muy grandes. Además, cada vez que se va a hacer una predicción con KNN, busca al vecino más cercano en el conjunto de entrenamiento completo. Por esto, se debe utilizar un dataset pequeño para que el clasificador KNN completa su ejecución rápidamente.
\end{itemize}
En conclusión, al utilizar solo una porción de nuestros datasets para obtener los distintos cálculos de distancias y entrenar KNN, el cálculo de WMD se podrá realizar en un tiempo finito, y nuestro clasificador KNN funcionará rápida y eficientemente al realizar predicciones.

\cleardoublepage

\subsection{Comparando textos y obteniendo similitudes.}
\colorbox{red}{FALTA}

Previamente a utilizar Cosine Similarity y WDM para obtener las medidas de similitud entre los textos, se debe emplear algún algoritmo de vectorización que permita representar las palabras de nuestros textos a un espacio vectorial. De esta forma Cosine Similarity y WMD podrán interpretarlos de la mejor manera.  Como mencionamos previamente, como algoritmos de vectorización se utilizarán TF-IDF y Word Embeddings. 

\cleardoublepage

\subsection{Armado del modelo de clasificación KNN.}
\colorbox{red}{FALTA}

Una vez obtenidas estas mediciones de similitud entre los Curriculum Vitae de los candidatos y las descripciones de los puestos laborales de IT, estos valores se utilizarán para alimentar un algoritmo de clustering K-means que a su vez, con sus datos de salida (4 clusters), alimentarán a un modelo de clasificación KNN. Finalmente, con este modelo KNN lograremos, en base a los valores de similitud de nuevos candidatos, clasificar qué tan similares son dichos candidatos con respecto a la descripción de un puesto de IT: similitud escasa, similitud media, similitud alta, similitud muy alta.

\cleardoublepage

\subsection{Clasificación de nuevas muestras y resultados obtenidos.}\label{5.4.Predicciondenuevasmuestrasyresultadosobtenidos}

\colorbox{red}{FALTA}

\cleardoublepage

\subsection{Integración al Sistema Web.}\label{5.5.IntegracionalSistemaWeb}
\colorbox{red}{FALTA}

Anteriormente lo que se hizo fue un análisis mediate documentos en Jupyter Notebooks para evaluar el comportamiento del modelo de clasificación y los distintos algoritmos de medición de similitudes. 

Al observar que los resultados fueron los esperables, lo que se hizo en esta última etapa fue reutilizar las funciones que contenian la lógica de los distintos algoritmos utilizados junto con el modelo de clasificación KNN obtenidos en la fase previa, para integrar todo esto en el sistema Web. 

Como mencionamos previamente, este sistema web está realizado en Django, y cuenta con una base de datos relacional que contiene la información de los candidatos y reclutadores junto con los Curiculum Vitae y puestos que hayan cargado. 

De esta manera, nuestro sistema cuenta con una interfaz gráfica permitiendo interactuar entre candidatos y reclutadores y, principalmente, permitiendo que el reclutador sea capaz de obtener un listado con todos los candidatos que aplicaron a un puesto determinado, ordenados de mayor a menor en cuanto a su \textit{similitud} con dicho puesto. Esta \textit{similitud} representa el resultado obtenido de la clasificación por nuestro modelo KNN.

El sistema web contará con 2 tipos de usuario: 
\begin{itemize}
\item Candidato: quienes cargarán en el sistema sus Curriculum Vitae y aplicarán a los distintos puestos disponibles.
\item Reclutador: quienes cargarán en el sistema los puestos de trabajo que tengan disponibles y podrán consultar, entre otras cosas, un listado con todos los candidatos que aplicaron a un puesto determinado, ordenados de mayor a menor en cuanto a su similitud con dicho puesto.

\end{itemize}

\cleardoublepage

\subsubsection{Base de datos.}

Nuestros datos los almacenaremos en una base de datos \colorbox{red}{FALTA definir cual}. 

Para modelar y gestionar nuestros datos utilizamos el modelo relacional \footnote{Una base de datos relacional es un conjunto de una o más tablas estructuradas en registros (líneas) y campos (columnas), que se vinculan entre sí por un campo en común.}.

\colorbox{red}{Sacar la mayoría del documento modelo-entidad-relacion-case-method-richar-barker.pdf} 

Para comprender los datos que se almacenan en dicha base de datos, los representaremos utilizando un diagrama entidad relación \footnote{Un modelo entidad-relación es una herramienta para el modelo de datos, la cual facilita la representación de entidades de una base de datos.}.
Previamente a esto explicaremos los elementos del diagrama de entidad relación: 

\colorbox{red}{FALTA PONER IMAGEN CON LOS ELEMENTOS: Entidad rectángulo, Unión entre entidades son} \\ \colorbox{red}{las lineas que puede ser obligatoria u opcional, cardinalidad son los 1:M / 1:1 / M:M}

\begin{itemize}
\item Entidad: objeto concreto o abstracto que figura en nuestra base de datos. Por ejemplo una entidad puede ser un alumno, un cliente, una empresa, etc. Dentro de las entidades estan los atributos, atributos principales o clave primaria (PK) y atributos foraneos o clave secundaria (FK).  Las entidades que necesitamos para crear nuestra BD son: Candidato, Puesto, Reclutador y Candidato\_Puesto -entidad intermedia entre Candidato y Puesto-.
\item Unión entre entidades: pueden ser obligatorias u opcionales. En nuestro diagrama nuestras uniones son todas opcionales, ya que el reclutador puede o no CARGAR un puesto, el candidato puede o no APLICAR a un puesto y a su vez el puesto puede o no ser aplicado por un candidato. 
\item Cardinalidad: Relación entre entidades o mapeo. La cardinalidad es el tipo de relación entre entidades. Observando la figura \ref{fig:Cardinalidad} y considerando que los rectángulos azules son una entidad y los naranjas son otra entidad observamos que pueden haber 4 tipos de cardinalidades posibles:

\begin{enumerate}
\item Uno a uno: a cada entidad azul le corresponde solo una entidad naranja.
\item Uno a muchos: a cada entidad azul le corresponde una o varias entidades naranjas.
\item Muchos a uno: a cada entidad naranja le corresponde una o varias entidades azules.
\item Muchos a muchos: las entidades azules pueden tener varias entidades naranjas y las entidades naranjas también pueden tener varias entidades azules.
\end{enumerate}
\end{itemize}

\begin{figure}[H]    %[H] es para que se ubique justo debajo del texto anterior. 
  \centering
  \includegraphics[width=1\textwidth]{images/Cardinalidad.png}
  \caption{Tipos de cardinalidad.}  
  \label{fig:Cardinalidad}
\end{figure}

La cardinalidad entre nuestras entidades son:
\begin{itemize}
\item Entre Candidato y Puesto existe una relación muchos a muchos (M:M), ya que un candidato puede aplicar a M puestos y un puesto puede ser aplicado por M candidatos. Es por esto que se creó la tabla intermedia Candidato\_Puesto conllevando dos relaciones uno a muchos (1:M) con Puesto y Candidato.
\item Entre Reclutador y Puesto existe una relación de uno a muchos (1:M), ya que un reclutador puede cargar M puestos, y un puesto pertenece a un solo reclutador.
\end{itemize}

En cuanto a las claves pueden haber dos tipos. Por un lado está la clave primaria o atributo principal (PK)  es única y toda entidad debe tener la suya. Pueden haber múltiples PKs; estas se llaman PKs compuestas. Y por el otro está la clave secundaria o atributo foráneo (FK). Estas claves identifican a una entidad externa en otra, utilizándose para generar relaciones entre nuestras entidades. Si tenemos una clave FK en una entidad, significa que dicha clave FK es clave PK en otra entidad.


El diagrama de relación que utilizamos para nuestro trabajo lo observamos en la figura \ref{fig:Entity_Relation}.

\begin{figure}[H]    %[H] es para que se ubique justo debajo del texto anterior. 
  \centering
  \includegraphics[width=1\textwidth]{images/BD_Entity_Relation.png}
  \caption{Diagrama de relación utilizado.}  
  \label{fig:Entity_Relation}
\end{figure}

\cleardoublepage

\subsubsection{Secciones del sistema}

Para registrarse o loguearse al sistema, se implementará la interfaz provista en la figura \ref{fig:Vista_Registro}.

\begin{figure}[H]    %[H] es para que se ubique justo debajo del texto anterior. 
  \centering
  \includegraphics[width=1\textwidth]{images/Vista_Registro.png}
  \caption{Logueo y Registración.}  
  \label{fig:Vista_Registro}
\end{figure}

\colorbox{red}{ES UN BOCETO, FALTA PONER LA IMAGEN REAL}

El Candidato tendrá acceso al menú indicado en la figura \ref{fig:Vista_Candidato}. 

\begin{figure}[H]    %[H] es para que se ubique justo debajo del texto anterior. 
  \centering
  \includegraphics[width=1\textwidth]{images/Vista_Candidato.png}
  \caption{Vista del Candidato.}  
  \label{fig:Vista_Candidato}
\end{figure}

\colorbox{red}{ES UN BOCETO, FALTA PONER LA IMAGEN REAL}

Por su parte, el Reclutador tendrá acceso al menú indicado en la figura \ref{fig:Vista_Reclutador}. 

\begin{figure}[H]    %[H] es para que se ubique justo debajo del texto anterior. 
  \centering
  \includegraphics[width=1\textwidth]{images/Vista_Reclutador.png}
  \caption{Vista del Reclutador.}  
  \label{fig:Vista_Reclutador}
\end{figure}

\colorbox{red}{ES UN BOCETO, FALTA PONER LA IMAGEN REAL}

\cleardoublepage

\subsubsection{Manejo de los datos.}
\colorbox{red}{FALTA}

\cleardoublepage

\paragraph{Modelado.}
\colorbox{red}{FALTA}

\cleardoublepage

\paragraph{Filtrado.}
\colorbox{red}{FALTA}

\cleardoublepage

\paragraph{Visualización.}
\colorbox{red}{FALTA}

\cleardoublepage

\subsection{Pipeline Flow final del Sistema.}
\colorbox{red}{FALTA}

Una vez que el reclutador dentro de la sección observada en la figura \ref{fig:Vista_Reclutador} haga click en "Analizar", el sistema reflejará el pipeline indicado en la figura \ref{fig:Pipeline_Final} para obtener como resultado un listado con todos los candidatos que aplicaron al puesto, ordenados de mayor a menor en cuanto a su \textit{similitud} con dicho puesto. Esta \textit{similitud} representa el resultado obtenido de la clasificación por nuestro modelo KNN.

\begin{figure}[H]    %[H] es para que se ubique justo debajo del texto anterior. 
  \centering
  \includegraphics[width=1\textwidth]{images/Pipeline_Final.png}
  \caption{Pipeline Flow final del Sistema.}  
  \label{fig:Pipeline_Final}
\end{figure}

\cleardoublepage

\subsection{Conclusiones.}
\colorbox{red}{FALTA}

\cleardoublepage

\subsection{Caso de Uso.}
\colorbox{red}{FALTA}

\cleardoublepage

\subsection{Limitaciones del sistema.}
\colorbox{red}{FALTA}

\cleardoublepage

\section{Próximos pasos.}  
\colorbox{red}{FALTA - acá poner mejoras}

\cleardoublepage

\section{Anexos.}
\colorbox{red}{FALTA}

\cleardoublepage


\begin{thebibliography}{9}
\bibitem{apunte_uba}
Luis Argerich, Natalia Golmar, Damián Martinelli, Martín Ramos Mejía, \&
Juan Andrés Laura. (2019, Enero). \textit{75.06, 95.58 Organización de Datos}. Apunte del Curso Organización de Datos, Universidad de Buenos Aires, Facultad de Ingenieria. (pp. COMPLETAR páginas). 


\end{thebibliography}



\end{document}
%Para poner en Las citas del anexo --> información\cite{iot}. 