\relax 
\providecommand\hyper@newdestlabel[2]{}
\@nameuse{bbl@beforestart}
\catcode `"\active 
\catcode `<\active 
\catcode `>\active 
\@nameuse{es@quoting}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:undav-logo}{{\caption@xref {fig:undav-logo}{ on input line 117}}{1}{}{figure.caption.1}{}}
\babel@aux{spanish}{}
\citation{trabajos_relacionados_1}
\citation{trabajos_relacionados_2}
\citation{trabajos_relacionados_3}
\citation{trabajos_relacionados_4}
\citation{trabajos_relacionados_5}
\citation{trabajos_relacionados_6}
\citation{trabajos_relacionados_7}
\citation{trabajos_relacionados_8}
\citation{trabajos_relacionados_9}
\citation{trabajos_relacionados_10}
\citation{trabajos_relacionados_11}
\citation{trabajos_relacionados_12}
\citation{trabajos_relacionados_13}
\citation{trabajos_relacionados_14}
\citation{trabajos_relacionados_15}
\citation{jobs_future}
\citation{jobs_future}
\citation{jobs_future}
\citation{jobs_future}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introducción.}{7}{section.1}\protected@file@percent }
\newlabel{Intro}{{1}{7}{Introducción}{section.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Top 20 demanda de roles laborales en aumento y disminución para el año 2020, por participación de las empresas encuestadas por el \textit  {Foro Económico Mundial}\cite  {jobs_future}.\relax }}{7}{figure.caption.3}\protected@file@percent }
\newlabel{fig:Increasing_Jobs}{{1.1}{7}{Top 20 demanda de roles laborales en aumento y disminución para el año 2020, por participación de las empresas encuestadas por el \textit {Foro Económico Mundial}\cite {jobs_future}.\relax }{figure.caption.3}{}}
\citation{Similarity_calculation}
\citation{Similarity_calculation}
\citation{Similarity_calculation}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Porcentaje de tareas realizadas por humanos frente a máquinas, 2020 y 2025 (previsto), por participación de las empresas encuestadas por el \textit  {Foro Económico Mundial}\cite  {jobs_future}.\relax }}{8}{figure.caption.4}\protected@file@percent }
\newlabel{fig:Automatizacion}{{1.2}{8}{Porcentaje de tareas realizadas por humanos frente a máquinas, 2020 y 2025 (previsto), por participación de las empresas encuestadas por el \textit {Foro Económico Mundial}\cite {jobs_future}.\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Algoritmos y técnicas utilizadas.}{9}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Objetivos del Proyecto.}{10}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}Objetivo general.}{10}{subsubsection.1.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.2}Objetivos específicos.}{10}{subsubsection.1.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Alcance del Proyecto.}{11}{subsection.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Organización.}{11}{subsection.1.4}\protected@file@percent }
\citation{seleccion_reclutamiento_2}
\citation{seleccion_reclutamiento_2}
\@writefile{toc}{\contentsline {section}{\numberline {2}Reclutamiento y selección laboral.}{13}{section.2}\protected@file@percent }
\newlabel{2.ReclutamientolaboralenIT}{{2}{13}{Reclutamiento y selección laboral}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Introducción.}{13}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Reclutamiento vs selección.}{13}{subsection.2.2}\protected@file@percent }
\newlabel{SeleccionYReclutamiento}{{2.2}{13}{Reclutamiento vs selección}{subsection.2.2}{}}
\citation{seleccion_reclutamiento_2}
\citation{seleccion_reclutamiento_2}
\citation{trabajos_relacionados_10}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Evolución de los procesos de reclutamiento y selección laboral.}{15}{subsection.2.3}\protected@file@percent }
\citation{estudio_eye_tracking}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Cribado o screening.}{16}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1}Screening manual vs screening automatizado}{16}{subsubsection.2.4.1}\protected@file@percent }
\citation{seleccion_reclutamiento_1}
\citation{seleccion_reclutamiento_1}
\citation{trabajos_relacionados_1}
\citation{trabajos_relacionados_2}
\citation{ontology_mapping}
\citation{trabajos_relacionados_3}
\citation{trabajos_relacionados_4}
\citation{trabajos_relacionados_5}
\citation{trabajos_relacionados_6}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Sistemas de screening: Estado del arte.}{17}{subsection.2.5}\protected@file@percent }
\newlabel{Estado_del_arte}{{2.5}{17}{Sistemas de screening: Estado del arte}{subsection.2.5}{}}
\citation{trabajos_relacionados_7}
\citation{trabajos_relacionados_8}
\citation{trabajos_relacionados_9}
\citation{trabajos_relacionados_10}
\citation{trabajos_relacionados_11}
\citation{trabajos_relacionados_12}
\citation{trabajos_relacionados_13}
\citation{sistema_recomendacion}
\citation{trabajos_relacionados_14}
\citation{trabajos_relacionados_15}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Enfoque del Proyecto.}{19}{subsection.2.6}\protected@file@percent }
\citation{intro_algos_ML}
\citation{apunte_uba}
\@writefile{toc}{\contentsline {section}{\numberline {3}Algoritmos de Machine Learning.}{20}{section.3}\protected@file@percent }
\newlabel{3.AlgoritmosdeMachineLearning}{{3}{20}{Algoritmos de Machine Learning}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Introducción.}{20}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Machine Learning (ML).}{20}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Aprendizaje supervisado y no supervisado.}{21}{subsubsection.3.2.1}\protected@file@percent }
\citation{apunte_uba}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Tipos de aprendizaje en ML}}{22}{figure.caption.5}\protected@file@percent }
\newlabel{fig:Clasif_algoritmos}{{3.1}{22}{Tipos de aprendizaje en ML}{figure.caption.5}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.2.1.1}Regresión.}{22}{paragraph.3.2.1.1}\protected@file@percent }
\citation{apunte_uba}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.2.1.2}Clasificación.}{23}{paragraph.3.2.1.2}\protected@file@percent }
\newlabel{clasificacion}{{3.2.1.2}{23}{Clasificación}{paragraph.3.2.1.2}{}}
\citation{apunte_uba}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.2.1.3}Agrupación (clustering).}{24}{paragraph.3.2.1.3}\protected@file@percent }
\newlabel{agrupacion}{{3.2.1.3}{24}{Agrupación (clustering)}{paragraph.3.2.1.3}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.2.1.4}Algoritmos más conocidos.}{25}{paragraph.3.2.1.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Algoritmos de machine learning más conocidos\relax }}{25}{figure.caption.6}\protected@file@percent }
\newlabel{fig:Diagrama_algoritmos}{{3.2}{25}{Algoritmos de machine learning más conocidos\relax }{figure.caption.6}{}}
\citation{aprendiz_transd}
\citation{apunte_uba}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Aprendizaje transductivo}{26}{subsubsection.3.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Aprendizaje transductivo\relax }}{26}{figure.caption.7}\protected@file@percent }
\newlabel{fig:Transductivo_1}{{3.3}{26}{Aprendizaje transductivo\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Aprendizaje transductivo\relax }}{26}{figure.caption.8}\protected@file@percent }
\newlabel{fig:Transductivo_2}{{3.4}{26}{Aprendizaje transductivo\relax }{figure.caption.8}{}}
\citation{apunte_uba}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}Separación de los datos.}{27}{subsubsection.3.2.3}\protected@file@percent }
\newlabel{Separacion datos}{{3.2.3}{27}{Separación de los datos}{subsubsection.3.2.3}{}}
\citation{preprocessing}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.4}¿Cómo implementar un modelo de ML?}{28}{subsubsection.3.2.4}\protected@file@percent }
\citation{apunte_uba}
\citation{metrics_clustering_1}
\citation{metrics_clustering_2}
\citation{metrics_clasification}
\citation{metrics_regression}
\citation{metrics_clustering_1}
\citation{metrics_clustering_2}
\citation{metrics_clasification}
\citation{metrics_regression}
\citation{apunte_uba}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Métricas para evaluar distintos tipos de modelos\cite  {metrics_clustering_1, metrics_clustering_2,metrics_clasification,metrics_regression}.\relax }}{30}{table.caption.9}\protected@file@percent }
\newlabel{table:1}{{1}{30}{Métricas para evaluar distintos tipos de modelos\cite {metrics_clustering_1, metrics_clustering_2,metrics_clasification,metrics_regression}.\relax }{table.caption.9}{}}
\citation{apunte_uba}
\citation{cross_validation}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.2.4.1}Cross Validation.}{32}{paragraph.3.2.4.1}\protected@file@percent }
\newlabel{Cross Validation}{{3.2.4.1}{32}{Cross Validation}{paragraph.3.2.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces k-fold Cross Validation.}}{32}{figure.caption.10}\protected@file@percent }
\newlabel{fig:cross_val}{{3.5}{32}{k-fold Cross Validation}{figure.caption.10}{}}
\citation{apunte_uba}
\citation{apunte_uba}
\citation{over_and_under}
\citation{apunte_uba}
\citation{apunte_uba}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.2.4.2}Los Problemas de ML: Overfitting y Underfitting.}{33}{paragraph.3.2.4.2}\protected@file@percent }
\newlabel{Over_y_under}{{3.2.4.2}{33}{Los Problemas de ML: Overfitting y Underfitting}{paragraph.3.2.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Overfitting y Underfitting\cite  {apunte_uba}\relax }}{33}{figure.caption.11}\protected@file@percent }
\newlabel{fig:fitting}{{3.6}{33}{Overfitting y Underfitting\cite {apunte_uba}\relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}K-Nearest Neighbor (KNN).}{34}{subsection.3.3}\protected@file@percent }
\citation{KNN_limitacion}
\citation{KNN_Ejemplo}
\citation{KNN_Ejemplo}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Principal limitación KNN.}{35}{subsubsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Funcionamiento y ejemplo de KNN.}{35}{subsubsection.3.3.2}\protected@file@percent }
\citation{KNN_Ejemplo}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Ejemplo de Clasificación con KNN con K=3 (círculo con linea sólida) y K=5 (círculo con linea punteada), usando la distancia euclidiana como métrica de cálculo de distancias\cite  {KNN_Ejemplo}.\relax }}{36}{figure.caption.12}\protected@file@percent }
\newlabel{fig:KNN_example}{{3.7}{36}{Ejemplo de Clasificación con KNN con K=3 (círculo con linea sólida) y K=5 (círculo con linea punteada), usando la distancia euclidiana como métrica de cálculo de distancias\cite {KNN_Ejemplo}.\relax }{figure.caption.12}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Probabilidad de pertenecer a cada clase para diferentes valores de k.\relax }}{36}{table.caption.13}\protected@file@percent }
\newlabel{table:2}{{2}{36}{Probabilidad de pertenecer a cada clase para diferentes valores de k.\relax }{table.caption.13}{}}
\citation{apunte_uba}
\citation{apunte_uba}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.3}Métrica de distancia a emplear.}{37}{subsubsection.3.3.3}\protected@file@percent }
\newlabel{metrica_dist_emp}{{3.3.3}{37}{Métrica de distancia a emplear}{subsubsection.3.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Distancia Manhattan vs Distancia Euclidiana\cite  {apunte_uba}.\relax }}{37}{figure.caption.14}\protected@file@percent }
\newlabel{fig:Man_euc}{{3.8}{37}{Distancia Manhattan vs Distancia Euclidiana\cite {apunte_uba}.\relax }{figure.caption.14}{}}
\citation{KNN_Ejemplo}
\citation{KNN_Ejemplo}
\citation{KNN_Ejemplo}
\citation{KNN_Ejemplo}
\citation{KNN_Ejemplo}
\citation{KNN_Ejemplo}
\citation{KNN_Ejemplo}
\citation{KNN_Ejemplo}
\newlabel{eq:ecuacion_1}{{1}{38}{Métrica de distancia a emplear}{equation.3.1}{}}
\newlabel{eq:ecuacion_2}{{2}{38}{Métrica de distancia a emplear}{equation.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces Distancia Euclidiana en 2 dimensiones.\relax }}{38}{figure.caption.15}\protected@file@percent }
\newlabel{fig:KNN_2_Dim}{{3.9}{38}{Distancia Euclidiana en 2 dimensiones.\relax }{figure.caption.15}{}}
\newlabel{eq:ecuacion_3}{{3}{38}{Métrica de distancia a emplear}{equation.3.3}{}}
\citation{apunte_uba}
\citation{apunte_uba}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.4}Eligiendo el valor de k: overfitting y underfitting.}{39}{subsubsection.3.3.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces KNN con k = 1. \cite  {apunte_uba}\relax }}{39}{figure.caption.16}\protected@file@percent }
\newlabel{fig:KNN_k_1}{{3.10}{39}{KNN con k = 1. \cite {apunte_uba}\relax }{figure.caption.16}{}}
\citation{apunte_uba}
\citation{apunte_uba}
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces KNN con k = 5. \cite  {apunte_uba}\relax }}{40}{figure.caption.17}\protected@file@percent }
\newlabel{fig:KNN_k_5}{{3.11}{40}{KNN con k = 5. \cite {apunte_uba}\relax }{figure.caption.17}{}}
\citation{K_means_review}
\citation{K_means_experiment}
\citation{K_means_experiment}
\citation{K_means_experiment}
\citation{K_means_experiment}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}K-means.}{41}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.1}Funcionamiento y ejemplo de K-means.}{41}{subsubsection.3.4.1}\protected@file@percent }
\newlabel{K_means_funcionamiento}{{3.4.1}{41}{Funcionamiento y ejemplo de K-means}{subsubsection.3.4.1}{}}
\newlabel{eq:ecuacion_4}{{4}{41}{Funcionamiento y ejemplo de K-means}{equation.3.4}{}}
\newlabel{eq:ecuacion_5}{{5}{42}{Funcionamiento y ejemplo de K-means}{equation.3.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces Algoritmo K-means.\relax }}{42}{figure.caption.18}\protected@file@percent }
\newlabel{fig:K_means_working_1}{{3.12}{42}{Algoritmo K-means.\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.13}{\ignorespaces Algoritmo K-means.\relax }}{43}{figure.caption.19}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.14}{\ignorespaces Algoritmo K-means.\relax }}{43}{figure.caption.20}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.15}{\ignorespaces Algoritmo K-means.\relax }}{44}{figure.caption.21}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.16}{\ignorespaces Algoritmo K-means.\relax }}{44}{figure.caption.22}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.17}{\ignorespaces Algoritmo K-means.\relax }}{44}{figure.caption.23}\protected@file@percent }
\citation{K_means_experiment}
\citation{K_means_elbow}
\citation{K_means_elbow}
\citation{K_means_elbow}
\citation{K_means_elbow}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2}Objetivo de k-means y su función de coste.}{45}{subsubsection.3.4.2}\protected@file@percent }
\newlabel{eq:ecuacion_6}{{6}{45}{Objetivo de k-means y su función de coste}{equation.3.6}{}}
\newlabel{eq:ecuacion_7}{{7}{45}{Objetivo de k-means y su función de coste}{equation.3.7}{}}
\citation{apunte_uba}
\citation{apunte_uba}
\citation{apunte_uba}
\citation{apunte_uba}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.3}Posición inicial de los centroides.}{46}{subsubsection.3.4.3}\protected@file@percent }
\newlabel{Posicion inicial centroides}{{3.4.3}{46}{Posición inicial de los centroides}{subsubsection.3.4.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.18}{\ignorespaces Ejemplo K-means. \cite  {apunte_uba}\relax }}{46}{figure.caption.24}\protected@file@percent }
\newlabel{fig:K_means_costo_1}{{3.18}{46}{Ejemplo K-means. \cite {apunte_uba}\relax }{figure.caption.24}{}}
\citation{apunte_uba}
\citation{apunte_uba}
\citation{apunte_uba}
\citation{apunte_uba}
\@writefile{lof}{\contentsline {figure}{\numberline {3.19}{\ignorespaces Ejemplo K-Means peor (izquierda) y mejor (derecha) costo. \cite  {apunte_uba}\relax }}{47}{figure.caption.25}\protected@file@percent }
\newlabel{fig:K_means_costo_2}{{3.19}{47}{Ejemplo K-Means peor (izquierda) y mejor (derecha) costo. \cite {apunte_uba}\relax }{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.20}{\ignorespaces Costo en K-Means. \cite  {apunte_uba}\relax }}{47}{figure.caption.26}\protected@file@percent }
\newlabel{fig:K_means_costo_3}{{3.20}{47}{Costo en K-Means. \cite {apunte_uba}\relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.21}{\ignorespaces Histograma J en K-Means. \cite  {apunte_uba}\relax }}{47}{figure.caption.26}\protected@file@percent }
\newlabel{fig:K_means_costo_4}{{3.21}{47}{Histograma J en K-Means. \cite {apunte_uba}\relax }{figure.caption.26}{}}
\citation{K_means_review}
\citation{K_means_review}
\citation{K_means_experiment}
\citation{K_means_initial_centroids}
\citation{K_means_plus_plus}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.4}Limitaciones K-means.}{48}{subsubsection.3.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.4.4.1}Obtención del k mediante Elbow Method.}{49}{paragraph.3.4.4.1}\protected@file@percent }
\newlabel{Elbow_Met}{{3.4.4.1}{49}{Obtención del k mediante Elbow Method}{paragraph.3.4.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.22}{\ignorespaces Puntos de datos.\relax }}{49}{figure.caption.27}\protected@file@percent }
\newlabel{fig:Elbow_1}{{3.22}{49}{Puntos de datos.\relax }{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.23}{\ignorespaces Método del codo usando Inercia.\relax }}{49}{figure.caption.27}\protected@file@percent }
\newlabel{fig:Elbow_2}{{3.23}{49}{Método del codo usando Inercia.\relax }{figure.caption.27}{}}
\citation{K_means_plus_plus}
\@writefile{lof}{\contentsline {figure}{\numberline {3.24}{\ignorespaces Puntos de datos clusterizados para diferentes valores de $k$.\relax }}{50}{figure.caption.28}\protected@file@percent }
\newlabel{fig:Elbow_3}{{3.24}{50}{Puntos de datos clusterizados para diferentes valores de $k$.\relax }{figure.caption.28}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.4.4.2}Inicialización de los centroides: k-means++.}{50}{paragraph.3.4.4.2}\protected@file@percent }
\newlabel{k_means_plus_plus}{{3.4.4.2}{50}{Inicialización de los centroides: k-means++}{paragraph.3.4.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.25}{\ignorespaces Inicialización de centroides mediante K-means.\relax }}{51}{figure.caption.29}\protected@file@percent }
\newlabel{fig:K_means_plus_plus}{{3.25}{51}{Inicialización de centroides mediante K-means.\relax }{figure.caption.29}{}}
\citation{ANN_21}
\citation{apunte_uba}
\citation{ANN_21}
\citation{ANN_22}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Redes Neuronales Artificiales (ANN).}{52}{subsection.3.5}\protected@file@percent }
\newlabel{ann_teoria}{{3.5}{52}{Redes Neuronales Artificiales (ANN)}{subsection.3.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.1}Perceptrón simple.}{52}{subsubsection.3.5.1}\protected@file@percent }
\citation{ANN_23}
\@writefile{lof}{\contentsline {figure}{\numberline {3.26}{\ignorespaces Modelo Perceptrón Simple\relax }}{53}{figure.caption.30}\protected@file@percent }
\newlabel{fig:ann_1}{{3.26}{53}{Modelo Perceptrón Simple\relax }{figure.caption.30}{}}
\newlabel{eq:ecuacion_1_ANN}{{8}{53}{Perceptrón simple}{equation.3.8}{}}
\citation{ANN_23}
\citation{ANN_24}
\citation{ANN_24}
\citation{ANN_24}
\newlabel{eq:ecuacion_2_ANN}{{9}{54}{Perceptrón simple}{equation.3.9}{}}
\newlabel{eq:ecuacion_3_ANN}{{10}{54}{Perceptrón simple}{equation.3.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.2}Desventaja del Perceptrón simple. }{54}{subsubsection.3.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.27}{\ignorespaces Perceptrones solucionando la función OR y XOR.}}{55}{figure.caption.31}\protected@file@percent }
\newlabel{fig:ann_2}{{3.27}{55}{Perceptrones solucionando la función OR y XOR}{figure.caption.31}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.3}Perceptrón multicapa (MLP).}{55}{subsubsection.3.5.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.28}{\ignorespaces Modelo Perceptrón Multicapa -MLP- (izquierda) y Perceptrón Simple (derecha).}}{56}{figure.caption.32}\protected@file@percent }
\newlabel{fig:ann_3}{{3.28}{56}{Modelo Perceptrón Multicapa -MLP- (izquierda) y Perceptrón Simple (derecha)}{figure.caption.32}{}}
\citation{ANN_25}
\citation{ANN_25}
\citation{ANN_25}
\citation{ANN_25}
\citation{ANN_25}
\citation{ANN_25}
\citation{ANN_25}
\citation{ANN_25}
\citation{ANN_25}
\newlabel{eq:ecuacion_5_ANN}{{11}{57}{Perceptrón multicapa (MLP)}{equation.3.11}{}}
\newlabel{eq:ecuacion_6_ANN}{{12}{57}{Perceptrón multicapa (MLP)}{equation.3.12}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.4}Funciones de activación en MLP.}{57}{subsubsection.3.5.4}\protected@file@percent }
\newlabel{Func_activ}{{3.5.4}{57}{Funciones de activación en MLP}{subsubsection.3.5.4}{}}
\citation{ANN_24}
\citation{ANN_24}
\citation{ANN_24}
\citation{ANN_24}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.5.4.1}Softmax en la capa de salida.}{58}{paragraph.3.5.4.1}\protected@file@percent }
\newlabel{soft_capa_salida}{{3.5.4.1}{58}{Softmax en la capa de salida}{paragraph.3.5.4.1}{}}
\newlabel{eq:ecuacion_7_ANN}{{13}{58}{Softmax en la capa de salida}{equation.3.13}{}}
\citation{ANN_25}
\citation{ANN_25}
\citation{ANN_25}
\citation{ANN_25}
\citation{ANN_25}
\citation{ANN_25}
\@writefile{lof}{\contentsline {figure}{\numberline {3.29}{\ignorespaces Función Softmax aplicada a la capa de salida.}}{59}{figure.caption.33}\protected@file@percent }
\newlabel{fig:ann_4}{{3.29}{59}{Función Softmax aplicada a la capa de salida}{figure.caption.33}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.5.4.2}Sigmoide en la capa de salida.}{59}{paragraph.3.5.4.2}\protected@file@percent }
\newlabel{sigm_capa_salida}{{3.5.4.2}{59}{Sigmoide en la capa de salida}{paragraph.3.5.4.2}{}}
\newlabel{eq:ecuacion_8_ANN}{{14}{59}{Sigmoide en la capa de salida}{equation.3.14}{}}
\citation{ANN_25}
\@writefile{lof}{\contentsline {figure}{\numberline {3.30}{\ignorespaces Funciones de activación escalón y sigmoide\cite  {ANN_25}.\relax }}{60}{figure.caption.34}\protected@file@percent }
\newlabel{fig:ann_5}{{3.30}{60}{Funciones de activación escalón y sigmoide\cite {ANN_25}.\relax }{figure.caption.34}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.5}Entrenamiento en una red neuronal.}{60}{subsubsection.3.5.5}\protected@file@percent }
\newlabel{entren_ann}{{3.5.5}{60}{Entrenamiento en una red neuronal}{subsubsection.3.5.5}{}}
\citation{ANN_25}
\citation{ANN_25}
\citation{ANN_25}
\citation{ANN_25}
\newlabel{eq:ecuacion_9_ANN}{{15}{61}{Entrenamiento en una red neuronal}{equation.3.15}{}}
\citation{ANN_25}
\citation{ANN_25}
\citation{ANN_25}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.5.5.1}Hiper-parámetro n.}{62}{paragraph.3.5.5.1}\protected@file@percent }
\newlabel{hiper_n}{{3.5.5.1}{62}{Hiper-parámetro n}{paragraph.3.5.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.31}{\ignorespaces Efecto de diferentes tasas de aprendizaje $n$ durante el entrenamiento.\cite  {ANN_25}.\relax }}{62}{figure.caption.35}\protected@file@percent }
\newlabel{fig:ann_6}{{3.31}{62}{Efecto de diferentes tasas de aprendizaje $n$ durante el entrenamiento.\cite {ANN_25}.\relax }{figure.caption.35}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Natural Language Processing.}{63}{section.4}\protected@file@percent }
\newlabel{4.NaturalLanguageProcessing}{{4}{63}{Natural Language Processing}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Introducción.}{64}{subsection.4.1}\protected@file@percent }
\newlabel{Intro_NLP}{{4.1}{64}{Introducción}{subsection.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Aplicaciones NLP.}{65}{subsection.4.2}\protected@file@percent }
\newlabel{Aplicaciones_NLP}{{4.2}{65}{Aplicaciones NLP}{subsection.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}NLP en la práctica.}{66}{subsection.4.3}\protected@file@percent }
\newlabel{Practica_NLP}{{4.3}{66}{NLP en la práctica}{subsection.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Preprocesamiento de textos.}{67}{subsection.4.4}\protected@file@percent }
\newlabel{Proces_textos}{{4.4}{67}{Preprocesamiento de textos}{subsection.4.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.1}Limpieza y normalización.}{68}{subsubsection.4.4.1}\protected@file@percent }
\newlabel{Limpieza_y_norm}{{4.4.1}{68}{Limpieza y normalización}{subsubsection.4.4.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.2}Tokenización.}{69}{subsubsection.4.4.2}\protected@file@percent }
\newlabel{tokenizacion}{{4.4.2}{69}{Tokenización}{subsubsection.4.4.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.3}Stemming y Lemmatization.}{70}{subsubsection.4.4.3}\protected@file@percent }
\newlabel{stem_y_lem}{{4.4.3}{70}{Stemming y Lemmatization}{subsubsection.4.4.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.4}N-grams.}{71}{subsubsection.4.4.4}\protected@file@percent }
\newlabel{ngrams}{{4.4.4}{71}{N-grams}{subsubsection.4.4.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Obtención de representaciones vectoriales.}{72}{subsection.4.5}\protected@file@percent }
\newlabel{rep_vect}{{4.5}{72}{Obtención de representaciones vectoriales}{subsection.4.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.1}Bag of Words (BoW).}{73}{subsubsection.4.5.1}\protected@file@percent }
\newlabel{bow}{{4.5.1}{73}{Bag of Words (BoW)}{subsubsection.4.5.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.2}TF-IDF.}{74}{subsubsection.4.5.2}\protected@file@percent }
\newlabel{tf_idf}{{4.5.2}{74}{TF-IDF}{subsubsection.4.5.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.3}Desventajas BoW \& TF-IDF.}{75}{subsubsection.4.5.3}\protected@file@percent }
\newlabel{desv_bow_tfidf}{{4.5.3}{75}{Desventajas BoW \& TF-IDF}{subsubsection.4.5.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.4}Word embeddings.}{76}{subsubsection.4.5.4}\protected@file@percent }
\newlabel{word_emb}{{4.5.4}{76}{Word embeddings}{subsubsection.4.5.4}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.5.4.1}Embeddings.}{77}{paragraph.4.5.4.1}\protected@file@percent }
\newlabel{embedd}{{4.5.4.1}{77}{Embeddings}{paragraph.4.5.4.1}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.5.4.2}Word2vec.}{78}{paragraph.4.5.4.2}\protected@file@percent }
\newlabel{word2vec}{{4.5.4.2}{78}{Word2vec}{paragraph.4.5.4.2}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.5.4.3}¿Cómo obtener nuestros Word embeddings?}{79}{paragraph.4.5.4.3}\protected@file@percent }
\newlabel{obt_word_emb}{{4.5.4.3}{79}{¿Cómo obtener nuestros Word embeddings?}{paragraph.4.5.4.3}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.5.4.4}CBOW vs Skipgram.}{80}{paragraph.4.5.4.4}\protected@file@percent }
\newlabel{cbow_vs_skip}{{4.5.4.4}{80}{CBOW vs Skipgram}{paragraph.4.5.4.4}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.5.4.5}One hot encoding.}{81}{paragraph.4.5.4.5}\protected@file@percent }
\newlabel{one_hot_enc}{{4.5.4.5}{81}{One hot encoding}{paragraph.4.5.4.5}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.5.4.6}Obteniendo nuestros Word Embeddings con Skipgram.}{82}{paragraph.4.5.4.6}\protected@file@percent }
\newlabel{obt_skip}{{4.5.4.6}{82}{Obteniendo nuestros Word Embeddings con Skipgram}{paragraph.4.5.4.6}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.5.4.7}Arquitectura del modelo Skipgram.}{83}{paragraph.4.5.4.7}\protected@file@percent }
\newlabel{skipgram}{{4.5.4.7}{83}{Arquitectura del modelo Skipgram}{paragraph.4.5.4.7}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.5.4.8}Entrenamiento y función de costo con Softmax.}{84}{paragraph.4.5.4.8}\protected@file@percent }
\newlabel{ent_costo_softmax}{{4.5.4.8}{84}{Entrenamiento y función de costo con Softmax}{paragraph.4.5.4.8}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.5.4.9}Optimizaciones: Muestreo Negativo.}{85}{paragraph.4.5.4.9}\protected@file@percent }
\newlabel{neg_samp}{{4.5.4.9}{85}{Optimizaciones: Muestreo Negativo}{paragraph.4.5.4.9}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.5.4.10}Entrenamiento y función de costo con Sigmoide.}{86}{paragraph.4.5.4.10}\protected@file@percent }
\newlabel{ent_costo_sigmoide}{{4.5.4.10}{86}{Entrenamiento y función de costo con Sigmoide}{paragraph.4.5.4.10}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.5.4.11}Desventajas Word2Vec.}{87}{paragraph.4.5.4.11}\protected@file@percent }
\newlabel{desv_word2vec}{{4.5.4.11}{87}{Desventajas Word2Vec}{paragraph.4.5.4.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Obtención de las mediciones de similitud entre textos.}{88}{subsection.4.6}\protected@file@percent }
\newlabel{med_sim_textos}{{4.6}{88}{Obtención de las mediciones de similitud entre textos}{subsection.4.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.6.1}Maneras de medir la similitud entre textos.}{89}{subsubsection.4.6.1}\protected@file@percent }
\newlabel{Tecnicas_Simil_textos}{{4.6.1}{89}{Maneras de medir la similitud entre textos}{subsubsection.4.6.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.6.2}¿Por qué decidimos utilizar Cosine similarity y WMD?}{90}{subsubsection.4.6.2}\protected@file@percent }
\newlabel{cos_y_wmd}{{4.6.2}{90}{¿Por qué decidimos utilizar Cosine similarity y WMD?}{subsubsection.4.6.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.6.3}Cosine Similarity.}{91}{subsubsection.4.6.3}\protected@file@percent }
\newlabel{cosine}{{4.6.3}{91}{Cosine Similarity}{subsubsection.4.6.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.6.4}Word Mover’s Distance (WMD).}{92}{subsubsection.4.6.4}\protected@file@percent }
\newlabel{wmd}{{4.6.4}{92}{Word Mover’s Distance (WMD)}{subsubsection.4.6.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Implementación.}{93}{section.5}\protected@file@percent }
\newlabel{5.Implementacion}{{5}{93}{Implementación}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Obtención del modelo de clasificación.}{94}{subsection.5.1}\protected@file@percent }
\newlabel{5.1.Obtenciondelmodelopredictivo}{{5.1}{94}{Obtención del modelo de clasificación}{subsection.5.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}Introducción.}{94}{subsubsection.5.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}Esquema.}{94}{subsubsection.5.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Pipeline Flow para la obtención del modelo de clasificación KNN\relax }}{94}{figure.caption.36}\protected@file@percent }
\newlabel{fig:FlowCoreSystem}{{5.1}{94}{Pipeline Flow para la obtención del modelo de clasificación KNN\relax }{figure.caption.36}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.3}Obtención de sets de datos.}{95}{subsubsection.5.1.3}\protected@file@percent }
\newlabel{obtencion_set_datos}{{5.1.3}{95}{Obtención de sets de datos}{subsubsection.5.1.3}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {5.1.3.1}Curriculum Vitae.}{95}{paragraph.5.1.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {5.1.3.2}Descripciones Puestos Laborales.}{95}{paragraph.5.1.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.4}Preprocesamiento de textos.}{96}{subsubsection.5.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.5}Cantidad final del set de datos y su uso en las distintas etapas.}{97}{subsubsection.5.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Comparando textos y obteniendo similitudes.}{99}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}TF-IDF \& Cosine Similarity.}{100}{subsubsection.5.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}Word embeddings (Word2vec) \& WMD.}{101}{subsubsection.5.2.2}\protected@file@percent }
\newlabel{Implementacion_word_emb_y_wmd}{{5.2.2}{101}{Word embeddings (Word2vec) \& WMD}{subsubsection.5.2.2}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {5.2.2.1}Elección de hiper-parámetros Word2vec.}{102}{paragraph.5.2.2.1}\protected@file@percent }
\newlabel{hiper_par_word2vec}{{5.2.2.1}{102}{Elección de hiper-parámetros Word2vec}{paragraph.5.2.2.1}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {5.2.2.2}Word Mover's Distance (WMD).}{103}{paragraph.5.2.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Armado del modelo de clasificación KNN.}{104}{subsection.5.3}\protected@file@percent }
\newlabel{IMP_Modelo_clasificacion_KNN}{{5.3}{104}{Armado del modelo de clasificación KNN}{subsection.5.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Clasificación de nuevas muestras y resultados obtenidos.}{105}{subsection.5.4}\protected@file@percent }
\newlabel{5.4.Predicciondenuevasmuestrasyresultadosobtenidos}{{5.4}{105}{Clasificación de nuevas muestras y resultados obtenidos}{subsection.5.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Integración al Sistema Web.}{106}{subsection.5.5}\protected@file@percent }
\newlabel{5.5.IntegracionalSistemaWeb}{{5.5}{106}{Integración al Sistema Web}{subsection.5.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.5.1}Base de datos.}{107}{subsubsection.5.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Tipos de cardinalidad.\relax }}{108}{figure.caption.37}\protected@file@percent }
\newlabel{fig:Cardinalidad}{{5.2}{108}{Tipos de cardinalidad.\relax }{figure.caption.37}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Diagrama de relación utilizado.\relax }}{108}{figure.caption.38}\protected@file@percent }
\newlabel{fig:Entity_Relation}{{5.3}{108}{Diagrama de relación utilizado.\relax }{figure.caption.38}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.5.2}Secciones del sistema}{109}{subsubsection.5.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Logueo y Registración.\relax }}{109}{figure.caption.39}\protected@file@percent }
\newlabel{fig:Vista_Registro}{{5.4}{109}{Logueo y Registración.\relax }{figure.caption.39}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Vista del Candidato.\relax }}{110}{figure.caption.40}\protected@file@percent }
\newlabel{fig:Vista_Candidato}{{5.5}{110}{Vista del Candidato.\relax }{figure.caption.40}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Vista del Reclutador.\relax }}{111}{figure.caption.41}\protected@file@percent }
\newlabel{fig:Vista_Reclutador}{{5.6}{111}{Vista del Reclutador.\relax }{figure.caption.41}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.5.3}Manejo de los datos.}{112}{subsubsection.5.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {5.5.3.1}Modelado.}{113}{paragraph.5.5.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {5.5.3.2}Filtrado.}{114}{paragraph.5.5.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {5.5.3.3}Visualización.}{115}{paragraph.5.5.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6}Pipeline Flow final del Sistema.}{116}{subsection.5.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Pipeline Flow final del Sistema.\relax }}{116}{figure.caption.42}\protected@file@percent }
\newlabel{fig:Pipeline_Final}{{5.7}{116}{Pipeline Flow final del Sistema.\relax }{figure.caption.42}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7}Conclusiones.}{117}{subsection.5.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.8}Caso de Uso.}{118}{subsection.5.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.9}Limitaciones del sistema.}{119}{subsection.5.9}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Próximos pasos.}{120}{section.6}\protected@file@percent }
\citation{ANN_22}
\citation{ANN_22}
\citation{ANN_22}
\citation{ANN_22}
\@writefile{toc}{\contentsline {section}{\numberline {7}Anexos.}{121}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Funciones de activación.}{121}{subsection.7.1}\protected@file@percent }
\newlabel{anexo_func_activ}{{7.1}{121}{Funciones de activación}{subsection.7.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces Funciones de activación más comunes\cite  {ANN_22}.\relax }}{121}{figure.caption.43}\protected@file@percent }
\newlabel{fig:ann_7}{{7.1}{121}{Funciones de activación más comunes\cite {ANN_22}.\relax }{figure.caption.43}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.2}{\ignorespaces Fórmulas y rangos de las funciones de activación más comunes.}}{121}{figure.caption.44}\protected@file@percent }
\newlabel{fig:ann_8}{{7.2}{121}{Fórmulas y rangos de las funciones de activación más comunes}{figure.caption.44}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Ejemplo de obtención de Word Embeddings mediante skipgram y softmax.}{122}{subsection.7.2}\protected@file@percent }
\newlabel{anexo_word_emb}{{7.2}{122}{Ejemplo de obtención de Word Embeddings mediante skipgram y softmax}{subsection.7.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.3}{\ignorespaces Armando dataset para Skipgram\relax }}{123}{figure.caption.45}\protected@file@percent }
\newlabel{fig:1_EjSkip}{{7.3}{123}{Armando dataset para Skipgram\relax }{figure.caption.45}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.4}{\ignorespaces Dataset para Skipgram\relax }}{123}{figure.caption.46}\protected@file@percent }
\newlabel{fig:2_EjSkip}{{7.4}{123}{Dataset para Skipgram\relax }{figure.caption.46}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.5}{\ignorespaces Representación en one-hot encoding para cada una de las palabras de entrada\relax }}{124}{figure.caption.47}\protected@file@percent }
\newlabel{fig:3_EjSkip}{{7.5}{124}{Representación en one-hot encoding para cada una de las palabras de entrada\relax }{figure.caption.47}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.6}{\ignorespaces Arquitectura Skipgram con V=8, N=3.\relax }}{124}{figure.caption.48}\protected@file@percent }
\newlabel{fig:4_EjSkip}{{7.6}{124}{Arquitectura Skipgram con V=8, N=3.\relax }{figure.caption.48}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.7}{\ignorespaces Primera iteración Skipgram del paso 2.\relax }}{125}{figure.caption.49}\protected@file@percent }
\newlabel{fig:5_EjSkip}{{7.7}{125}{Primera iteración Skipgram del paso 2.\relax }{figure.caption.49}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.8}{\ignorespaces Primera iteración Skipgram del paso 2 en mayor detalle.\relax }}{126}{figure.caption.50}\protected@file@percent }
\newlabel{fig:6_EjSkip}{{7.8}{126}{Primera iteración Skipgram del paso 2 en mayor detalle.\relax }{figure.caption.50}{}}
\newlabel{eq:skip_1}{{16}{126}{Ejemplo de obtención de Word Embeddings mediante skipgram y softmax}{equation.7.16}{}}
\newlabel{eq:skip_2}{{17}{127}{Ejemplo de obtención de Word Embeddings mediante skipgram y softmax}{equation.7.17}{}}
\newlabel{eq:skip_3}{{18}{127}{Ejemplo de obtención de Word Embeddings mediante skipgram y softmax}{equation.7.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.9}{\ignorespaces Segunda iteración Skipgram del paso 2 .\relax }}{127}{figure.caption.51}\protected@file@percent }
\newlabel{fig:7_EjSkip}{{7.9}{127}{Segunda iteración Skipgram del paso 2 .\relax }{figure.caption.51}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.10}{\ignorespaces Comparando \textit  {y pred softmax} con \textit  {y true}.\relax }}{128}{figure.caption.52}\protected@file@percent }
\newlabel{fig:8_EjSkip}{{7.10}{128}{Comparando \textit {y pred softmax} con \textit {y true}.\relax }{figure.caption.52}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.11}{\ignorespaces Matriz $W’$ de embeddings objetivo.\relax }}{129}{figure.caption.53}\protected@file@percent }
\newlabel{fig:9_EjSkip}{{7.11}{129}{Matriz $W’$ de embeddings objetivo.\relax }{figure.caption.53}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Palabras repetidas en nuestro Corpus y palabras polisémicas.}{130}{subsection.7.3}\protected@file@percent }
\newlabel{anexo_polisem}{{7.3}{130}{Palabras repetidas en nuestro Corpus y palabras polisémicas}{subsection.7.3}{}}
\bibcite{Similarity_calculation}{1}
\bibcite{jobs_future}{2}
\bibcite{wmd_paper}{3}
\bibcite{similarity_survey}{4}
\bibcite{cosine_sim_1}{5}
\bibcite{cosine_sim_2}{6}
\bibcite{cosine_sim_3}{7}
\bibcite{seleccion_reclutamiento_1}{8}
\bibcite{seleccion_reclutamiento_2}{9}
\bibcite{apunte_uba}{10}
\bibcite{estudio_eye_tracking}{11}
\bibcite{trabajos_relacionados_1}{12}
\bibcite{trabajos_relacionados_2}{13}
\bibcite{ontology_mapping}{14}
\bibcite{trabajos_relacionados_3}{15}
\bibcite{trabajos_relacionados_4}{16}
\bibcite{trabajos_relacionados_5}{17}
\bibcite{trabajos_relacionados_6}{18}
\bibcite{trabajos_relacionados_7}{19}
\bibcite{trabajos_relacionados_8}{20}
\bibcite{trabajos_relacionados_9}{21}
\bibcite{trabajos_relacionados_10}{22}
\bibcite{trabajos_relacionados_11}{23}
\bibcite{trabajos_relacionados_12}{24}
\bibcite{trabajos_relacionados_13}{25}
\bibcite{trabajos_relacionados_14}{26}
\bibcite{trabajos_relacionados_15}{27}
\bibcite{sistema_recomendacion}{28}
\bibcite{intro_algos_ML}{29}
\bibcite{aprendiz_transd}{30}
\bibcite{cross_validation}{31}
\bibcite{preprocessing}{32}
\bibcite{metrics_clustering_1}{33}
\bibcite{metrics_clustering_2}{34}
\bibcite{metrics_clasification}{35}
\bibcite{metrics_regression}{36}
\bibcite{over_and_under}{37}
\bibcite{KNN_limitacion}{38}
\bibcite{KNN_Ejemplo}{39}
\bibcite{K_means_experiment}{40}
\bibcite{K_means_elbow}{41}
\bibcite{K_means_review}{42}
\bibcite{K_means_initial_centroids}{43}
\bibcite{K_means_plus_plus}{44}
\bibcite{ANN_21}{45}
\bibcite{ANN_22}{46}
\bibcite{ANN_23}{47}
\bibcite{ANN_24}{48}
\bibcite{ANN_25}{49}
\bibcite{NLP_1}{50}
\bibcite{NLP_2}{51}
\bibcite{NLP_3_4}{52}
\bibcite{NLP_5}{53}
\bibcite{NLP_6}{54}
\bibcite{NLP_7}{55}
\bibcite{NLP_8}{56}
\bibcite{NLP_9}{57}
\bibcite{NLP_10}{58}
\bibcite{NLP_11}{59}
\bibcite{NLP_12}{60}
\bibcite{NLP_13}{61}
\bibcite{NLP_13_2}{62}
\bibcite{NLP_14}{63}
\bibcite{NLP_15}{64}
\bibcite{NLP_16}{65}
\bibcite{NLP_17_18}{66}
\bibcite{NLP_19}{67}
\bibcite{NLP_20}{68}
\bibcite{NLP_21}{69}
\bibcite{NLP_26}{70}
\bibcite{NLP_27}{71}
\bibcite{NLP_28}{72}
\bibcite{WMD_2}{73}
\bibcite{WMD_3}{74}
\bibcite{WMD_4}{75}
\bibcite{WMD_5}{76}
