\relax 
\providecommand\hyper@newdestlabel[2]{}
\@nameuse{bbl@beforestart}
\catcode `"\active 
\catcode `<\active 
\catcode `>\active 
\@nameuse{es@quoting}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:undav-logo}{{\caption@xref {fig:undav-logo}{ on input line 130}}{1}{}{figure.caption.1}{}}
\babel@aux{spanish}{}
\citation{trabajos_relacionados_1}
\citation{trabajos_relacionados_2}
\citation{trabajos_relacionados_3}
\citation{trabajos_relacionados_4}
\citation{trabajos_relacionados_5}
\citation{trabajos_relacionados_6}
\citation{trabajos_relacionados_7}
\citation{trabajos_relacionados_8}
\citation{trabajos_relacionados_9}
\citation{trabajos_relacionados_10}
\citation{trabajos_relacionados_11}
\citation{trabajos_relacionados_12}
\citation{trabajos_relacionados_13}
\citation{trabajos_relacionados_14}
\citation{trabajos_relacionados_15}
\citation{jobs_future}
\citation{jobs_future}
\citation{jobs_future}
\citation{jobs_future}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introducción.}{7}{section.1}\protected@file@percent }
\newlabel{Intro}{{1}{7}{Introducción}{section.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Top 20 demanda de roles laborales en aumento y disminución para el año 2020, por participación de las empresas encuestadas por el \textit  {Foro Económico Mundial}\cite  {jobs_future}.\relax }}{7}{figure.caption.3}\protected@file@percent }
\newlabel{fig:Increasing_Jobs}{{1.1}{7}{Top 20 demanda de roles laborales en aumento y disminución para el año 2020, por participación de las empresas encuestadas por el \textit {Foro Económico Mundial}\cite {jobs_future}.\relax }{figure.caption.3}{}}
\citation{Similarity_calculation}
\citation{Similarity_calculation}
\citation{Similarity_calculation}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Porcentaje de tareas realizadas por humanos frente a máquinas, 2020 y 2025 (previsto), por participación de las empresas encuestadas por el \textit  {Foro Económico Mundial}\cite  {jobs_future}.\relax }}{8}{figure.caption.4}\protected@file@percent }
\newlabel{fig:Automatizacion}{{1.2}{8}{Porcentaje de tareas realizadas por humanos frente a máquinas, 2020 y 2025 (previsto), por participación de las empresas encuestadas por el \textit {Foro Económico Mundial}\cite {jobs_future}.\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Algoritmos y técnicas utilizadas.}{9}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Objetivos del Proyecto.}{10}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}Objetivo general.}{10}{subsubsection.1.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.2}Objetivos específicos.}{10}{subsubsection.1.2.2}\protected@file@percent }
\newlabel{Obj_especif}{{1.2.2}{10}{Objetivos específicos}{subsubsection.1.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Alcance del Proyecto.}{11}{subsection.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Organización.}{11}{subsection.1.4}\protected@file@percent }
\newlabel{organizacion}{{1.4}{11}{Organización}{subsection.1.4}{}}
\citation{seleccion_reclutamiento_2}
\citation{seleccion_reclutamiento_2}
\@writefile{toc}{\contentsline {section}{\numberline {2}Reclutamiento y selección laboral.}{13}{section.2}\protected@file@percent }
\newlabel{2.ReclutamientolaboralenIT}{{2}{13}{Reclutamiento y selección laboral}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Introducción.}{13}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Reclutamiento vs selección.}{13}{subsection.2.2}\protected@file@percent }
\newlabel{SeleccionYReclutamiento}{{2.2}{13}{Reclutamiento vs selección}{subsection.2.2}{}}
\citation{seleccion_reclutamiento_2}
\citation{seleccion_reclutamiento_2}
\citation{trabajos_relacionados_10}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Evolución de los procesos de reclutamiento y selección laboral.}{15}{subsection.2.3}\protected@file@percent }
\citation{estudio_eye_tracking}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Cribado o screening.}{16}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1}Screening manual vs screening automatizado}{16}{subsubsection.2.4.1}\protected@file@percent }
\citation{seleccion_reclutamiento_1}
\citation{seleccion_reclutamiento_1}
\citation{trabajos_relacionados_1}
\citation{trabajos_relacionados_2}
\citation{ontology_mapping}
\citation{trabajos_relacionados_3}
\citation{trabajos_relacionados_4}
\citation{trabajos_relacionados_5}
\citation{trabajos_relacionados_6}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Sistemas de screening: Estado del arte.}{17}{subsection.2.5}\protected@file@percent }
\newlabel{Estado_del_arte}{{2.5}{17}{Sistemas de screening: Estado del arte}{subsection.2.5}{}}
\citation{trabajos_relacionados_7}
\citation{trabajos_relacionados_8}
\citation{trabajos_relacionados_9}
\citation{trabajos_relacionados_10}
\citation{trabajos_relacionados_11}
\citation{trabajos_relacionados_12}
\citation{trabajos_relacionados_13}
\citation{sistema_recomendacion}
\citation{trabajos_relacionados_14}
\citation{trabajos_relacionados_15}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Enfoque del Proyecto.}{19}{subsection.2.6}\protected@file@percent }
\citation{intro_algos_ML}
\citation{apunte_uba}
\@writefile{toc}{\contentsline {section}{\numberline {3}Algoritmos de Machine Learning.}{20}{section.3}\protected@file@percent }
\newlabel{3.AlgoritmosdeMachineLearning}{{3}{20}{Algoritmos de Machine Learning}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Introducción.}{20}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Machine Learning (ML).}{20}{subsection.3.2}\protected@file@percent }
\citation{intro_clasificacion_ML}
\citation{intro_clasificacion_ML}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Aprendizaje supervisado y no supervisado.}{21}{subsubsection.3.2.1}\protected@file@percent }
\citation{apunte_uba}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Tipos de aprendizaje en ML}}{22}{figure.caption.5}\protected@file@percent }
\newlabel{fig:Clasif_algoritmos}{{3.1}{22}{Tipos de aprendizaje en ML}{figure.caption.5}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.2.1.1}Regresión.}{22}{paragraph.3.2.1.1}\protected@file@percent }
\citation{apunte_uba}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.2.1.2}Clasificación.}{23}{paragraph.3.2.1.2}\protected@file@percent }
\newlabel{clasificacion}{{3.2.1.2}{23}{Clasificación}{paragraph.3.2.1.2}{}}
\citation{apunte_uba}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.2.1.3}Agrupación (clustering).}{24}{paragraph.3.2.1.3}\protected@file@percent }
\newlabel{agrupacion}{{3.2.1.3}{24}{Agrupación (clustering)}{paragraph.3.2.1.3}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.2.1.4}Algoritmos más conocidos.}{25}{paragraph.3.2.1.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Algoritmos de machine learning más conocidos\relax }}{25}{figure.caption.6}\protected@file@percent }
\newlabel{fig:Diagrama_algoritmos}{{3.2}{25}{Algoritmos de machine learning más conocidos\relax }{figure.caption.6}{}}
\citation{aprendiz_transd}
\citation{apunte_uba}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Aprendizaje transductivo}{26}{subsubsection.3.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Aprendizaje transductivo\relax }}{26}{figure.caption.7}\protected@file@percent }
\newlabel{fig:Transductivo_1}{{3.3}{26}{Aprendizaje transductivo\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Aprendizaje transductivo\relax }}{26}{figure.caption.8}\protected@file@percent }
\newlabel{fig:Transductivo_2}{{3.4}{26}{Aprendizaje transductivo\relax }{figure.caption.8}{}}
\citation{apunte_uba}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}Separación de los datos.}{27}{subsubsection.3.2.3}\protected@file@percent }
\newlabel{Separacion datos}{{3.2.3}{27}{Separación de los datos}{subsubsection.3.2.3}{}}
\citation{preprocessing}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.4}¿Cómo implementar un modelo de ML?}{28}{subsubsection.3.2.4}\protected@file@percent }
\newlabel{implementar_mod_ML}{{3.2.4}{28}{¿Cómo implementar un modelo de ML?}{subsubsection.3.2.4}{}}
\citation{apunte_uba}
\citation{metrics_clustering_1}
\citation{metrics_clustering_2}
\citation{metrics_clasification}
\citation{metrics_regression}
\citation{metrics_clustering_1}
\citation{metrics_clustering_2}
\citation{metrics_clasification}
\citation{metrics_regression}
\citation{apunte_uba}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Métricas para evaluar distintos tipos de modelos\cite  {metrics_clustering_1, metrics_clustering_2,metrics_clasification,metrics_regression}.\relax }}{30}{table.caption.9}\protected@file@percent }
\newlabel{table:1}{{1}{30}{Métricas para evaluar distintos tipos de modelos\cite {metrics_clustering_1, metrics_clustering_2,metrics_clasification,metrics_regression}.\relax }{table.caption.9}{}}
\citation{apunte_uba}
\citation{cross_validation}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.2.4.1}Cross Validation.}{32}{paragraph.3.2.4.1}\protected@file@percent }
\newlabel{Cross Validation}{{3.2.4.1}{32}{Cross Validation}{paragraph.3.2.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces k-fold Cross Validation.}}{32}{figure.caption.10}\protected@file@percent }
\newlabel{fig:cross_val}{{3.5}{32}{k-fold Cross Validation}{figure.caption.10}{}}
\citation{apunte_uba}
\citation{apunte_uba}
\citation{over_and_under}
\citation{apunte_uba}
\citation{apunte_uba}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.2.4.2}Los Problemas de ML: Overfitting y Underfitting.}{33}{paragraph.3.2.4.2}\protected@file@percent }
\newlabel{Over_y_under}{{3.2.4.2}{33}{Los Problemas de ML: Overfitting y Underfitting}{paragraph.3.2.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Overfitting y Underfitting\cite  {apunte_uba}\relax }}{33}{figure.caption.11}\protected@file@percent }
\newlabel{fig:fitting}{{3.6}{33}{Overfitting y Underfitting\cite {apunte_uba}\relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}K-Nearest Neighbor (KNN).}{34}{subsection.3.3}\protected@file@percent }
\newlabel{knn_teoria}{{3.3}{34}{K-Nearest Neighbor (KNN)}{subsection.3.3}{}}
\citation{KNN_limitacion}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Principal limitación KNN.}{35}{subsubsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Funcionamiento y ejemplo de KNN.}{35}{subsubsection.3.3.2}\protected@file@percent }
\citation{KNN_Ejemplo}
\citation{apunte_uba}
\citation{apunte_uba}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.3}Métrica de distancia a emplear.}{36}{subsubsection.3.3.3}\protected@file@percent }
\newlabel{metrica_dist_emp}{{3.3.3}{36}{Métrica de distancia a emplear}{subsubsection.3.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Distancia Manhattan vs Distancia Euclidiana\cite  {apunte_uba}.\relax }}{36}{figure.caption.12}\protected@file@percent }
\newlabel{fig:Man_euc}{{3.7}{36}{Distancia Manhattan vs Distancia Euclidiana\cite {apunte_uba}.\relax }{figure.caption.12}{}}
\citation{KNN_Ejemplo}
\citation{KNN_Ejemplo}
\citation{KNN_Ejemplo}
\citation{KNN_Ejemplo}
\citation{KNN_Ejemplo}
\citation{KNN_Ejemplo}
\citation{KNN_Ejemplo}
\citation{KNN_Ejemplo}
\newlabel{eq:ecuacion_1}{{1}{37}{Métrica de distancia a emplear}{equation.3.1}{}}
\newlabel{eq:ecuacion_2}{{2}{37}{Métrica de distancia a emplear}{equation.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Distancia Euclidiana en 2 dimensiones.\relax }}{37}{figure.caption.13}\protected@file@percent }
\newlabel{fig:KNN_2_Dim}{{3.8}{37}{Distancia Euclidiana en 2 dimensiones.\relax }{figure.caption.13}{}}
\newlabel{eq:ecuacion_3}{{3}{37}{Métrica de distancia a emplear}{equation.3.3}{}}
\citation{apunte_uba}
\citation{apunte_uba}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.4}Eligiendo el valor de k: overfitting y underfitting.}{38}{subsubsection.3.3.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces KNN con k = 1. \cite  {apunte_uba}\relax }}{38}{figure.caption.14}\protected@file@percent }
\newlabel{fig:KNN_k_1}{{3.9}{38}{KNN con k = 1. \cite {apunte_uba}\relax }{figure.caption.14}{}}
\citation{apunte_uba}
\citation{apunte_uba}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces KNN con k = 5. \cite  {apunte_uba}\relax }}{39}{figure.caption.15}\protected@file@percent }
\newlabel{fig:KNN_k_5}{{3.10}{39}{KNN con k = 5. \cite {apunte_uba}\relax }{figure.caption.15}{}}
\citation{K_means_review}
\citation{K_means_experiment}
\citation{K_means_experiment}
\citation{K_means_experiment}
\citation{K_means_experiment}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}K-means.}{40}{subsection.3.4}\protected@file@percent }
\newlabel{k_means_3_4}{{3.4}{40}{K-means}{subsection.3.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.1}Funcionamiento y ejemplo de K-means.}{40}{subsubsection.3.4.1}\protected@file@percent }
\newlabel{K_means_funcionamiento}{{3.4.1}{40}{Funcionamiento y ejemplo de K-means}{subsubsection.3.4.1}{}}
\newlabel{eq:ecuacion_4}{{4}{40}{Funcionamiento y ejemplo de K-means}{equation.3.4}{}}
\newlabel{eq:ecuacion_5}{{5}{41}{Funcionamiento y ejemplo de K-means}{equation.3.5}{}}
\citation{K_means_experiment}
\citation{K_means_elbow}
\citation{K_means_elbow}
\citation{K_means_elbow}
\citation{K_means_elbow}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2}Objetivo de k-means y su función de coste.}{42}{subsubsection.3.4.2}\protected@file@percent }
\newlabel{eq:ecuacion_6}{{6}{42}{Objetivo de k-means y su función de coste}{equation.3.6}{}}
\newlabel{eq:ecuacion_7}{{7}{42}{Objetivo de k-means y su función de coste}{equation.3.7}{}}
\citation{K_means_review}
\citation{K_means_review}
\citation{K_means_experiment}
\citation{K_means_initial_centroids}
\citation{K_means_plus_plus}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.3}Limitaciones K-means.}{44}{subsubsection.3.4.3}\protected@file@percent }
\newlabel{limit_kmeans}{{3.4.3}{44}{Limitaciones K-means}{subsubsection.3.4.3}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.4.3.1}Obtención del k mediante Elbow Method.}{45}{paragraph.3.4.3.1}\protected@file@percent }
\newlabel{Elbow_Met}{{3.4.3.1}{45}{Obtención del k mediante Elbow Method}{paragraph.3.4.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces Puntos de datos.\relax }}{45}{figure.caption.16}\protected@file@percent }
\newlabel{fig:Elbow_1}{{3.11}{45}{Puntos de datos.\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces Método del codo usando Inercia.\relax }}{45}{figure.caption.16}\protected@file@percent }
\newlabel{fig:Elbow_2}{{3.12}{45}{Método del codo usando Inercia.\relax }{figure.caption.16}{}}
\citation{K_means_plus_plus}
\@writefile{lof}{\contentsline {figure}{\numberline {3.13}{\ignorespaces Puntos de datos clusterizados para diferentes valores de $k$.\relax }}{46}{figure.caption.17}\protected@file@percent }
\newlabel{fig:Elbow_3}{{3.13}{46}{Puntos de datos clusterizados para diferentes valores de $k$.\relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.4.3.2}Inicialización de los centroides: k-means++.}{46}{paragraph.3.4.3.2}\protected@file@percent }
\newlabel{k_means_plus_plus}{{3.4.3.2}{46}{Inicialización de los centroides: k-means++}{paragraph.3.4.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.14}{\ignorespaces Inicialización de centroides mediante K-means.\relax }}{47}{figure.caption.18}\protected@file@percent }
\newlabel{fig:K_means_plus_plus}{{3.14}{47}{Inicialización de centroides mediante K-means.\relax }{figure.caption.18}{}}
\citation{ANN_21}
\citation{apunte_uba}
\citation{ANN_21}
\citation{ANN_22}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Redes Neuronales Artificiales (ANN).}{48}{subsection.3.5}\protected@file@percent }
\newlabel{ann_teoria}{{3.5}{48}{Redes Neuronales Artificiales (ANN)}{subsection.3.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.1}Perceptrón simple.}{48}{subsubsection.3.5.1}\protected@file@percent }
\citation{ANN_23}
\@writefile{lof}{\contentsline {figure}{\numberline {3.15}{\ignorespaces Modelo Perceptrón Simple\relax }}{49}{figure.caption.19}\protected@file@percent }
\newlabel{fig:ann_1}{{3.15}{49}{Modelo Perceptrón Simple\relax }{figure.caption.19}{}}
\newlabel{eq:ecuacion_1_ANN}{{8}{49}{Perceptrón simple}{equation.3.8}{}}
\citation{ANN_23}
\citation{ANN_24}
\citation{ANN_24}
\citation{ANN_24}
\newlabel{eq:ecuacion_2_ANN}{{9}{50}{Perceptrón simple}{equation.3.9}{}}
\newlabel{eq:ecuacion_3_ANN}{{10}{50}{Perceptrón simple}{equation.3.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.2}Desventaja del Perceptrón simple. }{50}{subsubsection.3.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.16}{\ignorespaces Perceptrones solucionando la función OR y XOR.}}{51}{figure.caption.20}\protected@file@percent }
\newlabel{fig:ann_2}{{3.16}{51}{Perceptrones solucionando la función OR y XOR}{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.3}Perceptrón multicapa (MLP).}{51}{subsubsection.3.5.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.17}{\ignorespaces Modelo Perceptrón Multicapa -MLP- (izquierda) y Perceptrón Simple (derecha).}}{52}{figure.caption.21}\protected@file@percent }
\newlabel{fig:ann_3}{{3.17}{52}{Modelo Perceptrón Multicapa -MLP- (izquierda) y Perceptrón Simple (derecha)}{figure.caption.21}{}}
\citation{ANN_25}
\citation{ANN_25}
\citation{ANN_25}
\citation{ANN_25}
\citation{ANN_25}
\citation{ANN_25}
\citation{ANN_25}
\citation{ANN_25}
\citation{ANN_25}
\newlabel{eq:ecuacion_5_ANN}{{11}{53}{Perceptrón multicapa (MLP)}{equation.3.11}{}}
\newlabel{eq:ecuacion_6_ANN}{{12}{53}{Perceptrón multicapa (MLP)}{equation.3.12}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.4}Funciones de activación en MLP.}{53}{subsubsection.3.5.4}\protected@file@percent }
\newlabel{Func_activ}{{3.5.4}{53}{Funciones de activación en MLP}{subsubsection.3.5.4}{}}
\citation{ANN_24}
\citation{ANN_24}
\citation{ANN_24}
\citation{ANN_24}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.5.4.1}Softmax en la capa de salida.}{54}{paragraph.3.5.4.1}\protected@file@percent }
\newlabel{soft_capa_salida}{{3.5.4.1}{54}{Softmax en la capa de salida}{paragraph.3.5.4.1}{}}
\newlabel{eq:ecuacion_7_ANN}{{13}{54}{Softmax en la capa de salida}{equation.3.13}{}}
\citation{ANN_25}
\citation{ANN_25}
\citation{ANN_25}
\citation{ANN_25}
\citation{ANN_25}
\citation{ANN_25}
\@writefile{lof}{\contentsline {figure}{\numberline {3.18}{\ignorespaces Función softmax aplicada a la capa de salida.}}{55}{figure.caption.22}\protected@file@percent }
\newlabel{fig:ann_4}{{3.18}{55}{Función softmax aplicada a la capa de salida}{figure.caption.22}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.5.4.2}Sigmoide en la capa de salida.}{55}{paragraph.3.5.4.2}\protected@file@percent }
\newlabel{sigm_capa_salida}{{3.5.4.2}{55}{Sigmoide en la capa de salida}{paragraph.3.5.4.2}{}}
\newlabel{eq:ecuacion_8_ANN}{{14}{55}{Sigmoide en la capa de salida}{equation.3.14}{}}
\citation{ANN_25}
\@writefile{lof}{\contentsline {figure}{\numberline {3.19}{\ignorespaces Funciones de activación escalón y sigmoide\cite  {ANN_25}.\relax }}{56}{figure.caption.23}\protected@file@percent }
\newlabel{fig:ann_5}{{3.19}{56}{Funciones de activación escalón y sigmoide\cite {ANN_25}.\relax }{figure.caption.23}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.5}Entrenamiento en una red neuronal.}{56}{subsubsection.3.5.5}\protected@file@percent }
\newlabel{entren_ann}{{3.5.5}{56}{Entrenamiento en una red neuronal}{subsubsection.3.5.5}{}}
\citation{ANN_25}
\citation{ANN_25}
\citation{ANN_25}
\citation{ANN_25}
\newlabel{eq:ecuacion_9_ANN}{{15}{57}{Entrenamiento en una red neuronal}{equation.3.15}{}}
\citation{ANN_25}
\citation{ANN_25}
\citation{ANN_25}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.5.5.1}Hiper-parámetro n.}{58}{paragraph.3.5.5.1}\protected@file@percent }
\newlabel{hiper_n}{{3.5.5.1}{58}{Hiper-parámetro n}{paragraph.3.5.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.20}{\ignorespaces Efecto de diferentes tasas de aprendizaje $n$ durante el entrenamiento\cite  {ANN_25}.\relax }}{58}{figure.caption.24}\protected@file@percent }
\newlabel{fig:ann_6}{{3.20}{58}{Efecto de diferentes tasas de aprendizaje $n$ durante el entrenamiento\cite {ANN_25}.\relax }{figure.caption.24}{}}
\citation{NLP_1}
\citation{NLP_2}
\citation{NLP_3_4}
\citation{NLP_3_4}
\@writefile{toc}{\contentsline {section}{\numberline {4}Natural Language Processing.}{59}{section.4}\protected@file@percent }
\newlabel{4.NaturalLanguageProcessing}{{4}{59}{Natural Language Processing}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Introducción.}{59}{subsection.4.1}\protected@file@percent }
\newlabel{Intro_NLP}{{4.1}{59}{Introducción}{subsection.4.1}{}}
\citation{NLP_5}
\citation{NLP_6}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Aplicaciones NLP.}{60}{subsection.4.2}\protected@file@percent }
\newlabel{Aplicaciones_NLP}{{4.2}{60}{Aplicaciones NLP}{subsection.4.2}{}}
\citation{Similarity_calculation}
\citation{NLP_2}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}NLP en la práctica.}{62}{subsection.4.3}\protected@file@percent }
\newlabel{Practica_NLP}{{4.3}{62}{NLP en la práctica}{subsection.4.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Pasos generales de nuestro proceso NLP.\relax }}{62}{figure.caption.25}\protected@file@percent }
\newlabel{fig:Imagen_NLP_1}{{4.1}{62}{Pasos generales de nuestro proceso NLP.\relax }{figure.caption.25}{}}
\citation{preprocessing}
\citation{NLP_2}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Preprocesamiento de textos.}{63}{subsection.4.4}\protected@file@percent }
\newlabel{Proces_textos}{{4.4}{63}{Preprocesamiento de textos}{subsection.4.4}{}}
\citation{NLP_2}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.1}Limpieza y normalización.}{64}{subsubsection.4.4.1}\protected@file@percent }
\newlabel{Limpieza_y_norm}{{4.4.1}{64}{Limpieza y normalización}{subsubsection.4.4.1}{}}
\citation{NLP_2}
\citation{NLP_2}
\citation{NLP_2}
\citation{NLP_2}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.2}Tokenización.}{65}{subsubsection.4.4.2}\protected@file@percent }
\newlabel{tokenizacion}{{4.4.2}{65}{Tokenización}{subsubsection.4.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Tokenización por palabras\cite  {NLP_2}.\relax }}{65}{figure.caption.26}\protected@file@percent }
\newlabel{fig:Imagen_NLP_2}{{4.2}{65}{Tokenización por palabras\cite {NLP_2}.\relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Tokenización por carácteres\cite  {NLP_2}.\relax }}{65}{figure.caption.27}\protected@file@percent }
\newlabel{fig:Imagen_NLP_3}{{4.3}{65}{Tokenización por carácteres\cite {NLP_2}.\relax }{figure.caption.27}{}}
\citation{NLP_2}
\citation{NLP_2}
\citation{NLP_2}
\citation{NLP_2}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.3}Stemming y lemmatization.}{66}{subsubsection.4.4.3}\protected@file@percent }
\newlabel{stem_y_lem}{{4.4.3}{66}{Stemming y lemmatization}{subsubsection.4.4.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Stemming\cite  {NLP_2}.\relax }}{66}{figure.caption.28}\protected@file@percent }
\newlabel{fig:Imagen_NLP_4}{{4.4}{66}{Stemming\cite {NLP_2}.\relax }{figure.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Lemmatization\cite  {NLP_2}.\relax }}{66}{figure.caption.29}\protected@file@percent }
\newlabel{fig:Imagen_NLP_5}{{4.5}{66}{Lemmatization\cite {NLP_2}.\relax }{figure.caption.29}{}}
\citation{NLP_2}
\citation{NLP_7}
\citation{NLP_2}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.4}N-grams.}{67}{subsubsection.4.4.4}\protected@file@percent }
\newlabel{ngrams}{{4.4.4}{67}{N-grams}{subsubsection.4.4.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Obtención de representaciones vectoriales.}{67}{subsection.4.5}\protected@file@percent }
\newlabel{rep_vect}{{4.5}{67}{Obtención de representaciones vectoriales}{subsection.4.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.1}Bag of Words (BoW).}{68}{subsubsection.4.5.1}\protected@file@percent }
\newlabel{bow}{{4.5.1}{68}{Bag of Words (BoW)}{subsubsection.4.5.1}{}}
\newlabel{eq:ecuacion_1_NLP}{{16}{68}{Bag of Words (BoW)}{equation.4.16}{}}
\citation{NLP_8}
\citation{NLP_8}
\citation{NLP_8}
\citation{NLP_8}
\citation{NLP_2}
\citation{NLP_2}
\citation{NLP_2}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Representación mediante BoW.   Ejemplo obtenido de \cite  {NLP_8}.\relax }}{69}{table.caption.30}\protected@file@percent }
\newlabel{table:bow_1}{{2}{69}{Representación mediante BoW. \\ Ejemplo obtenido de \cite {NLP_8}.\relax }{table.caption.30}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Representación binaria mediante BoW.  Ejemplo obtenido de \cite  {NLP_8}.\relax }}{69}{table.caption.31}\protected@file@percent }
\newlabel{table:bow_2}{{3}{69}{Representación binaria mediante BoW.\\ Ejemplo obtenido de \cite {NLP_8}.\relax }{table.caption.31}{}}
\citation{NLP_7}
\citation{NLP_2}
\citation{apunte_uba}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Representación mediante BoW.  Ejemplo obtenido de \cite  {NLP_2}.\relax }}{70}{table.caption.32}\protected@file@percent }
\newlabel{table:bow_3}{{4}{70}{Representación mediante BoW.\\ Ejemplo obtenido de \cite {NLP_2}.\relax }{table.caption.32}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.2}TF-IDF.}{70}{subsubsection.4.5.2}\protected@file@percent }
\newlabel{tf_idf}{{4.5.2}{70}{TF-IDF}{subsubsection.4.5.2}{}}
\newlabel{eq:ecuacion_2_NLP}{{17}{70}{TF-IDF}{equation.4.17}{}}
\citation{NLP_2}
\citation{NLP_2}
\citation{NLP_2}
\citation{NLP_2}
\citation{NLP_2}
\citation{NLP_2}
\citation{NLP_7}
\newlabel{eq:ecuacion_3_NLP}{{18}{71}{TF-IDF}{equation.4.18}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Cálculos de \textbf  {TF} para nuestro set de documentos $d$\cite  {NLP_2}.\relax }}{71}{table.caption.33}\protected@file@percent }
\newlabel{table:tf_idf_1}{{5}{71}{Cálculos de \textbf {TF} para nuestro set de documentos $d$\cite {NLP_2}.\relax }{table.caption.33}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Cálculos de \textbf  {IDF} para nuestro set de documentos $d$\cite  {NLP_2}.\relax }}{71}{table.caption.34}\protected@file@percent }
\newlabel{table:tf_idf_2}{{6}{71}{Cálculos de \textbf {IDF} para nuestro set de documentos $d$\cite {NLP_2}.\relax }{table.caption.34}{}}
\citation{NLP_26}
\citation{NLP_2}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Representación mediante \textbf  {TF-IDF}\cite  {NLP_2}.\relax }}{72}{table.caption.35}\protected@file@percent }
\newlabel{table:tf_idf_3}{{7}{72}{Representación mediante \textbf {TF-IDF}\cite {NLP_2}.\relax }{table.caption.35}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.3}Desventajas BoW \& TF-IDF.}{72}{subsubsection.4.5.3}\protected@file@percent }
\newlabel{desv_bow_tfidf}{{4.5.3}{72}{Desventajas BoW \& TF-IDF}{subsubsection.4.5.3}{}}
\citation{NLP_26}
\citation{NLP_9}
\citation{apunte_uba}
\citation{NLP_10}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.4}Word embeddings.}{73}{subsubsection.4.5.4}\protected@file@percent }
\newlabel{word_emb}{{4.5.4}{73}{Word embeddings}{subsubsection.4.5.4}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.5.4.1}Embeddings.}{73}{paragraph.4.5.4.1}\protected@file@percent }
\newlabel{embedd}{{4.5.4.1}{73}{Embeddings}{paragraph.4.5.4.1}{}}
\citation{NLP_26}
\citation{NLP_26}
\citation{NLP_28}
\citation{NLP_28}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces  Ejemplo de embedding de 2 dimensiones \cite  {NLP_28}.\relax }}{74}{figure.caption.36}\protected@file@percent }
\newlabel{fig:Imagen_NLP_12}{{4.6}{74}{Ejemplo de embedding de 2 dimensiones \cite {NLP_28}.\relax }{figure.caption.36}{}}
\citation{NLP_11}
\citation{datitos_nlp}
\citation{datitos_nlp}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.5.4.2}Word2vec.}{75}{paragraph.4.5.4.2}\protected@file@percent }
\newlabel{word2vec}{{4.5.4.2}{75}{Word2vec}{paragraph.4.5.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Ejemplo de Word embeddings (1)\cite  {datitos_nlp}.\relax }}{75}{figure.caption.37}\protected@file@percent }
\newlabel{fig:Imagen_NLP_13}{{4.7}{75}{Ejemplo de Word embeddings (1)\cite {datitos_nlp}.\relax }{figure.caption.37}{}}
\citation{datitos_nlp}
\citation{datitos_nlp}
\citation{NLP_12}
\citation{NLP_13}
\citation{wmd_paper}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Ejemplo de Word embeddings (2)\cite  {datitos_nlp}.\relax }}{76}{figure.caption.38}\protected@file@percent }
\newlabel{fig:Imagen_NLP_14}{{4.8}{76}{Ejemplo de Word embeddings (2)\cite {datitos_nlp}.\relax }{figure.caption.38}{}}
\citation{NLP_26}
\citation{NLP_26}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.5.4.3}¿Cómo obtener nuestros Word embeddings?}{77}{paragraph.4.5.4.3}\protected@file@percent }
\newlabel{obt_word_emb}{{4.5.4.3}{77}{¿Cómo obtener nuestros Word embeddings?}{paragraph.4.5.4.3}{}}
\citation{NLP_11}
\citation{NLP_27}
\citation{NLP_27}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.5.4.4}CBOW vs Skipgram.}{78}{paragraph.4.5.4.4}\protected@file@percent }
\newlabel{cbow_vs_skip}{{4.5.4.4}{78}{CBOW vs Skipgram}{paragraph.4.5.4.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Skipgram y CBOW\cite  {NLP_27}.\relax }}{78}{figure.caption.39}\protected@file@percent }
\newlabel{fig:Imagen_NLP_15}{{4.9}{78}{Skipgram y CBOW\cite {NLP_27}.\relax }{figure.caption.39}{}}
\citation{NLP_27}
\citation{NLP_27}
\citation{NLP_27}
\citation{NLP_27}
\citation{NLP_26}
\citation{NLP_27}
\citation{NLP_27}
\citation{NLP_27}
\citation{NLP_27}
\newlabel{eq:ecuacion_4_NLP}{{19}{79}{CBOW vs Skipgram}{equation.4.19}{}}
\citation{NLP_11}
\citation{NLP_9}
\newlabel{eq:ecuacion_8_NLP}{{20}{80}{CBOW vs Skipgram}{equation.4.20}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.5.4.5}One hot encoding.}{80}{paragraph.4.5.4.5}\protected@file@percent }
\newlabel{one_hot_enc}{{4.5.4.5}{80}{One hot encoding}{paragraph.4.5.4.5}{}}
\citation{NLP_28}
\citation{NLP_28}
\citation{NLP_28}
\citation{NLP_28}
\citation{NLP_28}
\citation{NLP_28}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces One Hot Encoding (1)\cite  {NLP_28}.\relax }}{81}{figure.caption.40}\protected@file@percent }
\newlabel{fig:Imagen_NLP_16}{{4.10}{81}{One Hot Encoding (1)\cite {NLP_28}.\relax }{figure.caption.40}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces One Hot Encoding (2)\cite  {NLP_28}.\relax }}{81}{figure.caption.40}\protected@file@percent }
\newlabel{fig:Imagen_NLP_17}{{4.11}{81}{One Hot Encoding (2)\cite {NLP_28}.\relax }{figure.caption.40}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.12}{\ignorespaces One Hot Encoding (3)\cite  {NLP_28}.\relax }}{81}{figure.caption.41}\protected@file@percent }
\newlabel{fig:Imagen_NLP_18}{{4.12}{81}{One Hot Encoding (3)\cite {NLP_28}.\relax }{figure.caption.41}{}}
\citation{NLP_26}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.5.4.6}Obteniendo nuestros Word embeddings con Skipgram.}{82}{paragraph.4.5.4.6}\protected@file@percent }
\newlabel{obt_skip}{{4.5.4.6}{82}{Obteniendo nuestros Word embeddings con Skipgram}{paragraph.4.5.4.6}{}}
\citation{NLP_26}
\citation{NLP_26}
\@writefile{lof}{\contentsline {figure}{\numberline {4.13}{\ignorespaces Skipgram: dada la palabra central se predicen las palabras de contexto.\relax }}{83}{figure.caption.42}\protected@file@percent }
\newlabel{fig:Imagen_NLP_19}{{4.13}{83}{Skipgram: dada la palabra central se predicen las palabras de contexto.\relax }{figure.caption.42}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.14}{\ignorespaces Skipgram: próxima iteración.\relax }}{83}{figure.caption.43}\protected@file@percent }
\newlabel{fig:Imagen_NLP_20}{{4.14}{83}{Skipgram: próxima iteración.\relax }{figure.caption.43}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.15}{\ignorespaces Preparando nuestro dataset para Skipgram (con $C$ = 2)\cite  {NLP_26}.\relax }}{84}{figure.caption.44}\protected@file@percent }
\newlabel{fig:Imagen_NLP_21}{{4.15}{84}{Preparando nuestro dataset para Skipgram (con $C$ = 2)\cite {NLP_26}.\relax }{figure.caption.44}{}}
\citation{NLP_26}
\citation{NLP_26}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.5.4.7}Arquitectura del modelo Skipgram.}{85}{paragraph.4.5.4.7}\protected@file@percent }
\newlabel{skipgram}{{4.5.4.7}{85}{Arquitectura del modelo Skipgram}{paragraph.4.5.4.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.16}{\ignorespaces Arquitectura básica Skipgram\cite  {NLP_26}.\relax }}{85}{figure.caption.45}\protected@file@percent }
\newlabel{fig:Imagen_NLP_22}{{4.16}{85}{Arquitectura básica Skipgram\cite {NLP_26}.\relax }{figure.caption.45}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.17}{\ignorespaces Arquitectura Skipgram con $V=8$, $N=3$, $C=1$.\relax }}{86}{figure.caption.46}\protected@file@percent }
\newlabel{fig:Imagen_NLP_23}{{4.17}{86}{Arquitectura Skipgram con $V=8$, $N=3$, $C=1$.\relax }{figure.caption.46}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.5.4.8}Entrenamiento y función de costo con Softmax.}{87}{paragraph.4.5.4.8}\protected@file@percent }
\newlabel{ent_costo_softmax}{{4.5.4.8}{87}{Entrenamiento y función de costo con Softmax}{paragraph.4.5.4.8}{}}
\citation{NLP_11}
\citation{NLP_27}
\citation{NLP_27}
\citation{NLP_27}
\citation{NLP_27}
\newlabel{eq:ecuacion_10_NLP}{{21}{89}{Entrenamiento y función de costo con Softmax}{equation.4.21}{}}
\citation{NLP_27}
\citation{NLP_27}
\citation{NLP_27}
\citation{NLP_27}
\citation{NLP_27}
\citation{NLP_27}
\citation{NLP_27}
\citation{NLP_27}
\citation{NLP_27}
\citation{NLP_27}
\citation{NLP_27}
\citation{NLP_27}
\newlabel{eq:ecuacion_11_NLP}{{22}{90}{Entrenamiento y función de costo con Softmax}{equation.4.22}{}}
\newlabel{eq:ecuacion_12_NLP}{{23}{90}{Entrenamiento y función de costo con Softmax}{equation.4.23}{}}
\newlabel{eq:ecuacion_15_NLP}{{24}{90}{Entrenamiento y función de costo con Softmax}{equation.4.24}{}}
\citation{NLP_14}
\citation{NLP_13_2}
\citation{datitos_nlp}
\citation{datitos_nlp}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.5.4.9}Optimizaciones: Muestreo Negativo.}{91}{paragraph.4.5.4.9}\protected@file@percent }
\newlabel{neg_samp}{{4.5.4.9}{91}{Optimizaciones: Muestreo Negativo}{paragraph.4.5.4.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.18}{\ignorespaces Comparación Skipgram con distintas funciones de salida: softmax (izquierda) y sigmoide (derecha)\cite  {datitos_nlp}.\relax }}{91}{figure.caption.47}\protected@file@percent }
\newlabel{fig:Imagen_NLP_24}{{4.18}{91}{Comparación Skipgram con distintas funciones de salida: softmax (izquierda) y sigmoide (derecha)\cite {datitos_nlp}.\relax }{figure.caption.47}{}}
\citation{NLP_27}
\citation{NLP_27}
\citation{NLP_27}
\citation{NLP_27}
\citation{NLP_27}
\citation{NLP_27}
\citation{NLP_27}
\citation{NLP_27}
\citation{datitos_nlp}
\citation{datitos_nlp}
\citation{datitos_nlp}
\citation{datitos_nlp}
\newlabel{eq:ecuacion_17_NLP}{{25}{92}{Optimizaciones: Muestreo Negativo}{equation.4.25}{}}
\newlabel{eq:ecuacion_18_NLP}{{26}{92}{Optimizaciones: Muestreo Negativo}{equation.4.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.19}{\ignorespaces Armando el datasets para distintas funciones de salida: softmax (izquierda), sigmoide (derecha)\cite  {datitos_nlp}.\relax }}{92}{figure.caption.48}\protected@file@percent }
\newlabel{fig:Imagen_NLP_25}{{4.19}{92}{Armando el datasets para distintas funciones de salida: softmax (izquierda), sigmoide (derecha)\cite {datitos_nlp}.\relax }{figure.caption.48}{}}
\citation{NLP_27}
\citation{NLP_27}
\citation{NLP_27}
\citation{NLP_27}
\@writefile{lof}{\contentsline {figure}{\numberline {4.20}{\ignorespaces Armando el datasets para función de salida sigmoide usando negative sampling\cite  {datitos_nlp}.\relax }}{93}{figure.caption.49}\protected@file@percent }
\newlabel{fig:Imagen_NLP_26}{{4.20}{93}{Armando el datasets para función de salida sigmoide usando negative sampling\cite {datitos_nlp}.\relax }{figure.caption.49}{}}
\newlabel{eq:ecuacion_19_NLP}{{27}{93}{Optimizaciones: Muestreo Negativo}{equation.4.27}{}}
\citation{datitos_nlp}
\citation{datitos_nlp}
\citation{datitos_nlp}
\citation{datitos_nlp}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.5.4.10}Entrenamiento y función de costo con Sigmoide.}{94}{paragraph.4.5.4.10}\protected@file@percent }
\newlabel{ent_costo_sigmoide}{{4.5.4.10}{94}{Entrenamiento y función de costo con Sigmoide}{paragraph.4.5.4.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.21}{\ignorespaces Primer paso entrenamiento Word2vec con función de salida sigmoide y utilizando negative sampling\cite  {datitos_nlp}.\relax }}{94}{figure.caption.50}\protected@file@percent }
\newlabel{fig:Imagen_NLP_27}{{4.21}{94}{Primer paso entrenamiento Word2vec con función de salida sigmoide y utilizando negative sampling\cite {datitos_nlp}.\relax }{figure.caption.50}{}}
\citation{NLP_27}
\citation{datitos_nlp}
\citation{datitos_nlp}
\@writefile{lof}{\contentsline {figure}{\numberline {4.22}{\ignorespaces Obtención de vectores para el cálculo de forward propagation\cite  {datitos_nlp}.\relax }}{95}{figure.caption.51}\protected@file@percent }
\newlabel{fig:Imagen_NLP_28}{{4.22}{95}{Obtención de vectores para el cálculo de forward propagation\cite {datitos_nlp}.\relax }{figure.caption.51}{}}
\newlabel{eq:ecuacion_21_NLP}{{28}{95}{Entrenamiento y función de costo con Sigmoide}{equation.4.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.23}{\ignorespaces Forward y Back propagation\cite  {datitos_nlp}.\relax }}{95}{figure.caption.52}\protected@file@percent }
\newlabel{fig:Imagen_NLP_29}{{4.23}{95}{Forward y Back propagation\cite {datitos_nlp}.\relax }{figure.caption.52}{}}
\citation{NLP_28}
\citation{NLP_28}
\citation{NLP_28}
\citation{NLP_28}
\citation{NLP_28}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.5.4.11}Desventajas Word2Vec.}{96}{paragraph.4.5.4.11}\protected@file@percent }
\newlabel{desv_word2vec}{{4.5.4.11}{96}{Desventajas Word2Vec}{paragraph.4.5.4.11}{}}
\citation{NLP_28}
\citation{NLP_28}
\citation{NLP_28}
\citation{NLP_26}
\citation{NLP_2}
\citation{NLP_15}
\@writefile{lof}{\contentsline {figure}{\numberline {4.24}{\ignorespaces Representación de ‘apple’ mediante FastText\cite  {NLP_28}.\relax }}{97}{figure.caption.53}\protected@file@percent }
\newlabel{fig:Imagen_NLP_30}{{4.24}{97}{Representación de ‘apple’ mediante FastText\cite {NLP_28}.\relax }{figure.caption.53}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.25}{\ignorespaces Word2vec (izquierda) / FastText (derecha)\cite  {NLP_28}.\relax }}{97}{figure.caption.53}\protected@file@percent }
\newlabel{fig:Imagen_NLP_31}{{4.25}{97}{Word2vec (izquierda) / FastText (derecha)\cite {NLP_28}.\relax }{figure.caption.53}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.26}{\ignorespaces Word2vec / FastText\cite  {NLP_28}. \relax }}{97}{figure.caption.54}\protected@file@percent }
\newlabel{fig:Imagen_NLP_32}{{4.26}{97}{Word2vec / FastText\cite {NLP_28}. \relax }{figure.caption.54}{}}
\citation{similarity_survey}
\citation{NLP_17_18}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Obtención de las mediciones de similitud entre textos.}{98}{subsection.4.6}\protected@file@percent }
\newlabel{med_sim_textos}{{4.6}{98}{Obtención de las mediciones de similitud entre textos}{subsection.4.6}{}}
\citation{NLP_16}
\citation{similarity_survey}
\citation{similarity_survey}
\citation{NLP_16}
\citation{similarity_survey}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.6.1}Maneras de medir la similitud entre textos.}{99}{subsubsection.4.6.1}\protected@file@percent }
\newlabel{Tecnicas_Simil_textos}{{4.6.1}{99}{Maneras de medir la similitud entre textos}{subsubsection.4.6.1}{}}
\citation{similarity_survey}
\citation{similarity_survey}
\@writefile{lof}{\contentsline {figure}{\numberline {4.27}{\ignorespaces Medición de similitudes entre textos (remarcadas las técnicas utilizadas en la implementación)\cite  {similarity_survey}.\relax }}{100}{figure.caption.55}\protected@file@percent }
\newlabel{fig:Imagen_NLP_33}{{4.27}{100}{Medición de similitudes entre textos (remarcadas las técnicas utilizadas en la implementación)\cite {similarity_survey}.\relax }{figure.caption.55}{}}
\citation{similarity_survey}
\citation{WMD_2}
\citation{wmd_paper}
\citation{similarity_survey}
\citation{similarity_survey}
\citation{cosine_sim_1}
\citation{cosine_sim_2}
\citation{cosine_sim_3}
\citation{wmd_paper}
\citation{similarity_survey}
\citation{similarity_survey}
\citation{wmd_paper}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.6.2}¿Por qué decidimos utilizar Cosine Similarity y WMD?}{104}{subsubsection.4.6.2}\protected@file@percent }
\newlabel{cos_y_wmd}{{4.6.2}{104}{¿Por qué decidimos utilizar Cosine Similarity y WMD?}{subsubsection.4.6.2}{}}
\citation{KNN_Ejemplo}
\citation{KNN_Ejemplo}
\citation{KNN_Ejemplo}
\citation{KNN_Ejemplo}
\citation{KNN_Ejemplo}
\citation{KNN_Ejemplo}
\citation{KNN_Ejemplo}
\citation{KNN_Ejemplo}
\citation{similarity_survey}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.6.3}Cosine Similarity.}{105}{subsubsection.4.6.3}\protected@file@percent }
\newlabel{cosine}{{4.6.3}{105}{Cosine Similarity}{subsubsection.4.6.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.28}{\ignorespaces Obteniendo similitud del coseno.\relax }}{105}{figure.caption.56}\protected@file@percent }
\newlabel{fig:Imagen_NLP_34}{{4.28}{105}{Obteniendo similitud del coseno.\relax }{figure.caption.56}{}}
\newlabel{eq:ecuacion_22_NLP}{{29}{105}{Cosine Similarity}{equation.4.29}{}}
\newlabel{eq:ecuacion_23_NLP}{{30}{105}{Cosine Similarity}{equation.4.30}{}}
\citation{NLP_19}
\citation{NLP_19}
\citation{NLP_19}
\@writefile{lof}{\contentsline {figure}{\numberline {4.29}{\ignorespaces Similitud del coseno entre documentos\cite  {NLP_19}.\relax }}{106}{figure.caption.57}\protected@file@percent }
\newlabel{fig:Imagen_NLP_35}{{4.29}{106}{Similitud del coseno entre documentos\cite {NLP_19}.\relax }{figure.caption.57}{}}
\citation{wmd_paper}
\citation{similarity_survey}
\citation{NLP_21}
\citation{WMD_3}
\citation{WMD_4}
\citation{WMD_5}
\citation{wmd_paper}
\citation{NLP_20}
\citation{NLP_21}
\citation{wmd_paper}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.6.4}Word Mover’s Distance (WMD).}{107}{subsubsection.4.6.4}\protected@file@percent }
\newlabel{wmd}{{4.6.4}{107}{Word Mover’s Distance (WMD)}{subsubsection.4.6.4}{}}
\citation{NLP_21}
\citation{NLP_21}
\citation{NLP_21}
\citation{NLP_21}
\@writefile{lof}{\contentsline {figure}{\numberline {4.30}{\ignorespaces Ejemplo de ilustración de las distancias euclidianas entre word embeddings (2 dimensiones)\cite  {NLP_21}.\relax }}{108}{figure.caption.58}\protected@file@percent }
\newlabel{fig:Imagen_NLP_36}{{4.30}{108}{Ejemplo de ilustración de las distancias euclidianas entre word embeddings (2 dimensiones)\cite {NLP_21}.\relax }{figure.caption.58}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.31}{\ignorespaces Ejemplo del cálculo de WMD$(d1,d2)$ y WMD$(d3,d2)$\cite  {NLP_21}.\relax }}{108}{figure.caption.59}\protected@file@percent }
\newlabel{fig:Imagen_NLP_37}{{4.31}{108}{Ejemplo del cálculo de WMD$(d1,d2)$ y WMD$(d3,d2)$\cite {NLP_21}.\relax }{figure.caption.59}{}}
\citation{NLP_21}
\citation{NLP_21}
\citation{NLP_21}
\citation{NLP_21}
\citation{wmd_paper}
\newlabel{eq:ecuacion_24_NLP}{{31}{109}{Word Mover’s Distance (WMD)}{equation.4.31}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Implementación.}{110}{section.5}\protected@file@percent }
\newlabel{5.Implementacion}{{5}{110}{Implementación}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Obtención del modelo de clasificación.}{111}{subsection.5.1}\protected@file@percent }
\newlabel{5.1.Obtenciondelmodelopredictivo}{{5.1}{111}{Obtención del modelo de clasificación}{subsection.5.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}Esquema.}{111}{subsubsection.5.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Workflow para la obtención del modelo de clasificación KNN.  \relax }}{111}{figure.caption.60}\protected@file@percent }
\newlabel{fig:FlowCoreSystem}{{5.1}{111}{Workflow para la obtención del modelo de clasificación KNN. \\\relax }{figure.caption.60}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}Obtención de sets de datos.}{111}{subsubsection.5.1.2}\protected@file@percent }
\newlabel{obtencion_set_datos}{{5.1.2}{111}{Obtención de sets de datos}{subsubsection.5.1.2}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {5.1.2.1}Curriculum Vitae.}{112}{paragraph.5.1.2.1}\protected@file@percent }
\newlabel{cvs}{{5.1.2.1}{112}{Curriculum Vitae}{paragraph.5.1.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Ejemplo de una página de un candidato -pdf- (izquierda) y visualización de los 228 candidatos en el Jupyter Notebook -sin preprocesar- (derecha).\relax }}{112}{figure.caption.61}\protected@file@percent }
\newlabel{fig:DS_Cand_1}{{5.2}{112}{Ejemplo de una página de un candidato -pdf- (izquierda) y visualización de los 228 candidatos en el Jupyter Notebook -sin preprocesar- (derecha).\relax }{figure.caption.61}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Ejemplo de una fila de un candidato -csv- (izquierda) y visualización de los 2484 candidatos en el Jupyter Notebook -sin preprocesar- (derecha).\relax }}{113}{figure.caption.62}\protected@file@percent }
\newlabel{fig:DS_Cand_2}{{5.3}{113}{Ejemplo de una fila de un candidato -csv- (izquierda) y visualización de los 2484 candidatos en el Jupyter Notebook -sin preprocesar- (derecha).\relax }{figure.caption.62}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Ejemplo de una fila de un candidato -csv- y visualización de los 962 candidatos en el Jupyter Notebook -sin preprocesar- (derecha).\relax }}{113}{figure.caption.63}\protected@file@percent }
\newlabel{fig:DS_Cand_3}{{5.4}{113}{Ejemplo de una fila de un candidato -csv- y visualización de los 962 candidatos en el Jupyter Notebook -sin preprocesar- (derecha).\relax }{figure.caption.63}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Ejemplo de una página de un candidato -pdf- (izquierda) y visualización de los 10 candidatos en el Jupyter Notebook -sin preprocesar- (derecha).\relax }}{113}{figure.caption.64}\protected@file@percent }
\newlabel{fig:DS_Cand_4}{{5.5}{113}{Ejemplo de una página de un candidato -pdf- (izquierda) y visualización de los 10 candidatos en el Jupyter Notebook -sin preprocesar- (derecha).\relax }{figure.caption.64}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {5.1.2.2}Descripciones Puestos Laborales.}{114}{paragraph.5.1.2.2}\protected@file@percent }
\newlabel{puestos_lab}{{5.1.2.2}{114}{Descripciones Puestos Laborales}{paragraph.5.1.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Ejemplo de una fila de una descripción -csv- (izquierda) y visualización de las 22.000 descripciones en el Jupyter Notebook -sin preprocesar- (derecha).\relax }}{114}{figure.caption.65}\protected@file@percent }
\newlabel{fig:DS_Job_1}{{5.6}{114}{Ejemplo de una fila de una descripción -csv- (izquierda) y visualización de las 22.000 descripciones en el Jupyter Notebook -sin preprocesar- (derecha).\relax }{figure.caption.65}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Ejemplo de una fila de una descripción -csv- (izquierda) y visualización de las 10 descripciones en el Jupyter Notebook -sin preprocesar- (derecha).\relax }}{114}{figure.caption.66}\protected@file@percent }
\newlabel{fig:DS_Job_2}{{5.7}{114}{Ejemplo de una fila de una descripción -csv- (izquierda) y visualización de las 10 descripciones en el Jupyter Notebook -sin preprocesar- (derecha).\relax }{figure.caption.66}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.3}Preprocesamiento de textos.}{115}{subsubsection.5.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces Dataset de 962 filas iniciales luego de eliminar filas duplicadas e innecesarias.\relax }}{116}{figure.caption.67}\protected@file@percent }
\newlabel{fig:DS_Cand_3_sin_dup}{{5.8}{116}{Dataset de 962 filas iniciales luego de eliminar filas duplicadas e innecesarias.\relax }{figure.caption.67}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces Datasets de candidatos (izquierda) y de puestos de IT (derecha).\relax }}{116}{figure.caption.68}\protected@file@percent }
\newlabel{fig:final_antes_preproc}{{5.9}{116}{Datasets de candidatos (izquierda) y de puestos de IT (derecha).\relax }{figure.caption.68}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces Palabras comunes eliminadas de los textos.\relax }}{117}{figure.caption.69}\protected@file@percent }
\newlabel{fig:common_text}{{5.10}{117}{Palabras comunes eliminadas de los textos.\relax }{figure.caption.69}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.11}{\ignorespaces Candidato luego de aplicar pasos 3-5.\relax }}{117}{figure.caption.70}\protected@file@percent }
\newlabel{fig:tokens_obt}{{5.11}{117}{Candidato luego de aplicar pasos 3-5.\relax }{figure.caption.70}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.12}{\ignorespaces Candidato luego de aplicar bi-gramas.\relax }}{117}{figure.caption.71}\protected@file@percent }
\newlabel{fig:bigrams_obt}{{5.12}{117}{Candidato luego de aplicar bi-gramas.\relax }{figure.caption.71}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.13}{\ignorespaces Dataset de candidatos luego de realizar el preprocesamiento.\relax }}{118}{figure.caption.72}\protected@file@percent }
\newlabel{fig:Cand_clean}{{5.13}{118}{Dataset de candidatos luego de realizar el preprocesamiento.\relax }{figure.caption.72}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.14}{\ignorespaces Dataset de descripciones de puestos luego de realizar el preprocesamiento.\relax }}{118}{figure.caption.73}\protected@file@percent }
\newlabel{fig:Desc_clean}{{5.14}{118}{Dataset de descripciones de puestos luego de realizar el preprocesamiento.\relax }{figure.caption.73}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.4}Cantidad final del set de datos y su uso en las distintas etapas.}{119}{subsubsection.5.1.4}\protected@file@percent }
\newlabel{etapas_set_datos}{{5.1.4}{119}{Cantidad final del set de datos y su uso en las distintas etapas}{subsubsection.5.1.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Comparando textos y obteniendo similitudes.}{121}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}TF-IDF \& Cosine Similarity.}{121}{subsubsection.5.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.15}{\ignorespaces Valores de ejemplo de TF-IDF luego de entrenar y aplicarse sobre 3 documentos / textos.\relax }}{121}{figure.caption.74}\protected@file@percent }
\newlabel{fig:1_TF_IDF}{{5.15}{121}{Valores de ejemplo de TF-IDF luego de entrenar y aplicarse sobre 3 documentos / textos.\relax }{figure.caption.74}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.16}{\ignorespaces Obtención de ejemplo de Similitud del Coseno luego de calcular TF-IDF.\relax }}{122}{figure.caption.75}\protected@file@percent }
\newlabel{fig:2_TF_IDF}{{5.16}{122}{Obtención de ejemplo de Similitud del Coseno luego de calcular TF-IDF.\relax }{figure.caption.75}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.17}{\ignorespaces Obtención final de Similitud del Coseno luego de calcular TF-IDF.\relax }}{123}{figure.caption.76}\protected@file@percent }
\newlabel{fig:3_TF_IDF}{{5.17}{123}{Obtención final de Similitud del Coseno luego de calcular TF-IDF.\relax }{figure.caption.76}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}Word embeddings (Word2vec) \& WMD.}{123}{subsubsection.5.2.2}\protected@file@percent }
\newlabel{Implementacion_word_emb_y_wmd}{{5.2.2}{123}{Word embeddings (Word2vec) \& WMD}{subsubsection.5.2.2}{}}
\citation{NLP_26}
\citation{Implem_3}
\@writefile{toc}{\contentsline {paragraph}{\numberline {5.2.2.1}Elección de hiper-parámetros Word2vec.}{124}{paragraph.5.2.2.1}\protected@file@percent }
\newlabel{hiper_par_word2vec}{{5.2.2.1}{124}{Elección de hiper-parámetros Word2vec}{paragraph.5.2.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.18}{\ignorespaces Hiper-parámetros al implementar Word2vec.\relax }}{124}{figure.caption.77}\protected@file@percent }
\newlabel{fig:4_Implementacion_Word2vec}{{5.18}{124}{Hiper-parámetros al implementar Word2vec.\relax }{figure.caption.77}{}}
\citation{datitos_nlp}
\citation{datitos_nlp}
\citation{NLP_26}
\citation{datitos_nlp}
\@writefile{lof}{\contentsline {figure}{\numberline {5.19}{\ignorespaces Hiper-parámetro Ventana de Contexto\cite  {datitos_nlp}.\relax }}{125}{figure.caption.78}\protected@file@percent }
\newlabel{fig:5_Window}{{5.19}{125}{Hiper-parámetro Ventana de Contexto\cite {datitos_nlp}.\relax }{figure.caption.78}{}}
\citation{Implem_1}
\citation{Implem_2}
\citation{Implem_2}
\citation{NLP_26}
\citation{datitos_nlp}
\citation{datitos_nlp}
\citation{datitos_nlp}
\citation{NLP_11}
\@writefile{lof}{\contentsline {figure}{\numberline {5.20}{\ignorespaces Hiper-parámetro Número de muestras negativas.\cite  {datitos_nlp}.\relax }}{127}{figure.caption.79}\protected@file@percent }
\newlabel{fig:6_Neg_samples}{{5.20}{127}{Hiper-parámetro Número de muestras negativas.\cite {datitos_nlp}.\relax }{figure.caption.79}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {5.2.2.2}Word Mover's Distance (WMD).}{129}{paragraph.5.2.2.2}\protected@file@percent }
\newlabel{calculo_wmd}{{5.2.2.2}{129}{Word Mover's Distance (WMD)}{paragraph.5.2.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.21}{\ignorespaces Obtención final de WMD.\relax }}{129}{figure.caption.80}\protected@file@percent }
\newlabel{fig:7_Calculo_WMD}{{5.21}{129}{Obtención final de WMD.\relax }{figure.caption.80}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.22}{\ignorespaces Word embedding del 2-gram ‘$data\_scientist$’.\relax }}{130}{figure.caption.81}\protected@file@percent }
\newlabel{fig:8_Word_emb}{{5.22}{130}{Word embedding del 2-gram ‘$data\_scientist$’.\relax }{figure.caption.81}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {5.2.2.3}Observaciones valores de Cosine Similarity y WMD.}{131}{paragraph.5.2.2.3}\protected@file@percent }
\newlabel{Obs_cos_y_wmd}{{5.2.2.3}{131}{Observaciones valores de Cosine Similarity y WMD}{paragraph.5.2.2.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.23}{\ignorespaces Posiciones más y menos similares para el Candidato \textit  {$MLEngineer\_Bradly\_Johnston$} de acuerdo a nuestras métricas (TF-IDF \& Cosine a la izquierda y WMD a la derecha).\relax }}{131}{figure.caption.82}\protected@file@percent }
\newlabel{fig:Valores_para_Bradly_Johnson}{{5.23}{131}{Posiciones más y menos similares para el Candidato \textit {$MLEngineer\_Bradly\_Johnston$} de acuerdo a nuestras métricas (TF-IDF \& Cosine a la izquierda y WMD a la derecha).\relax }{figure.caption.82}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.24}{\ignorespaces CVs de Candidatos más similares para el la descripción del puesto \textit  {Security Specialist 2} de acuerdo a nuestras métricas (TF-IDF \& Cosine a la izquierda y WMD a la derecha).\relax }}{132}{figure.caption.83}\protected@file@percent }
\newlabel{fig:Valores_para_security_spec_2}{{5.24}{132}{CVs de Candidatos más similares para el la descripción del puesto \textit {Security Specialist 2} de acuerdo a nuestras métricas (TF-IDF \& Cosine a la izquierda y WMD a la derecha).\relax }{figure.caption.83}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Armado del modelo de clasificación KNN.}{133}{subsection.5.3}\protected@file@percent }
\newlabel{IMP_Modelo_clasificacion_KNN}{{5.3}{133}{Armado del modelo de clasificación KNN}{subsection.5.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}Preparación de los datos.}{133}{subsubsection.5.3.1}\protected@file@percent }
\newlabel{prep_datosd}{{5.3.1}{133}{Preparación de los datos}{subsubsection.5.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.25}{\ignorespaces Dataset de 131 filas / puntos para realizar la clasificación de nuevas muestras: 101 filas referentes a la posición \textit  {HCM Consultant 2} (izquierda) y 30 filas referentes al candidato \textit  {Denis Banik} (derecha).\relax }}{134}{figure.caption.84}\protected@file@percent }
\newlabel{fig:eliminacion_hcm_2_y_denis}{{5.25}{134}{Dataset de 131 filas / puntos para realizar la clasificación de nuevas muestras: 101 filas referentes a la posición \textit {HCM Consultant 2} (izquierda) y 30 filas referentes al candidato \textit {Denis Banik} (derecha).\relax }{figure.caption.84}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.26}{\ignorespaces Dataset de 3000 filas / puntos para utilizar en K-means y KNN.\relax }}{134}{figure.caption.85}\protected@file@percent }
\newlabel{fig:dataset_kmeans_knn_final}{{5.26}{134}{Dataset de 3000 filas / puntos para utilizar en K-means y KNN.\relax }{figure.caption.85}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2}K-means.}{135}{subsubsection.5.3.2}\protected@file@percent }
\newlabel{imp_kmeans}{{5.3.2}{135}{K-means}{subsubsection.5.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.27}{\ignorespaces Gráfico de dispersión con nuestros valores de similitud como dimensiones.\relax }}{135}{figure.caption.86}\protected@file@percent }
\newlabel{fig:dispersion}{{5.27}{135}{Gráfico de dispersión con nuestros valores de similitud como dimensiones.\relax }{figure.caption.86}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.28}{\ignorespaces Detección (izquierda) y eliminación (derecha) de outliers.\relax }}{136}{figure.caption.87}\protected@file@percent }
\newlabel{fig:detec_elim_outliers}{{5.28}{136}{Detección (izquierda) y eliminación (derecha) de outliers.\relax }{figure.caption.87}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.29}{\ignorespaces Método del codo usando Inertia.\relax }}{136}{figure.caption.88}\protected@file@percent }
\newlabel{fig:elbow_method_inertia}{{5.29}{136}{Método del codo usando Inertia.\relax }{figure.caption.88}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.30}{\ignorespaces Código K-means y obtención de las coordenadas de los centroides.\relax }}{137}{figure.caption.89}\protected@file@percent }
\newlabel{fig:codigo_k-means}{{5.30}{137}{Código K-means y obtención de las coordenadas de los centroides.\relax }{figure.caption.89}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.31}{\ignorespaces Distribución de centroides (izquierda) y asignación final de los clusters (derecha).\relax }}{137}{figure.caption.90}\protected@file@percent }
\newlabel{fig:final_groups}{{5.31}{137}{Distribución de centroides (izquierda) y asignación final de los clusters (derecha).\relax }{figure.caption.90}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.32}{\ignorespaces Dataset base para entrenar y evaluar KNN. \relax }}{138}{figure.caption.91}\protected@file@percent }
\newlabel{fig:to_knn}{{5.32}{138}{Dataset base para entrenar y evaluar KNN.\\\relax }{figure.caption.91}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.3}KNN.}{138}{subsubsection.5.3.3}\protected@file@percent }
\newlabel{imp_knn}{{5.3.3}{138}{KNN}{subsubsection.5.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.33}{\ignorespaces Esquema inicial y división de datos para el entrenamiento y evaluación del modelo KNN.\relax }}{139}{figure.caption.92}\protected@file@percent }
\newlabel{fig:esquema_1_validacion}{{5.33}{139}{Esquema inicial y división de datos para el entrenamiento y evaluación del modelo KNN.\relax }{figure.caption.92}{}}
\citation{Implem_4}
\@writefile{lof}{\contentsline {figure}{\numberline {5.34}{\ignorespaces Esquema final y división de datos para el entrenamiento y evaluación del modelo KNN utilizando Cross Validation.\relax }}{140}{figure.caption.93}\protected@file@percent }
\newlabel{fig:esquema_2_cross_val}{{5.34}{140}{Esquema final y división de datos para el entrenamiento y evaluación del modelo KNN utilizando Cross Validation.\relax }{figure.caption.93}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.35}{\ignorespaces Código implementación Cross Validation en KNN con 5-fold.}}{141}{figure.caption.94}\protected@file@percent }
\newlabel{fig:cross_val_code}{{5.35}{141}{Código implementación Cross Validation en KNN con 5-fold}{figure.caption.94}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.36}{\ignorespaces Valores de accuracy obtenidos mediante Cross Validation para cada valor de K.\relax }}{141}{figure.caption.95}\protected@file@percent }
\newlabel{fig:Cross_val_accuracy}{{5.36}{141}{Valores de accuracy obtenidos mediante Cross Validation para cada valor de K.\relax }{figure.caption.95}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.37}{\ignorespaces Código entrenamiento y evaluación final en KNN con k=8.\relax }}{142}{figure.caption.96}\protected@file@percent }
\newlabel{fig:train_knn_con_k_8}{{5.37}{142}{Código entrenamiento y evaluación final en KNN con k=8.\relax }{figure.caption.96}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Clasificación de nuevas muestras y resultados obtenidos.}{143}{subsection.5.4}\protected@file@percent }
\newlabel{5.4.Predicciondenuevasmuestrasyresultadosobtenidos}{{5.4}{143}{Clasificación de nuevas muestras y resultados obtenidos}{subsection.5.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.38}{\ignorespaces Predicción del modelo KNN para el puesto HCM Consultant 2.\relax }}{143}{figure.caption.97}\protected@file@percent }
\newlabel{fig:Pred_HCM_Consultant_2}{{5.38}{143}{Predicción del modelo KNN para el puesto HCM Consultant 2.\relax }{figure.caption.97}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.39}{\ignorespaces Predicción del modelo KNN para el Candidato Denis Banik (Security Specialist).\relax }}{144}{figure.caption.98}\protected@file@percent }
\newlabel{fig:prediccion_denis}{{5.39}{144}{Predicción del modelo KNN para el Candidato Denis Banik (Security Specialist).\relax }{figure.caption.98}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Integración al Sistema Web.}{145}{subsection.5.5}\protected@file@percent }
\newlabel{5.5.IntegracionalSistemaWeb}{{5.5}{145}{Integración al Sistema Web}{subsection.5.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6}Integración al Sistema Web.}{145}{subsection.5.6}\protected@file@percent }
\newlabel{5.5.IntegracionalSistemaWeb}{{5.6}{145}{Integración al Sistema Web}{subsection.5.6}{}}
\citation{Mozila}
\citation{Mozila}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.6.1}Django.}{146}{subsubsection.5.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {5.6.1.1}Ventajas de Django.}{146}{paragraph.5.6.1.1}\protected@file@percent }
\citation{Mozila}
\@writefile{toc}{\contentsline {paragraph}{\numberline {5.6.1.2}Arquitectura en Django.}{147}{paragraph.5.6.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.6.2}Base de datos.}{148}{subsubsection.5.6.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.40}{\ignorespaces Tipos de cardinalidad.\relax }}{149}{figure.caption.99}\protected@file@percent }
\newlabel{fig:Cardinalidad}{{5.40}{149}{Tipos de cardinalidad.\relax }{figure.caption.99}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.41}{\ignorespaces Diagrama de relación utilizado.\relax }}{150}{figure.caption.100}\protected@file@percent }
\newlabel{fig:Entity_Relation}{{5.41}{150}{Diagrama de relación utilizado.\relax }{figure.caption.100}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.6.3}Secciones del sistema}{151}{subsubsection.5.6.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.42}{\ignorespaces Logueo y Registración.\relax }}{151}{figure.caption.101}\protected@file@percent }
\newlabel{fig:Vista_Registro}{{5.42}{151}{Logueo y Registración.\relax }{figure.caption.101}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.43}{\ignorespaces Vista del Candidato.\relax }}{152}{figure.caption.102}\protected@file@percent }
\newlabel{fig:Vista_Candidato}{{5.43}{152}{Vista del Candidato.\relax }{figure.caption.102}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.44}{\ignorespaces Vista del Reclutador.\relax }}{153}{figure.caption.103}\protected@file@percent }
\newlabel{fig:Vista_Reclutador}{{5.44}{153}{Vista del Reclutador.\relax }{figure.caption.103}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.6.4}Manejo de los datos.}{154}{subsubsection.5.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {5.6.4.1}Modelado.}{155}{paragraph.5.6.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {5.6.4.2}Filtrado.}{156}{paragraph.5.6.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {5.6.4.3}Visualización.}{157}{paragraph.5.6.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7}Workflow final del Sistema.}{158}{subsection.5.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.45}{\ignorespaces Workflow final del Sistema.\relax }}{158}{figure.caption.104}\protected@file@percent }
\newlabel{fig:Pipeline_Final}{{5.45}{158}{Workflow final del Sistema.\relax }{figure.caption.104}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.8}Caso de Uso.}{159}{subsection.5.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.9}Limitaciones del sistema.}{160}{subsection.5.9}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusiones.}{161}{section.6}\protected@file@percent }
\citation{KNN_Ejemplo}
\citation{KNN_Ejemplo}
\@writefile{toc}{\contentsline {section}{\numberline {7}Anexos.}{162}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Ejemplo de funcionamiento KNN.}{162}{subsection.7.1}\protected@file@percent }
\newlabel{anexo_knn}{{7.1}{162}{Ejemplo de funcionamiento KNN}{subsection.7.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces Ejemplo de Clasificación con KNN con K=3 (círculo con linea sólida) y K=5 (círculo con linea punteada), usando la distancia euclidiana como métrica de cálculo de distancias\cite  {KNN_Ejemplo}.\relax }}{162}{figure.caption.105}\protected@file@percent }
\newlabel{fig:KNN_example}{{7.1}{162}{Ejemplo de Clasificación con KNN con K=3 (círculo con linea sólida) y K=5 (círculo con linea punteada), usando la distancia euclidiana como métrica de cálculo de distancias\cite {KNN_Ejemplo}.\relax }{figure.caption.105}{}}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Probabilidad de pertenecer a cada clase para diferentes valores de k.\relax }}{162}{table.caption.106}\protected@file@percent }
\newlabel{table:2}{{8}{162}{Probabilidad de pertenecer a cada clase para diferentes valores de k.\relax }{table.caption.106}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Ejemplo de funcionamiento K-means.}{163}{subsection.7.2}\protected@file@percent }
\newlabel{anexo_k_means}{{7.2}{163}{Ejemplo de funcionamiento K-means}{subsection.7.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.2}{\ignorespaces Algoritmo K-means.\relax }}{163}{figure.caption.107}\protected@file@percent }
\newlabel{fig:K_means_working_1}{{7.2}{163}{Algoritmo K-means.\relax }{figure.caption.107}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.3}{\ignorespaces Algoritmo K-means.\relax }}{164}{figure.caption.108}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.4}{\ignorespaces Algoritmo K-means.\relax }}{164}{figure.caption.109}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.5}{\ignorespaces Algoritmo K-means.\relax }}{164}{figure.caption.110}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.6}{\ignorespaces Algoritmo K-means.\relax }}{165}{figure.caption.111}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.7}{\ignorespaces Algoritmo K-means.\relax }}{165}{figure.caption.112}\protected@file@percent }
\citation{apunte_uba}
\citation{apunte_uba}
\citation{apunte_uba}
\citation{apunte_uba}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Posición inicial de los centroides en K-means.}{166}{subsection.7.3}\protected@file@percent }
\newlabel{anexo_pos_inic_centroides}{{7.3}{166}{Posición inicial de los centroides en K-means}{subsection.7.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.8}{\ignorespaces Ejemplo K-means. \cite  {apunte_uba}\relax }}{166}{figure.caption.113}\protected@file@percent }
\newlabel{fig:K_means_costo_1}{{7.8}{166}{Ejemplo K-means. \cite {apunte_uba}\relax }{figure.caption.113}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.9}{\ignorespaces Ejemplo K-Means peor (izquierda) y mejor (derecha) costo. \cite  {apunte_uba}\relax }}{166}{figure.caption.114}\protected@file@percent }
\newlabel{fig:K_means_costo_2}{{7.9}{166}{Ejemplo K-Means peor (izquierda) y mejor (derecha) costo. \cite {apunte_uba}\relax }{figure.caption.114}{}}
\citation{apunte_uba}
\citation{apunte_uba}
\citation{apunte_uba}
\citation{apunte_uba}
\@writefile{lof}{\contentsline {figure}{\numberline {7.10}{\ignorespaces Costo en K-Means. \cite  {apunte_uba}\relax }}{167}{figure.caption.115}\protected@file@percent }
\newlabel{fig:K_means_costo_3}{{7.10}{167}{Costo en K-Means. \cite {apunte_uba}\relax }{figure.caption.115}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.11}{\ignorespaces Histograma J en K-Means. \cite  {apunte_uba}\relax }}{167}{figure.caption.115}\protected@file@percent }
\newlabel{fig:K_means_costo_4}{{7.11}{167}{Histograma J en K-Means. \cite {apunte_uba}\relax }{figure.caption.115}{}}
\citation{ANN_22}
\citation{ANN_22}
\citation{ANN_22}
\citation{ANN_22}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}Funciones de activación.}{168}{subsection.7.4}\protected@file@percent }
\newlabel{anexo_func_activ}{{7.4}{168}{Funciones de activación}{subsection.7.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.12}{\ignorespaces Funciones de activación más comunes\cite  {ANN_22}.\relax }}{168}{figure.caption.116}\protected@file@percent }
\newlabel{fig:ann_7}{{7.12}{168}{Funciones de activación más comunes\cite {ANN_22}.\relax }{figure.caption.116}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.13}{\ignorespaces Fórmulas y rangos de las funciones de activación más comunes.}}{168}{figure.caption.117}\protected@file@percent }
\newlabel{fig:ann_8}{{7.13}{168}{Fórmulas y rangos de las funciones de activación más comunes}{figure.caption.117}{}}
\citation{NLP_26}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5}Ejemplo de obtención de Word embeddings mediante Skipgram y softmax.}{169}{subsection.7.5}\protected@file@percent }
\newlabel{anexo_word_emb}{{7.5}{169}{Ejemplo de obtención de Word embeddings mediante Skipgram y softmax}{subsection.7.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.14}{\ignorespaces Armando dataset para Skipgram\relax }}{170}{figure.caption.118}\protected@file@percent }
\newlabel{fig:1_EjSkip}{{7.14}{170}{Armando dataset para Skipgram\relax }{figure.caption.118}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.15}{\ignorespaces Dataset para Skipgram\relax }}{170}{figure.caption.119}\protected@file@percent }
\newlabel{fig:2_EjSkip}{{7.15}{170}{Dataset para Skipgram\relax }{figure.caption.119}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.16}{\ignorespaces Representación en one-hot encoding para cada una de las palabras de entrada\relax }}{171}{figure.caption.120}\protected@file@percent }
\newlabel{fig:3_EjSkip}{{7.16}{171}{Representación en one-hot encoding para cada una de las palabras de entrada\relax }{figure.caption.120}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.17}{\ignorespaces Arquitectura Skipgram con V=8, N=3.\relax }}{171}{figure.caption.121}\protected@file@percent }
\newlabel{fig:4_EjSkip}{{7.17}{171}{Arquitectura Skipgram con V=8, N=3.\relax }{figure.caption.121}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.18}{\ignorespaces Primera iteración Skipgram del paso 2.\relax }}{172}{figure.caption.122}\protected@file@percent }
\newlabel{fig:5_EjSkip}{{7.18}{172}{Primera iteración Skipgram del paso 2.\relax }{figure.caption.122}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.19}{\ignorespaces Primera iteración Skipgram del paso 2 en mayor detalle.\relax }}{173}{figure.caption.123}\protected@file@percent }
\newlabel{fig:6_EjSkip}{{7.19}{173}{Primera iteración Skipgram del paso 2 en mayor detalle.\relax }{figure.caption.123}{}}
\newlabel{eq:skip_1}{{32}{173}{Ejemplo de obtención de Word embeddings mediante Skipgram y softmax}{equation.7.32}{}}
\newlabel{eq:skip_2}{{33}{174}{Ejemplo de obtención de Word embeddings mediante Skipgram y softmax}{equation.7.33}{}}
\newlabel{eq:skip_3}{{34}{174}{Ejemplo de obtención de Word embeddings mediante Skipgram y softmax}{equation.7.34}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.20}{\ignorespaces Segunda iteración Skipgram del paso 2 .\relax }}{174}{figure.caption.124}\protected@file@percent }
\newlabel{fig:7_EjSkip}{{7.20}{174}{Segunda iteración Skipgram del paso 2 .\relax }{figure.caption.124}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.21}{\ignorespaces Comparando \textit  {y pred softmax} con \textit  {y true}.\relax }}{175}{figure.caption.125}\protected@file@percent }
\newlabel{fig:8_EjSkip}{{7.21}{175}{Comparando \textit {y pred softmax} con \textit {y true}.\relax }{figure.caption.125}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.22}{\ignorespaces Matriz $W’$ de embeddings objetivo.\relax }}{176}{figure.caption.126}\protected@file@percent }
\newlabel{fig:9_EjSkip}{{7.22}{176}{Matriz $W’$ de embeddings objetivo.\relax }{figure.caption.126}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.6}Palabras repetidas en nuestro Corpus y palabras polisémicas.}{177}{subsection.7.6}\protected@file@percent }
\newlabel{anexo_polisem}{{7.6}{177}{Palabras repetidas en nuestro Corpus y palabras polisémicas}{subsection.7.6}{}}
\bibcite{Similarity_calculation}{1}
\bibcite{jobs_future}{2}
\bibcite{wmd_paper}{3}
\bibcite{similarity_survey}{4}
\bibcite{cosine_sim_1}{5}
\bibcite{cosine_sim_2}{6}
\bibcite{cosine_sim_3}{7}
\bibcite{seleccion_reclutamiento_1}{8}
\bibcite{seleccion_reclutamiento_2}{9}
\bibcite{apunte_uba}{10}
\bibcite{estudio_eye_tracking}{11}
\bibcite{trabajos_relacionados_1}{12}
\bibcite{trabajos_relacionados_2}{13}
\bibcite{ontology_mapping}{14}
\bibcite{trabajos_relacionados_3}{15}
\bibcite{trabajos_relacionados_4}{16}
\bibcite{trabajos_relacionados_5}{17}
\bibcite{trabajos_relacionados_6}{18}
\bibcite{trabajos_relacionados_7}{19}
\bibcite{trabajos_relacionados_8}{20}
\bibcite{trabajos_relacionados_9}{21}
\bibcite{trabajos_relacionados_10}{22}
\bibcite{trabajos_relacionados_11}{23}
\bibcite{trabajos_relacionados_12}{24}
\bibcite{trabajos_relacionados_13}{25}
\bibcite{trabajos_relacionados_14}{26}
\bibcite{trabajos_relacionados_15}{27}
\bibcite{sistema_recomendacion}{28}
\bibcite{intro_algos_ML}{29}
\bibcite{intro_clasificacion_ML}{30}
\bibcite{aprendiz_transd}{31}
\bibcite{cross_validation}{32}
\bibcite{preprocessing}{33}
\bibcite{metrics_clustering_1}{34}
\bibcite{metrics_clustering_2}{35}
\bibcite{metrics_clasification}{36}
\bibcite{metrics_regression}{37}
\bibcite{over_and_under}{38}
\bibcite{KNN_limitacion}{39}
\bibcite{KNN_Ejemplo}{40}
\bibcite{K_means_experiment}{41}
\bibcite{K_means_elbow}{42}
\bibcite{K_means_review}{43}
\bibcite{K_means_initial_centroids}{44}
\bibcite{K_means_plus_plus}{45}
\bibcite{ANN_21}{46}
\bibcite{ANN_22}{47}
\bibcite{ANN_23}{48}
\bibcite{ANN_24}{49}
\bibcite{ANN_25}{50}
\bibcite{NLP_1}{51}
\bibcite{NLP_2}{52}
\bibcite{NLP_3_4}{53}
\bibcite{NLP_5}{54}
\bibcite{NLP_6}{55}
\bibcite{NLP_7}{56}
\bibcite{NLP_8}{57}
\bibcite{NLP_9}{58}
\bibcite{NLP_10}{59}
\bibcite{NLP_11}{60}
\bibcite{NLP_12}{61}
\bibcite{NLP_13}{62}
\bibcite{NLP_13_2}{63}
\bibcite{NLP_14}{64}
\bibcite{NLP_15}{65}
\bibcite{NLP_16}{66}
\bibcite{NLP_17_18}{67}
\bibcite{NLP_19}{68}
\bibcite{NLP_20}{69}
\bibcite{NLP_21}{70}
\bibcite{NLP_26}{71}
\bibcite{NLP_27}{72}
\bibcite{NLP_28}{73}
\bibcite{datitos_nlp}{74}
\bibcite{WMD_2}{75}
\bibcite{WMD_3}{76}
\bibcite{WMD_4}{77}
\bibcite{WMD_5}{78}
\bibcite{Implem_1}{79}
\bibcite{Implem_2}{80}
\bibcite{Implem_3}{81}
\bibcite{Implem_4}{82}
\bibcite{Mozila}{83}
