{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "extra-contractor",
   "metadata": {},
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-furniture",
   "metadata": {},
   "source": [
    "En esta serie de Jupyter Notebooks aplicaremos las técnicas de **WMD** y **Cosine Similarity** para medir distancias y obtener similitudes entre textos.  \n",
    "Previamente a aplicar **Cosine Similarity** usaremos **TF-IDF** para...  **COMPLETAR**  \n",
    "Y, previamente a aplicar **WMD** usaremos **Word Embeddings** mediante **Word2vec** para... **COMPLETAR**\n",
    "\n",
    "Para obtener dichas similitudes entre textos, las comparaciones que realizaremos serán entre el **contenido de CVs de distintos Candidatos** y las **Descripciones de los Puestos de IT publicados por distintas empresas**. \n",
    "\n",
    "Los datasets utilizados y la implementación realizada del programa es para Curriculums y Descripciones de Puestos en idioma **Inglés**.\n",
    "\n",
    "<u> Luego de aplicar preprocesamiento y limpieza de datos nos quedarán los siguientes datasets: </u>\n",
    "* **625** CVs de Candidatos (en formato pdf y csv). \n",
    "* **20593** Descripciones de Puestos de IT (en formato csv). \n",
    "\n",
    "**Nota**: el total de CVs de Candidatos (**625**) y Descripciones de Puestos de IT (**20593**) serán utilizados para entrenar nuestro Vocabulario para el cálculo de WMD **COMPLETAR BIEN**. \n",
    "Por otro lado, debido a que queremos que nuestro clasificador KNN funcione rápido al realizar predicciones, lo entrenaremos únicamente con una porción de nuestros datasets (**300** CVs y **200** Jobs Descriptions). No obstante, como realizamos una comparación de cada CV con cada Descripción de Puesto, tendremos un total de 300x100 = **30.000** filas para entrenar nuestro clasificador KNN. Cada fila tendrá un valor de WMD y Cosine Similarity, por lo cual representaremos estos 30.000 puntos en un plano de 2 dimensiones.  \n",
    "\n",
    "<u> Ubicación Datasets: </u>\n",
    "* CVs: **/Datasets_CVs_And_Job_Descriptions/EN/CVs**.    \n",
    "* Descripciones Puestos: **/Datasets_CVs_And_Job_Descriptions/EN/JOb_Descr**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-commodity",
   "metadata": {},
   "source": [
    "# Índice y Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-radar",
   "metadata": {},
   "source": [
    "### Jupyter Notebook \"1-Preprocessing_&_Data_Cleaning\":\n",
    "* 1-Armado de Dataframes y Limpieza de datos.\n",
    "    * 1.1-Impotando librerías necesarias.\n",
    "    * 1.2-Funciones necesarias para la Limpieza de datos. ( * )\n",
    "    * 1.3-Armado Dataframe Puestos en base a Datasets.   \n",
    "        *1.3.1- (Archivo CSV) '1-10_examples_job_Desc.csv'    \n",
    "        *1.3.2- (Archivo CSV) '2-22000_examples_dice_com-job_us.csv'  \n",
    "    * 1.4-Limpieza Dataframe Puestos.\n",
    "    * 1.5-Armado Dataframe CVs en base a Datasets.  \n",
    "        *1.5.1- (Carpeta con archivos en PDF) '1-10_examples_CVs_PDF'  \n",
    "        *1.5.2- (Carpeta con archivos en PDF) '2-228_examples_CVs_PDF'  \n",
    "        *1.5.3- (Archivo CSV) '3-2484_examples_CVs.csv'  \n",
    "        *1.5.4- (Archivo CSV) '4-962_examples_CVs.csv'  \n",
    "    * 1.6-Limpieza Dataframe CVs.  \n",
    "    \n",
    "* 2-Export de DFs para usarlo en el siguiente Jupyter Notebook.\n",
    "\n",
    "( * ) **El procedimiento para la Limpieza de los CVs y los Puestos será el siguiente:**\n",
    "\n",
    "1. Convertimos todo a minúscula.\n",
    "2. Eliminamos datos no relevantes para nuestros análisis (mails y páginas web).\n",
    "3. Eliminamos signos de puntuación y caracterés especiales (incluyendo números).\n",
    "4. Eliminamos stop words.\n",
    "5. Eliminamos common words no relevantes para nuestros análisis.\n",
    "6. Aplicamos Lematización y Tokenización.\n",
    "7. Obtenemos los bi-gramas y los usamos en nuestros textos.\n",
    "\n",
    "**Fuentes de los datasets:** \n",
    "\n",
    "* 1.3.1- (Archivo CSV) '1-10_examples_job_Desc.csv': Recolección propia del sitio Indeed (https://www.indeed.com/q-USA-jobs.html) para puestos de trabajo de IT.  \n",
    "* 1.3.2- (Archivo CSV) '2-22000_examples_dice_com-job_us.csv': CSV obtenido del sitio Kaggle (https://www.kaggle.com/PromptCloudHQ/us-technology-jobs-on-dicecom). El CSV cuenta con descripciones de puestos obtenidos del sitio web de USA de postulación de trabajos del rubro de IT '**Dice.com**'.\n",
    "* 1.4.1- (Carpeta con archivos en PDF) '1-10_examples_CVs_PDF': Recolección propia de distintos sitios web con ejemplos de CVs de Candidatos para distintos Puestos.    \n",
    "* 1.4.2- (Carpeta con archivos en PDF) '2-228_examples_CVs_PDF': Documentos .docx convertidos a .pdf obtenidos del sitio Kaggle (https://www.kaggle.com/palaksood97/resume-dataset). Estos pdfs son Candidatos de la India con experiencia en el rubro de IT.  \n",
    "* 1.4.3- (Archivo CSV) '3-2484_examples_CVs.csv': CSV obtenido del sitio Kagle (https://www.kaggle.com/snehaanbhawal/resume-dataset). Este CSV cuenta con CVs obtenidos del sitio web de postulación de trabajos '**livecareer.com**'.\n",
    "* 1.4.4- (Archivo CSV) '4-962_examples_CVs.csv': CSV obtenido del sitio Kaggle (https://www.kaggle.com/gauravduttakiit/resume-dataset). Este CSV cuenta con CVs repartidos en distintas categorías de IT.\n",
    "\n",
    "**Cantidades finales de los datasets luego de aplicar preprocesamiento y limpieza de datos:**\n",
    "\n",
    "| Dataset                              | Cantidad Inicial | Cantidad Final | Cantidad Total Final Puestos | Cantidad Total Final CVs |\n",
    "|--------------------------------------|------------------|----------------|------------------------|--------------------|\n",
    "| 1-10_examples_job_Desc.csv           | 10               | 10             | -                      | -                  |\n",
    "| 2-22000_examples_dice_com-job_us.csv | 22000            | 20583          | -                      | -                  |\n",
    "| -                                    | -                | -              | 20593                  | -                  |\n",
    "| 1-10_examples_CVs_PDF                | 10               | 10             | -                      | -                  |\n",
    "| 2-228_examples_CVs_PDF               | 228              | 228            | -                      | -                  |\n",
    "| 3-2484_examples_CVs.csv              | 2484             | 290            | -                      | -                  |\n",
    "| 4-962_examples_CVs.csv               | 962              | 97             | -                      | -                  |\n",
    "| -                                    | -                | -              | -                      | 625                |\n",
    "\n",
    "  \n",
    "### Jupyter Notebook \"2-TF_IDF_Cosine_&_Word2vec_WMD\":  \n",
    "* 3-Imports.\n",
    "     * 3.1-Import librerias necesarias.\n",
    "     * 3.2-Import de DFs del Jupyter Notebook anterior.\n",
    "* 4-División DFs para usarlos en los distintos entrenamientos.\n",
    "* 5-Realizando Comparaciones y obteniendo Similitudes.\n",
    "     * 5.1- TF-IDF & Cosine Similarity.\n",
    "     * 5.2- Word Embedding (Word2vec) & WMD.\n",
    "* 6-Export del DF para usarlo en el siguiente Jupyter Notebook.\n",
    "     \n",
    "### Jupyter Notebook \"3-Kmeans_&_KNN\":  \n",
    "* 7-Imports.\n",
    "     * 7.1-Import librerias necesarias.\n",
    "     * 7.2-Import de DFs del Jupyter Notebook anterior.\n",
    "* 8.-..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-graduate",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
