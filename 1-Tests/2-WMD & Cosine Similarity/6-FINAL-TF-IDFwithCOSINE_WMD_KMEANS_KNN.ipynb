{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1-Importando librerias necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fedricio/anaconda3/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/fedricio/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import matplotlib.pyplot as  plt\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import math\n",
    "import re\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-Dataset Puestos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Job_Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Master’s degree or above in a STEM field, incl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist 2</td>\n",
       "      <td>\\nReporting to the Director, Data &amp; Analytics,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HCM Consultant</td>\n",
       "      <td>\\nThe Oracle Cloud HCM Absence Consultant will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HCM Consultant 2</td>\n",
       "      <td>4+ years of experience in PeopleSoft or Oracle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Leveraging the latest machine and deep learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Machine Learning Engineer 2</td>\n",
       "      <td>Collaborate with a multidisciplinary team to g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Security Specialist</td>\n",
       "      <td>Work in a fast-paced environment that combine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Security Specialist 2</td>\n",
       "      <td>\\n    Handling incoming requests for assistanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Web Developer Full Stack</td>\n",
       "      <td>\\n\\n    Graduate Degree in Information Technol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Web Developer Full Stack 2</td>\n",
       "      <td>\\n· Enter existing website codebases and exten...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Job_Title  \\\n",
       "2               Data Scientist   \n",
       "3             Data Scientist 2   \n",
       "6               HCM Consultant   \n",
       "7             HCM Consultant 2   \n",
       "0    Machine Learning Engineer   \n",
       "1  Machine Learning Engineer 2   \n",
       "8          Security Specialist   \n",
       "9        Security Specialist 2   \n",
       "4     Web Developer Full Stack   \n",
       "5   Web Developer Full Stack 2   \n",
       "\n",
       "                                     Job_Description  \n",
       "2  Master’s degree or above in a STEM field, incl...  \n",
       "3  \\nReporting to the Director, Data & Analytics,...  \n",
       "6  \\nThe Oracle Cloud HCM Absence Consultant will...  \n",
       "7  4+ years of experience in PeopleSoft or Oracle...  \n",
       "0  Leveraging the latest machine and deep learnin...  \n",
       "1  Collaborate with a multidisciplinary team to g...  \n",
       "8  Work in a fast-paced environment that combine ...  \n",
       "9  \\n    Handling incoming requests for assistanc...  \n",
       "4  \\n\\n    Graduate Degree in Information Technol...  \n",
       "5  \\n· Enter existing website codebases and exten...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Jobs = pd.read_csv(\"Archivos 2-Especificos/Ejemplo1_Dataset_CVs_And_Job_Desc/EN/Job_Descr/Job_Positions_Scrapped/10_Positions_Only_Qualif.csv\")\n",
    "df_Jobs = df_Jobs.rename(columns={'job_title': 'Job_Title', 'job_description':'Job_Description'})\n",
    "\n",
    "df_Jobs = df_Jobs.sort_values('Job_Title', ascending=True)\n",
    "df_Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-Dataset CVs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF a texto usando pdfplumber."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de CVs extraidos: 10\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import os\n",
    "import collections\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "#Leemos los CVs almacenados en nuestra carpeta y los extraemos uno por uno convirtiendolos a texto\n",
    "#mediante la libreria pdfplumber:\n",
    "pathCVs='Archivos 2-Especificos/Ejemplo1_Dataset_CVs_And_Job_Desc/EN/PDFs_CVs_2'\n",
    "onlyfiles = [os.path.join(pathCVs, f) for f in os.listdir(pathCVs) if os.path.isfile(os.path.join(pathCVs, f))]\n",
    "print(\"Cantidad de CVs extraidos:\", len(onlyfiles))\n",
    "\n",
    "#Funcion para extraer las palabras del CV:\n",
    "\n",
    "def pdfextract(PDF_file):\n",
    "    single_page_text = \"\"\n",
    "    all_text = \"\"\n",
    "    pdf = pdfplumber.open(PDF_file)\n",
    "    for pdf_page in pdf.pages:\n",
    "        single_page_text = pdf_page.extract_text()\n",
    "        all_text = all_text + '\\n' + single_page_text\n",
    "    pdf.close()\n",
    "    #return(all_text)        \n",
    "    return(all_text.encode('utf-8'))\n",
    "\n",
    "def extract_text(file):\n",
    "    text = pdfextract(file).decode('utf-8')\n",
    "    #text = pdfextract(file)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Candidate_Name</th>\n",
       "      <th>Content_CV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data_Scientist_Karla_Lewis</td>\n",
       "      <td>\\nKARLA LEWIS\\nData Scientist\\nCONTACT WORK EX...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data_Scientist_Rahul_Malik</td>\n",
       "      <td>\\nRAHUL MALIK\\nNLP Data Scientist\\nCONTACT WOR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HCM_Federico_Calonge</td>\n",
       "      <td>\\n                                            ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HCM_Robert_Smith</td>\n",
       "      <td>\\nSap Hcm Consultant Phone: (123) 456 78 99\\nE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ML_Engineer_Bradly_Johnston</td>\n",
       "      <td>\\nBradly Johnston\\n435 Kasey Vista, Detroit\\n+...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ML_Engineer_Jonathon_Price</td>\n",
       "      <td>\\nJonathon Price \\n4587 Terry Groves, Boston\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Security_Specialist_Ahmed Wayne</td>\n",
       "      <td>\\nAhmed Wayne\\nAddress: Abu Dhabi, UAE\\nNation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Security_Specialist_Denis Banik</td>\n",
       "      <td>\\nDenis Banik\\nEmail address: hello@kickresume...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Web_Dev_Alec_Dionisio</td>\n",
       "      <td>\\nChestertown, MD 4107083942\\nhi@alecdionis.io...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Web_Dev_Karen_Higgins</td>\n",
       "      <td>\\nKaren Higgins \\n        We b Developer \\n \\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Candidate_Name  \\\n",
       "6       Data_Scientist_Karla_Lewis   \n",
       "2       Data_Scientist_Rahul_Malik   \n",
       "4             HCM_Federico_Calonge   \n",
       "7                 HCM_Robert_Smith   \n",
       "0      ML_Engineer_Bradly_Johnston   \n",
       "1       ML_Engineer_Jonathon_Price   \n",
       "8  Security_Specialist_Ahmed Wayne   \n",
       "3  Security_Specialist_Denis Banik   \n",
       "5            Web_Dev_Alec_Dionisio   \n",
       "9            Web_Dev_Karen_Higgins   \n",
       "\n",
       "                                          Content_CV  \n",
       "6  \\nKARLA LEWIS\\nData Scientist\\nCONTACT WORK EX...  \n",
       "2  \\nRAHUL MALIK\\nNLP Data Scientist\\nCONTACT WOR...  \n",
       "4  \\n                                            ...  \n",
       "7  \\nSap Hcm Consultant Phone: (123) 456 78 99\\nE...  \n",
       "0  \\nBradly Johnston\\n435 Kasey Vista, Detroit\\n+...  \n",
       "1  \\nJonathon Price \\n4587 Terry Groves, Boston\\n...  \n",
       "8  \\nAhmed Wayne\\nAddress: Abu Dhabi, UAE\\nNation...  \n",
       "3  \\nDenis Banik\\nEmail address: hello@kickresume...  \n",
       "5  \\nChestertown, MD 4107083942\\nhi@alecdionis.io...  \n",
       "9  \\nKaren Higgins \\n        We b Developer \\n \\n...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtenemos todas las palabras del CV sin preprocesar ni nada:\n",
    "df_Candidates=pd.DataFrame(columns = ['Candidate_Name','Content_CV'])\n",
    "i=0\n",
    "while i < len(onlyfiles):\n",
    "    file=onlyfiles[i]\n",
    "    base = os.path.basename(file)  #Test_Phoebe Buffay.pdf\n",
    "    filename = os.path.splitext(base)[0]  #Test_Phoebe Buffay\n",
    "    dat=extract_text(file)\n",
    "    data = [{'Candidate_Name':filename, 'Content_CV':dat}]\n",
    "    df_Candidates=df_Candidates.append(data, ignore_index=True)\n",
    "    i+=1\n",
    "\n",
    "df_Candidates = df_Candidates.sort_values('Candidate_Name', ascending=True)\n",
    "df_Candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limpieza De los CVs**:\n",
    "1. Limpieza \"general\": Pasar todo a minúscula, eliminar signos de puntuación, espacios en blanco.\n",
    "2. Limpieza de stop words.\n",
    "3. Steaming para unir palabras: computer_science, machine_learning.\n",
    "4. Lematización. (VER)\n",
    "5. Limpieza en txt de datos personales (mails, telefonos).\n",
    "6. Limpieza de palabras innecesarias en archivo txt (Page, meses, años, etc).\n",
    "\n",
    "**Limpieza de los Puestos**:\n",
    "1. Limpieza \"general\": Pasar todo a minúscula, eliminar signos de puntuación, espacios en blanco.\n",
    "2. Limpieza de stop words.\n",
    "3. Steaming para unir palabras: computer_science, machine_learning.\n",
    "4. Lematización. (VER)\n",
    "5. Limpieza de palabras innecesarias en archivo txt (VER: por ej. mails que dejan las empresas, telefonos, etc.).\n",
    "6. Luego, para la obtención de Keywords (VER si es necesario): --> Por el problema que me tomaba las keywords como \"you\", \"I\" y demás..., podría hacer un txt con lenguajes y skills por \"defecto\" y me fijo si están en las keywords... sino no las pongo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones para limpiar datos en columnas de un DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/fedricio/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import regex as re #Usado en la función remove_punctuation_and_special_characters.\n",
    "from nltk.stem import WordNetLemmatizer   #Usado para lematización.\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize   #Usado para tokenizar.\n",
    "\n",
    "#Definimos nuestras stop words desde nltk:\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "                \n",
    "def lower_text(DF,clean_column):\n",
    "    DF[clean_column] = DF[clean_column].apply(lambda x: x.lower() if isinstance(x,str) else x)\n",
    "    \n",
    "def remove_stop_words(DF,clean_column):\n",
    "    DF[clean_column] = DF[clean_column].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "\n",
    "def remove_punctuation_and_special_characters(DF,clean_column):\n",
    "    DF[clean_column] = DF[clean_column].apply(lambda x: re.sub('[^\\w-]|(\\d+)',' ', x) if isinstance(x,str) else x)\n",
    "                                                                #Macheamos cualquier non-word excepto el -; y tambien macheamos los números (\\d+)\n",
    "    #Macheos:\n",
    "        #'\\W+'                  --> Cualquier non-word.\n",
    "        #'[()!@#$/,;.:\"]'       --> todos esos carácteres especiales que pongo ahi. \n",
    "        #'\\w+[-]\\w+'            --> machea a las palabras non-algo.\n",
    "        #'[^\\w-+]'              --> Machea todas las non-words excepto el guion medio y el +.\n",
    "        #'\\C\\+\\+'               --> Machea C++.\n",
    "        #[^\\w-+]|(\\C\\+\\+|team)  --> Machea todas las non-words excepto el guion medio y el +. Y tambien machea C++ y la palabra \"team\"\n",
    "        #[^\\w-+]|(\\C\\+\\+|\\d+)   --> Machea todas las non-words excepto el guion medio y el +. Y tambien machea C++ y los números (\\d+).\n",
    "        \n",
    "    #Para m.sc' --> reemplazar el . por espacio cuando antes y despues del punto esta todo \"junto\"... para diferenciarlo del punto de una oración. \n",
    "    \n",
    "#Tokenizar es el proceso de parsear Strings de texto en diferentes secciones (\"tokens\"). Debemos tokenizar teniendo en cuenta qué hacer con las comas, con los espacios en blanco, \n",
    "#con los \"-\", etc. Para esto usamos la función \"word_tokenize\" que se encargará de esta tarea. \n",
    "#Esta funcion NO divide las palabras que estan con un \"-\"... de esta manera la palabra \"scale-up\" queda así y NO se divide.\n",
    "#Tambien tendremos la palabra con una única letra (\"c\", del lenguaje c) macheado únicamente a un token \"c\". \n",
    "def tokenize_and_lemmatization(text_column):\n",
    "    tokens = word_tokenize(text_column) #Tokenizamos.\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [wordnet_lemmatizer.lemmatize(tok).lower() for tok in tokens] # Stem words.\n",
    "    return list(lemmatized_tokens)\n",
    "    \n",
    "def cleaning_DF(DF,column_to_clean):\n",
    "    clean_column='clean_'+column_to_clean\n",
    "    DF[clean_column]=DF[column_to_clean] #Copiamos el contenido de 'column_to_clean' en 'clean_column' para utilizarla en las funciones posteriores.\n",
    "    lower_text(DF,clean_column)\n",
    "    remove_punctuation_and_special_characters(DF,clean_column)\n",
    "    remove_stop_words(DF,clean_column)\n",
    "     \n",
    "def tokenize_and_lemmatize(DF,column_to_clean):\n",
    "    clean_column='clean_'+column_to_clean\n",
    "    tokens_column='tokens_'+column_to_clean\n",
    "    DF[tokens_column] = DF[clean_column].apply(tokenize_and_lemmatization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpieza de datos del DF de Jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collaborate with a multidisciplinary team to gain insight into complex biochemical systems.\n",
      "Design computational models to study various interactions such as interactions between genomes, proteins, and binding sites\n",
      "Extract various features from the computational models and communicate the results back to the team.\n",
      "Predict the behaviour of new protein structures on certain binding sites using the computational models.\n",
      "Work with the team of software engineers to embed your models into production.\n",
      "Perform other related duties in keeping with the purpose and accountabilities of the job.\n",
      "\n",
      "M.Sc. or Ph.D. in Engineering/Computer Science, or an equivalent combination of experience and knowledge.\n",
      "2+ years' experience applying machine learning and deep learning concepts to real-world problems.\n",
      "Solid programming skills with a focus on writing clean/maintainable code, with 2+ years of experience in Python (preferred), Java, or C++ programming.\n",
      "Good knowledge of machine learning libraries (Tensorflow, Keras, Pytorch, Sklearn, etc.).\n",
      "Strong analytical ability and mathematical skills.\n",
      "Advanced knowledge of machine learning theory and state of the art practices.\n",
      "Matured communication and critical thinking ability to influence and propose analytics strategies that challenge status quo thinking.\n",
      "Preferences:\n",
      "Strong background in natural language processing and/or the application of deep learning to genomic/proteomic data.\n",
      "Background in genetics, virology, microbiology, or biochemistry.\n",
      "Familiarity with statistical analysis (such as experiment design and hypothesis testing).\n",
      "Proficiency in Linux environments.\n",
      "Knowledge of the Agile project management methodology.\n",
      "Portfolio of machine learning projects available for review.\n",
      "\n",
      "Aptitude for interdisciplinary collaboration.\n",
      "Highly conscientious with strong follow-through.\n",
      "Capable of performing research on best practices and communicating results to a non-expert audience.\n",
      "Able to apply domain knowledge to ambiguous and novel situations.\n",
      "#######################################################\n",
      "collaborate multidisciplinary team gain insight complex biochemical systems design computational models study various interactions interactions genomes proteins binding sites extract various features computational models communicate results back team predict behaviour new protein structures certain binding sites using computational models work team software engineers embed models production perform related duties keeping purpose accountabilities job sc ph engineering computer science equivalent combination experience knowledge years experience applying machine learning deep learning concepts real-world problems solid programming skills focus writing clean maintainable code years experience python preferred java c programming good knowledge machine learning libraries tensorflow keras pytorch sklearn etc strong analytical ability mathematical skills advanced knowledge machine learning theory state art practices matured communication critical thinking ability influence propose analytics strategies challenge status quo thinking preferences strong background natural language processing application deep learning genomic proteomic data background genetics virology microbiology biochemistry familiarity statistical analysis experiment design hypothesis testing proficiency linux environments knowledge agile project management methodology portfolio machine learning projects available review aptitude interdisciplinary collaboration highly conscientious strong follow-through capable performing research best practices communicating results non-expert audience able apply domain knowledge ambiguous novel situations\n",
      "#######################################################\n",
      "['collaborate', 'multidisciplinary', 'team', 'gain', 'insight', 'complex', 'biochemical', 'system', 'design', 'computational', 'model', 'study', 'various', 'interaction', 'interaction', 'genome', 'protein', 'binding', 'site', 'extract', 'various', 'feature', 'computational', 'model', 'communicate', 'result', 'back', 'team', 'predict', 'behaviour', 'new', 'protein', 'structure', 'certain', 'binding', 'site', 'using', 'computational', 'model', 'work', 'team', 'software', 'engineer', 'embed', 'model', 'production', 'perform', 'related', 'duty', 'keeping', 'purpose', 'accountability', 'job', 'sc', 'ph', 'engineering', 'computer', 'science', 'equivalent', 'combination', 'experience', 'knowledge', 'year', 'experience', 'applying', 'machine', 'learning', 'deep', 'learning', 'concept', 'real-world', 'problem', 'solid', 'programming', 'skill', 'focus', 'writing', 'clean', 'maintainable', 'code', 'year', 'experience', 'python', 'preferred', 'java', 'c', 'programming', 'good', 'knowledge', 'machine', 'learning', 'library', 'tensorflow', 'kera', 'pytorch', 'sklearn', 'etc', 'strong', 'analytical', 'ability', 'mathematical', 'skill', 'advanced', 'knowledge', 'machine', 'learning', 'theory', 'state', 'art', 'practice', 'matured', 'communication', 'critical', 'thinking', 'ability', 'influence', 'propose', 'analytics', 'strategy', 'challenge', 'status', 'quo', 'thinking', 'preference', 'strong', 'background', 'natural', 'language', 'processing', 'application', 'deep', 'learning', 'genomic', 'proteomic', 'data', 'background', 'genetics', 'virology', 'microbiology', 'biochemistry', 'familiarity', 'statistical', 'analysis', 'experiment', 'design', 'hypothesis', 'testing', 'proficiency', 'linux', 'environment', 'knowledge', 'agile', 'project', 'management', 'methodology', 'portfolio', 'machine', 'learning', 'project', 'available', 'review', 'aptitude', 'interdisciplinary', 'collaboration', 'highly', 'conscientious', 'strong', 'follow-through', 'capable', 'performing', 'research', 'best', 'practice', 'communicating', 'result', 'non-expert', 'audience', 'able', 'apply', 'domain', 'knowledge', 'ambiguous', 'novel', 'situation']\n",
      "#######################################################\n"
     ]
    }
   ],
   "source": [
    "cleaning_DF(df_Jobs,'Job_Description')\n",
    "tokenize_and_lemmatize(df_Jobs,'Job_Description')\n",
    "\n",
    "\n",
    "#Tomamos el job_description de la posición 5 como ejemplo (Machine Learning Engineer 2'):\n",
    "\n",
    "print(df_Jobs['Job_Description'].iloc[5])  \n",
    "#non-expert  debería mantenerse.\n",
    "#deberia juntar el Computer Science\n",
    "print(\"#######################################################\")\n",
    "print(df_Jobs['clean_Job_Description'].iloc[5]) \n",
    "print(\"#######################################################\")\n",
    "print(df_Jobs['tokens_Job_Description'].iloc[5]) \n",
    "print(\"#######################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Job_Description</th>\n",
       "      <th>clean_Job_Description</th>\n",
       "      <th>tokens_Job_Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Master’s degree or above in a STEM field, incl...</td>\n",
       "      <td>master degree stem field including limited com...</td>\n",
       "      <td>[master, degree, stem, field, including, limit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist 2</td>\n",
       "      <td>\\nReporting to the Director, Data &amp; Analytics,...</td>\n",
       "      <td>reporting director data analytics senior data ...</td>\n",
       "      <td>[reporting, director, data, analytics, senior,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HCM Consultant</td>\n",
       "      <td>\\nThe Oracle Cloud HCM Absence Consultant will...</td>\n",
       "      <td>oracle cloud hcm absence consultant responsibl...</td>\n",
       "      <td>[oracle, cloud, hcm, absence, consultant, resp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HCM Consultant 2</td>\n",
       "      <td>4+ years of experience in PeopleSoft or Oracle...</td>\n",
       "      <td>years experience peoplesoft oracle ebs impleme...</td>\n",
       "      <td>[year, experience, peoplesoft, oracle, eb, imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Leveraging the latest machine and deep learnin...</td>\n",
       "      <td>leveraging latest machine deep learning techni...</td>\n",
       "      <td>[leveraging, latest, machine, deep, learning, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Machine Learning Engineer 2</td>\n",
       "      <td>Collaborate with a multidisciplinary team to g...</td>\n",
       "      <td>collaborate multidisciplinary team gain insigh...</td>\n",
       "      <td>[collaborate, multidisciplinary, team, gain, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Security Specialist</td>\n",
       "      <td>Work in a fast-paced environment that combine ...</td>\n",
       "      <td>work fast-paced environment combine technical ...</td>\n",
       "      <td>[work, fast-paced, environment, combine, techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Security Specialist 2</td>\n",
       "      <td>\\n    Handling incoming requests for assistanc...</td>\n",
       "      <td>handling incoming requests assistance business...</td>\n",
       "      <td>[handling, incoming, request, assistance, busi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Web Developer Full Stack</td>\n",
       "      <td>\\n\\n    Graduate Degree in Information Technol...</td>\n",
       "      <td>graduate degree information technology similar...</td>\n",
       "      <td>[graduate, degree, information, technology, si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Web Developer Full Stack 2</td>\n",
       "      <td>\\n· Enter existing website codebases and exten...</td>\n",
       "      <td>enter existing website codebases extend functi...</td>\n",
       "      <td>[enter, existing, website, codebases, extend, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Job_Title  \\\n",
       "2               Data Scientist   \n",
       "3             Data Scientist 2   \n",
       "6               HCM Consultant   \n",
       "7             HCM Consultant 2   \n",
       "0    Machine Learning Engineer   \n",
       "1  Machine Learning Engineer 2   \n",
       "8          Security Specialist   \n",
       "9        Security Specialist 2   \n",
       "4     Web Developer Full Stack   \n",
       "5   Web Developer Full Stack 2   \n",
       "\n",
       "                                     Job_Description  \\\n",
       "2  Master’s degree or above in a STEM field, incl...   \n",
       "3  \\nReporting to the Director, Data & Analytics,...   \n",
       "6  \\nThe Oracle Cloud HCM Absence Consultant will...   \n",
       "7  4+ years of experience in PeopleSoft or Oracle...   \n",
       "0  Leveraging the latest machine and deep learnin...   \n",
       "1  Collaborate with a multidisciplinary team to g...   \n",
       "8  Work in a fast-paced environment that combine ...   \n",
       "9  \\n    Handling incoming requests for assistanc...   \n",
       "4  \\n\\n    Graduate Degree in Information Technol...   \n",
       "5  \\n· Enter existing website codebases and exten...   \n",
       "\n",
       "                               clean_Job_Description  \\\n",
       "2  master degree stem field including limited com...   \n",
       "3  reporting director data analytics senior data ...   \n",
       "6  oracle cloud hcm absence consultant responsibl...   \n",
       "7  years experience peoplesoft oracle ebs impleme...   \n",
       "0  leveraging latest machine deep learning techni...   \n",
       "1  collaborate multidisciplinary team gain insigh...   \n",
       "8  work fast-paced environment combine technical ...   \n",
       "9  handling incoming requests assistance business...   \n",
       "4  graduate degree information technology similar...   \n",
       "5  enter existing website codebases extend functi...   \n",
       "\n",
       "                              tokens_Job_Description  \n",
       "2  [master, degree, stem, field, including, limit...  \n",
       "3  [reporting, director, data, analytics, senior,...  \n",
       "6  [oracle, cloud, hcm, absence, consultant, resp...  \n",
       "7  [year, experience, peoplesoft, oracle, eb, imp...  \n",
       "0  [leveraging, latest, machine, deep, learning, ...  \n",
       "1  [collaborate, multidisciplinary, team, gain, i...  \n",
       "8  [work, fast-paced, environment, combine, techn...  \n",
       "9  [handling, incoming, request, assistance, busi...  \n",
       "4  [graduate, degree, information, technology, si...  \n",
       "5  [enter, existing, website, codebases, extend, ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpieza de datos del DF de Candidatos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Candidate_Name</th>\n",
       "      <th>Content_CV</th>\n",
       "      <th>clean_Content_CV</th>\n",
       "      <th>tokens_Content_CV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data_Scientist_Karla_Lewis</td>\n",
       "      <td>\\nKARLA LEWIS\\nData Scientist\\nCONTACT WORK EX...</td>\n",
       "      <td>karla lewis data scientist contact work experi...</td>\n",
       "      <td>[karla, lewis, data, scientist, contact, work,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data_Scientist_Rahul_Malik</td>\n",
       "      <td>\\nRAHUL MALIK\\nNLP Data Scientist\\nCONTACT WOR...</td>\n",
       "      <td>rahul malik nlp data scientist contact work ex...</td>\n",
       "      <td>[rahul, malik, nlp, data, scientist, contact, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HCM_Federico_Calonge</td>\n",
       "      <td>\\n                                            ...</td>\n",
       "      <td>calonge federico matías hcm technical consulta...</td>\n",
       "      <td>[calonge, federico, matías, hcm, technical, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HCM_Robert_Smith</td>\n",
       "      <td>\\nSap Hcm Consultant Phone: (123) 456 78 99\\nE...</td>\n",
       "      <td>sap hcm consultant phone email info qwikresume...</td>\n",
       "      <td>[sap, hcm, consultant, phone, email, info, qwi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ML_Engineer_Bradly_Johnston</td>\n",
       "      <td>\\nBradly Johnston\\n435 Kasey Vista, Detroit\\n+...</td>\n",
       "      <td>bradly johnston kasey vista detroit work exper...</td>\n",
       "      <td>[bradly, johnston, kasey, vista, detroit, work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ML_Engineer_Jonathon_Price</td>\n",
       "      <td>\\nJonathon Price \\n4587 Terry Groves, Boston\\n...</td>\n",
       "      <td>jonathon price terry groves boston experience ...</td>\n",
       "      <td>[jonathon, price, terry, grove, boston, experi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Security_Specialist_Ahmed Wayne</td>\n",
       "      <td>\\nAhmed Wayne\\nAddress: Abu Dhabi, UAE\\nNation...</td>\n",
       "      <td>ahmed wayne address abu dhabi uae nationality ...</td>\n",
       "      <td>[ahmed, wayne, address, abu, dhabi, uae, natio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Security_Specialist_Denis Banik</td>\n",
       "      <td>\\nDenis Banik\\nEmail address: hello@kickresume...</td>\n",
       "      <td>denis banik email address hello kickresume com...</td>\n",
       "      <td>[denis, banik, email, address, hello, kickresu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Web_Dev_Alec_Dionisio</td>\n",
       "      <td>\\nChestertown, MD 4107083942\\nhi@alecdionis.io...</td>\n",
       "      <td>chestertown md hi alecdionis io alecdionis io ...</td>\n",
       "      <td>[chestertown, md, hi, alecdionis, io, alecdion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Web_Dev_Karen_Higgins</td>\n",
       "      <td>\\nKaren Higgins \\n        We b Developer \\n \\n...</td>\n",
       "      <td>karen higgins b developer areas expertise pers...</td>\n",
       "      <td>[karen, higgins, b, developer, area, expertise...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Candidate_Name  \\\n",
       "6       Data_Scientist_Karla_Lewis   \n",
       "2       Data_Scientist_Rahul_Malik   \n",
       "4             HCM_Federico_Calonge   \n",
       "7                 HCM_Robert_Smith   \n",
       "0      ML_Engineer_Bradly_Johnston   \n",
       "1       ML_Engineer_Jonathon_Price   \n",
       "8  Security_Specialist_Ahmed Wayne   \n",
       "3  Security_Specialist_Denis Banik   \n",
       "5            Web_Dev_Alec_Dionisio   \n",
       "9            Web_Dev_Karen_Higgins   \n",
       "\n",
       "                                          Content_CV  \\\n",
       "6  \\nKARLA LEWIS\\nData Scientist\\nCONTACT WORK EX...   \n",
       "2  \\nRAHUL MALIK\\nNLP Data Scientist\\nCONTACT WOR...   \n",
       "4  \\n                                            ...   \n",
       "7  \\nSap Hcm Consultant Phone: (123) 456 78 99\\nE...   \n",
       "0  \\nBradly Johnston\\n435 Kasey Vista, Detroit\\n+...   \n",
       "1  \\nJonathon Price \\n4587 Terry Groves, Boston\\n...   \n",
       "8  \\nAhmed Wayne\\nAddress: Abu Dhabi, UAE\\nNation...   \n",
       "3  \\nDenis Banik\\nEmail address: hello@kickresume...   \n",
       "5  \\nChestertown, MD 4107083942\\nhi@alecdionis.io...   \n",
       "9  \\nKaren Higgins \\n        We b Developer \\n \\n...   \n",
       "\n",
       "                                    clean_Content_CV  \\\n",
       "6  karla lewis data scientist contact work experi...   \n",
       "2  rahul malik nlp data scientist contact work ex...   \n",
       "4  calonge federico matías hcm technical consulta...   \n",
       "7  sap hcm consultant phone email info qwikresume...   \n",
       "0  bradly johnston kasey vista detroit work exper...   \n",
       "1  jonathon price terry groves boston experience ...   \n",
       "8  ahmed wayne address abu dhabi uae nationality ...   \n",
       "3  denis banik email address hello kickresume com...   \n",
       "5  chestertown md hi alecdionis io alecdionis io ...   \n",
       "9  karen higgins b developer areas expertise pers...   \n",
       "\n",
       "                                   tokens_Content_CV  \n",
       "6  [karla, lewis, data, scientist, contact, work,...  \n",
       "2  [rahul, malik, nlp, data, scientist, contact, ...  \n",
       "4  [calonge, federico, matías, hcm, technical, co...  \n",
       "7  [sap, hcm, consultant, phone, email, info, qwi...  \n",
       "0  [bradly, johnston, kasey, vista, detroit, work...  \n",
       "1  [jonathon, price, terry, grove, boston, experi...  \n",
       "8  [ahmed, wayne, address, abu, dhabi, uae, natio...  \n",
       "3  [denis, banik, email, address, hello, kickresu...  \n",
       "5  [chestertown, md, hi, alecdionis, io, alecdion...  \n",
       "9  [karen, higgins, b, developer, area, expertise...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_DF(df_Candidates,'Content_CV')\n",
    "tokenize_and_lemmatize(df_Candidates,'Content_CV')\n",
    "\n",
    "df_Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['calonge',\n",
       " 'federico',\n",
       " 'matías',\n",
       " 'hcm',\n",
       " 'technical',\n",
       " 'consultant',\n",
       " 'federico',\n",
       " 'working',\n",
       " 'oracle',\n",
       " 'tool',\n",
       " 'since',\n",
       " 'october',\n",
       " 'march',\n",
       " 'participated',\n",
       " 'erp',\n",
       " 'cloud',\n",
       " 'project',\n",
       " 'performing',\n",
       " 'reporting',\n",
       " 'task',\n",
       " 'working',\n",
       " 'module',\n",
       " 'ap',\n",
       " 'ar',\n",
       " 'gl',\n",
       " 'since',\n",
       " 'march',\n",
       " 'participating',\n",
       " 'hcm',\n",
       " 'cloud',\n",
       " 'project',\n",
       " 'performing',\n",
       " 'reporting',\n",
       " 'extraction',\n",
       " 'integration',\n",
       " 'task',\n",
       " 'working',\n",
       " 'module',\n",
       " 'core',\n",
       " 'recruitment',\n",
       " 'since',\n",
       " 'october',\n",
       " 'member',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'ai',\n",
       " 'committee',\n",
       " 'oracle',\n",
       " 'strong',\n",
       " 'interest',\n",
       " 'data',\n",
       " 'science',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'last',\n",
       " 'year',\n",
       " 'computer',\n",
       " 'engineering',\n",
       " 'degree',\n",
       " 'studying',\n",
       " 'th',\n",
       " 'year',\n",
       " 'english',\n",
       " 'personal',\n",
       " 'academic',\n",
       " 'programming',\n",
       " 'project',\n",
       " 'http',\n",
       " 'github',\n",
       " 'com',\n",
       " 'federicocalonge',\n",
       " 'skill',\n",
       " 'summary',\n",
       " 'oracle',\n",
       " 'hcm',\n",
       " 'cloud',\n",
       " 'core',\n",
       " 'recruitment',\n",
       " 'oracle',\n",
       " 'erp',\n",
       " 'cloud',\n",
       " 'account',\n",
       " 'receivable',\n",
       " 'ar',\n",
       " 'account',\n",
       " 'payable',\n",
       " 'ap',\n",
       " 'general',\n",
       " 'ledger',\n",
       " 'gl',\n",
       " 'main',\n",
       " 'experience',\n",
       " 'reporting',\n",
       " 'sql',\n",
       " 'bi',\n",
       " 'publisher',\n",
       " 'intermediate-advanced',\n",
       " 'point',\n",
       " 'technical',\n",
       " 'documentation',\n",
       " 'extraction',\n",
       " 'api',\n",
       " 'rest',\n",
       " 'hcm',\n",
       " 'extract',\n",
       " 'web',\n",
       " 'service',\n",
       " 'soap',\n",
       " 'basic-intermediate',\n",
       " 'integration',\n",
       " 'hdl',\n",
       " 'basic-intermediate',\n",
       " 'extra',\n",
       " 'data',\n",
       " 'analysis',\n",
       " 'implementation',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'algorithm',\n",
       " 'python',\n",
       " 'intermediate',\n",
       " 'calonge',\n",
       " 'federico',\n",
       " 'matias',\n",
       " 'oracle',\n",
       " 'consultant',\n",
       " 'page',\n",
       " 'professional',\n",
       " 'experience',\n",
       " 'oracle',\n",
       " 'hcm',\n",
       " 'implementation',\n",
       " 'technical',\n",
       " 'consultant',\n",
       " 'report',\n",
       " 'core',\n",
       " 'assembling',\n",
       " 'do',\n",
       " 'pinos',\n",
       " 'cr',\n",
       " 'technical',\n",
       " 'documentation',\n",
       " 'extraction',\n",
       " 'web',\n",
       " 'service',\n",
       " 'may-',\n",
       " 'soap',\n",
       " 'hcm',\n",
       " 'extract',\n",
       " 'absence',\n",
       " 'time',\n",
       " 'extraction',\n",
       " 'rest',\n",
       " 'api',\n",
       " 'integration',\n",
       " 'hdl',\n",
       " 'oracle',\n",
       " 'hcm',\n",
       " 'implementation',\n",
       " 'technical',\n",
       " 'consultant',\n",
       " 'report',\n",
       " 'core',\n",
       " 'personal',\n",
       " 'usta',\n",
       " 'col',\n",
       " 'profile',\n",
       " 'data',\n",
       " 'recruitment',\n",
       " 'selection',\n",
       " 'candidate',\n",
       " '-',\n",
       " 'apr-',\n",
       " 'feedback',\n",
       " 'oracle',\n",
       " 'hcm',\n",
       " 'implementation',\n",
       " 'technical',\n",
       " 'consultant',\n",
       " 'bank',\n",
       " 'reconciliation',\n",
       " 'report',\n",
       " 'consorcio',\n",
       " 'chi',\n",
       " 'jan-',\n",
       " 'oracle',\n",
       " 'hcm',\n",
       " 'implementation',\n",
       " 'technical',\n",
       " 'consultant',\n",
       " 'daily',\n",
       " 'book',\n",
       " 'purchase',\n",
       " 'book',\n",
       " 'sky',\n",
       " 'airline',\n",
       " 'chi',\n",
       " 'report',\n",
       " 'taking',\n",
       " 'account',\n",
       " 'tax',\n",
       " 'withholding',\n",
       " 'applied',\n",
       " 'dec-',\n",
       " 'accomplishment',\n",
       " 'education',\n",
       " 'national',\n",
       " 'university',\n",
       " 'avellaneda',\n",
       " 'undav',\n",
       " '-',\n",
       " 'computer',\n",
       " 'engineering',\n",
       " 'orientation',\n",
       " 'distributed',\n",
       " 'system',\n",
       " '-',\n",
       " 'progress',\n",
       " 'approved',\n",
       " 'subject',\n",
       " 'thesis',\n",
       " 'progress',\n",
       " 'oriented',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'applied',\n",
       " 'human',\n",
       " 'resource',\n",
       " 'language',\n",
       " 'spanish',\n",
       " 'native',\n",
       " 'english',\n",
       " 'intermediate',\n",
       " '-',\n",
       " 'advanced',\n",
       " 'th',\n",
       " 'year',\n",
       " 'cambridge',\n",
       " 'institute',\n",
       " 'approved',\n",
       " 'calonge',\n",
       " 'federico',\n",
       " 'matias',\n",
       " '-',\n",
       " 'oracle',\n",
       " 'consultant',\n",
       " 'page']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vemos los tokens generados para el candidato HCM_Federico_Calonge:\n",
    "df_Candidates.iloc[2]['tokens_Content_CV']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AGREGADO: Funciones para tokenizar textos de una columna de un DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/fedricio/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/fedricio/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import string\n",
    "#Esto de arriba se descarga LOCALMENTE en home/user/nltk_data.\n",
    "\n",
    "def tokenize(text):\n",
    "    #Convierte el texto recibido como entrada en una lista de tokens (palabras).\n",
    "    #Dentro pasamos todo a minusculas, se eliminan signos de puntuación, espacios en blanco y se eliminan las stop words.\n",
    "        #input  --> text: el documento como un STRING. \n",
    "        #output --> texts_tokens: cada palabra del texto en una LISTA de string. \n",
    "    texts_tokens=[]\n",
    "    for line in text:\n",
    "        tokens=word_tokenize(line)\n",
    "        tok=[w.lower() for w in tokens]\n",
    "        table=str.maketrans('','',string.punctuation)\n",
    "        strpp=[w.translate(table) for w in tok]\n",
    "        words=[word for word in strpp if word.isalpha()]\n",
    "        stop_words=set(stopwords.words('english'))\n",
    "        words=[w for w in words if not w in stop_words]\n",
    "        texts_tokens.append(words)\n",
    "    return texts_tokens\n",
    "\n",
    "def text_to_vector(text):\n",
    "    #Convierte el texto del documento en una \"term matrix\" donde todas las palabras estan listadas junto a \n",
    "    #la frecuencia en que aparecen en el texto.\n",
    "        #input  --> text: el documento como una LISTA de string. \n",
    "        #output --> Term matrix: una MATRIZ con cada palabra del documento junto a su frecuencia. \n",
    "        \n",
    "    texts_tokens = tokenize(text)\n",
    "    #print(texts_tokens)\n",
    "    return Counter(texts_tokens[0]) #[0] porque es una lista dentro de otra lista."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FUNCION QUE USABA ANTES.\n",
    "\n",
    "def text_to_vector(text):\n",
    "    #Convierte el texto del documento en una \"term matrix\" donde todas las palabras estan listadas junto a \n",
    "    #la frecuencia en que aparecen en el texto.\n",
    "        #input  --> text: el documento como una LISTA de string. \n",
    "        #output --> Term matrix: una MATRIZ con cada palabra del documento junto a su frecuencia. \n",
    "        \n",
    "    texts_tokens = tokenize(text)\n",
    "    #print(texts_tokens)\n",
    "    return Counter(texts_tokens[0]) #[0] porque es una lista dentro de otra lista.\n",
    "\n",
    "def text_to_vector_TF_IDF(text):\n",
    "    #Convierte el texto del documento en una \"term matrix\" donde todas las palabras estan listadas junto a \n",
    "    #la frecuencia en que aparecen en el texto.\n",
    "        #input  --> text: el documento como una LISTA de string. \n",
    "        #output --> Term matrix: una MATRIZ con cada palabra del documento junto a su frecuencia. \n",
    "        \n",
    "    texts_tokens = tokenize(text)\n",
    "    #print(texts_tokens)\n",
    "    return Counter(texts_tokens[0]) #[0] porque es una lista dentro de otra lista.\n",
    "\n",
    "\n",
    "#REAL:\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "col_one_list = df_Jobs['Job_Description'].tolist()\n",
    "corpus = col_one_list\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Initialize an instance of tf-idf Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Generate the tf-idf vectors for the corpus\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# compute and print the cosine similarity matrix\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "print(cosine_sim)\n",
    "\n",
    "\n",
    "def get_cosine(doc1, doc2):\n",
    "    #Get the cosine similarity between two documents.\n",
    "    #Depends on the angle between two non zero vectors which are constructed by each word frequency in the two documents.\n",
    "        #input  --> doc1: the first document as STRING.\n",
    "                    #doc2: the second document as STRING.\n",
    "        #output --> cosine similarity score\n",
    "    \n",
    "    #vec1 = text_to_vector([doc1])\n",
    "    #print(vec1)\n",
    "    #vec2 = text_to_vector([doc2])\n",
    "   \n",
    "    vec1 = text_to_vector_TF_IDF([doc1])\n",
    "    #print(vec1)\n",
    "    vec2 = text_to_vector_TF_IDF([doc2])\n",
    "    \n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "    sum1 = sum([vec1[x] ** 2 for x in list(vec1.keys())])\n",
    "    sum2 = sum([vec2[x] ** 2 for x in list(vec2.keys())])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'business': 6, 'learning': 5, 'data': 4, 'experience': 4, 'machine': 3, 'deep': 3, 'across': 3, 'cloud': 3, 'ability': 3, 'practices': 2, 'units': 2, 'unit': 2, 'performance': 2, 'new': 2, 'development': 2, 'technical': 2, 'organization': 2, 'managing': 2, 'algorithms': 2, 'tools': 2, 'etc': 2, 'industry': 2, 'computer': 2, 'engineering': 2, 'proficient': 2, 'knowledge': 2, 'environment': 2, 'aws': 2, 'gcp': 2, 'projects': 2, 'highly': 2, 'skills': 2, 'leveraging': 1, 'latest': 1, 'techniques': 1, 'challenge': 1, 'current': 1, 'enhancing': 1, 'internal': 1, 'collaboration': 1, 'alignment': 1, 'people': 1, 'processes': 1, 'technologies': 1, 'goals': 1, 'proposing': 1, 'best': 1, 'optimize': 1, 'presence': 1, 'security': 1, 'cost': 1, 'develop': 1, 'specs': 1, 'documentation': 1, 'partake': 1, 'procedures': 1, 'user': 1, 'support': 1, 'guides': 1, 'carry': 1, 'debugging': 1, 'troubleshooting': 1, 'modifications': 1, 'testing': 1, 'custom': 1, 'solutions': 1, 'built': 1, 'platform': 1, 'code': 1, 'artifacts': 1, 'including': 1, 'models': 1, 'templates': 1, 'policies': 1, 'guidelines': 1, 'measuring': 1, 'comparing': 1, 'results': 1, 'similar': 1, 'efforts': 1, 'working': 1, 'different': 1, 'organizations': 1, 'company': 1, 'understand': 1, 'needs': 1, 'help': 1, 'identify': 1, 'opportunities': 1, 'mentoring': 1, 'coaching': 1, 'training': 1, 'fellow': 1, 'master': 1, 'degree': 1, 'science': 1, 'software': 1, 'applied': 1, 'mathematics': 1, 'statistics': 1, 'analytics': 1, 'agribusiness': 1, 'accounting': 1, 'finance': 1, 'economics': 1, 'equivalent': 1, 'particularly': 1, 'bi': 1, 'expertise': 1, 'visionbased': 1, 'python': 1, 'sql': 1, 'solid': 1, 'handson': 1, 'regression': 1, 'classification': 1, 'clustering': 1, 'dimensionality': 1, 'reduction': 1, 'cnn': 1, 'rnn': 1, 'lstm': 1, 'gan': 1, 'timeseries': 1, 'anomaly': 1, 'detection': 1, 'statistical': 1, 'mining': 1, 'keras': 1, 'tensorflow': 1, 'pytorch': 1, 'computing': 1, 'infrastructures': 1, 'azure': 1, 'strong': 1, 'use': 1, 'logic': 1, 'excellent': 1, 'problemsolving': 1, 'work': 1, 'independently': 1, 'flexible': 1, 'thrive': 1, 'fastpaced': 1, 'dynamic': 1, 'demonstrated': 1, 'agile': 1, 'rapid': 1, 'methods': 1, 'passion': 1, 'innovation': 1, 'attitude': 1, 'agricultural': 1, 'edge': 1, 'plus': 1})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.478"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_job_descr = df_Jobs.loc[0,'clean_Job_Description']\n",
    "first_content_cv = df_Candidates.loc[0,'clean_Content_CV']\n",
    "\n",
    "cosine_result = round(get_cosine(first_job_descr,first_content_cv),3)\n",
    "cosine_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AHORA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Candidate_Name</th>\n",
       "      <th>Content_CV</th>\n",
       "      <th>clean_Content_CV</th>\n",
       "      <th>tokens_Content_CV</th>\n",
       "      <th>tfidf_cosine</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Job_Description</th>\n",
       "      <th>clean_Job_Description</th>\n",
       "      <th>tokens_Job_Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data_Scientist_Karla_Lewis</td>\n",
       "      <td>\\nKARLA LEWIS\\nData Scientist\\nCONTACT WORK EX...</td>\n",
       "      <td>karla lewis data scientist contact work experi...</td>\n",
       "      <td>[karla, lewis, data, scientist, contact, work,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Master’s degree or above in a STEM field, incl...</td>\n",
       "      <td>master degree stem field including limited com...</td>\n",
       "      <td>[master, degree, stem, field, including, limit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data_Scientist_Karla_Lewis</td>\n",
       "      <td>\\nKARLA LEWIS\\nData Scientist\\nCONTACT WORK EX...</td>\n",
       "      <td>karla lewis data scientist contact work experi...</td>\n",
       "      <td>[karla, lewis, data, scientist, contact, work,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Data Scientist 2</td>\n",
       "      <td>\\nReporting to the Director, Data &amp; Analytics,...</td>\n",
       "      <td>reporting director data analytics senior data ...</td>\n",
       "      <td>[reporting, director, data, analytics, senior,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data_Scientist_Karla_Lewis</td>\n",
       "      <td>\\nKARLA LEWIS\\nData Scientist\\nCONTACT WORK EX...</td>\n",
       "      <td>karla lewis data scientist contact work experi...</td>\n",
       "      <td>[karla, lewis, data, scientist, contact, work,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HCM Consultant</td>\n",
       "      <td>\\nThe Oracle Cloud HCM Absence Consultant will...</td>\n",
       "      <td>oracle cloud hcm absence consultant responsibl...</td>\n",
       "      <td>[oracle, cloud, hcm, absence, consultant, resp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data_Scientist_Karla_Lewis</td>\n",
       "      <td>\\nKARLA LEWIS\\nData Scientist\\nCONTACT WORK EX...</td>\n",
       "      <td>karla lewis data scientist contact work experi...</td>\n",
       "      <td>[karla, lewis, data, scientist, contact, work,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HCM Consultant 2</td>\n",
       "      <td>4+ years of experience in PeopleSoft or Oracle...</td>\n",
       "      <td>years experience peoplesoft oracle ebs impleme...</td>\n",
       "      <td>[year, experience, peoplesoft, oracle, eb, imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data_Scientist_Karla_Lewis</td>\n",
       "      <td>\\nKARLA LEWIS\\nData Scientist\\nCONTACT WORK EX...</td>\n",
       "      <td>karla lewis data scientist contact work experi...</td>\n",
       "      <td>[karla, lewis, data, scientist, contact, work,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Leveraging the latest machine and deep learnin...</td>\n",
       "      <td>leveraging latest machine deep learning techni...</td>\n",
       "      <td>[leveraging, latest, machine, deep, learning, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Web_Dev_Karen_Higgins</td>\n",
       "      <td>\\nKaren Higgins \\n        We b Developer \\n \\n...</td>\n",
       "      <td>karen higgins b developer areas expertise pers...</td>\n",
       "      <td>[karen, higgins, b, developer, area, expertise...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Machine Learning Engineer 2</td>\n",
       "      <td>Collaborate with a multidisciplinary team to g...</td>\n",
       "      <td>collaborate multidisciplinary team gain insigh...</td>\n",
       "      <td>[collaborate, multidisciplinary, team, gain, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Web_Dev_Karen_Higgins</td>\n",
       "      <td>\\nKaren Higgins \\n        We b Developer \\n \\n...</td>\n",
       "      <td>karen higgins b developer areas expertise pers...</td>\n",
       "      <td>[karen, higgins, b, developer, area, expertise...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Security Specialist</td>\n",
       "      <td>Work in a fast-paced environment that combine ...</td>\n",
       "      <td>work fast-paced environment combine technical ...</td>\n",
       "      <td>[work, fast-paced, environment, combine, techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Web_Dev_Karen_Higgins</td>\n",
       "      <td>\\nKaren Higgins \\n        We b Developer \\n \\n...</td>\n",
       "      <td>karen higgins b developer areas expertise pers...</td>\n",
       "      <td>[karen, higgins, b, developer, area, expertise...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Security Specialist 2</td>\n",
       "      <td>\\n    Handling incoming requests for assistanc...</td>\n",
       "      <td>handling incoming requests assistance business...</td>\n",
       "      <td>[handling, incoming, request, assistance, busi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Web_Dev_Karen_Higgins</td>\n",
       "      <td>\\nKaren Higgins \\n        We b Developer \\n \\n...</td>\n",
       "      <td>karen higgins b developer areas expertise pers...</td>\n",
       "      <td>[karen, higgins, b, developer, area, expertise...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Web Developer Full Stack</td>\n",
       "      <td>\\n\\n    Graduate Degree in Information Technol...</td>\n",
       "      <td>graduate degree information technology similar...</td>\n",
       "      <td>[graduate, degree, information, technology, si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Web_Dev_Karen_Higgins</td>\n",
       "      <td>\\nKaren Higgins \\n        We b Developer \\n \\n...</td>\n",
       "      <td>karen higgins b developer areas expertise pers...</td>\n",
       "      <td>[karen, higgins, b, developer, area, expertise...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Web Developer Full Stack 2</td>\n",
       "      <td>\\n· Enter existing website codebases and exten...</td>\n",
       "      <td>enter existing website codebases extend functi...</td>\n",
       "      <td>[enter, existing, website, codebases, extend, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Candidate_Name  \\\n",
       "0   Data_Scientist_Karla_Lewis   \n",
       "1   Data_Scientist_Karla_Lewis   \n",
       "2   Data_Scientist_Karla_Lewis   \n",
       "3   Data_Scientist_Karla_Lewis   \n",
       "4   Data_Scientist_Karla_Lewis   \n",
       "..                         ...   \n",
       "95       Web_Dev_Karen_Higgins   \n",
       "96       Web_Dev_Karen_Higgins   \n",
       "97       Web_Dev_Karen_Higgins   \n",
       "98       Web_Dev_Karen_Higgins   \n",
       "99       Web_Dev_Karen_Higgins   \n",
       "\n",
       "                                           Content_CV  \\\n",
       "0   \\nKARLA LEWIS\\nData Scientist\\nCONTACT WORK EX...   \n",
       "1   \\nKARLA LEWIS\\nData Scientist\\nCONTACT WORK EX...   \n",
       "2   \\nKARLA LEWIS\\nData Scientist\\nCONTACT WORK EX...   \n",
       "3   \\nKARLA LEWIS\\nData Scientist\\nCONTACT WORK EX...   \n",
       "4   \\nKARLA LEWIS\\nData Scientist\\nCONTACT WORK EX...   \n",
       "..                                                ...   \n",
       "95  \\nKaren Higgins \\n        We b Developer \\n \\n...   \n",
       "96  \\nKaren Higgins \\n        We b Developer \\n \\n...   \n",
       "97  \\nKaren Higgins \\n        We b Developer \\n \\n...   \n",
       "98  \\nKaren Higgins \\n        We b Developer \\n \\n...   \n",
       "99  \\nKaren Higgins \\n        We b Developer \\n \\n...   \n",
       "\n",
       "                                     clean_Content_CV  \\\n",
       "0   karla lewis data scientist contact work experi...   \n",
       "1   karla lewis data scientist contact work experi...   \n",
       "2   karla lewis data scientist contact work experi...   \n",
       "3   karla lewis data scientist contact work experi...   \n",
       "4   karla lewis data scientist contact work experi...   \n",
       "..                                                ...   \n",
       "95  karen higgins b developer areas expertise pers...   \n",
       "96  karen higgins b developer areas expertise pers...   \n",
       "97  karen higgins b developer areas expertise pers...   \n",
       "98  karen higgins b developer areas expertise pers...   \n",
       "99  karen higgins b developer areas expertise pers...   \n",
       "\n",
       "                                    tokens_Content_CV  tfidf_cosine  \\\n",
       "0   [karla, lewis, data, scientist, contact, work,...           1.0   \n",
       "1   [karla, lewis, data, scientist, contact, work,...           1.0   \n",
       "2   [karla, lewis, data, scientist, contact, work,...           1.0   \n",
       "3   [karla, lewis, data, scientist, contact, work,...           1.0   \n",
       "4   [karla, lewis, data, scientist, contact, work,...           1.0   \n",
       "..                                                ...           ...   \n",
       "95  [karen, higgins, b, developer, area, expertise...           1.0   \n",
       "96  [karen, higgins, b, developer, area, expertise...           1.0   \n",
       "97  [karen, higgins, b, developer, area, expertise...           1.0   \n",
       "98  [karen, higgins, b, developer, area, expertise...           1.0   \n",
       "99  [karen, higgins, b, developer, area, expertise...           1.0   \n",
       "\n",
       "                      Job_Title  \\\n",
       "0                Data Scientist   \n",
       "1              Data Scientist 2   \n",
       "2                HCM Consultant   \n",
       "3              HCM Consultant 2   \n",
       "4     Machine Learning Engineer   \n",
       "..                          ...   \n",
       "95  Machine Learning Engineer 2   \n",
       "96          Security Specialist   \n",
       "97        Security Specialist 2   \n",
       "98     Web Developer Full Stack   \n",
       "99   Web Developer Full Stack 2   \n",
       "\n",
       "                                      Job_Description  \\\n",
       "0   Master’s degree or above in a STEM field, incl...   \n",
       "1   \\nReporting to the Director, Data & Analytics,...   \n",
       "2   \\nThe Oracle Cloud HCM Absence Consultant will...   \n",
       "3   4+ years of experience in PeopleSoft or Oracle...   \n",
       "4   Leveraging the latest machine and deep learnin...   \n",
       "..                                                ...   \n",
       "95  Collaborate with a multidisciplinary team to g...   \n",
       "96  Work in a fast-paced environment that combine ...   \n",
       "97  \\n    Handling incoming requests for assistanc...   \n",
       "98  \\n\\n    Graduate Degree in Information Technol...   \n",
       "99  \\n· Enter existing website codebases and exten...   \n",
       "\n",
       "                                clean_Job_Description  \\\n",
       "0   master degree stem field including limited com...   \n",
       "1   reporting director data analytics senior data ...   \n",
       "2   oracle cloud hcm absence consultant responsibl...   \n",
       "3   years experience peoplesoft oracle ebs impleme...   \n",
       "4   leveraging latest machine deep learning techni...   \n",
       "..                                                ...   \n",
       "95  collaborate multidisciplinary team gain insigh...   \n",
       "96  work fast-paced environment combine technical ...   \n",
       "97  handling incoming requests assistance business...   \n",
       "98  graduate degree information technology similar...   \n",
       "99  enter existing website codebases extend functi...   \n",
       "\n",
       "                               tokens_Job_Description  \n",
       "0   [master, degree, stem, field, including, limit...  \n",
       "1   [reporting, director, data, analytics, senior,...  \n",
       "2   [oracle, cloud, hcm, absence, consultant, resp...  \n",
       "3   [year, experience, peoplesoft, oracle, eb, imp...  \n",
       "4   [leveraging, latest, machine, deep, learning, ...  \n",
       "..                                                ...  \n",
       "95  [collaborate, multidisciplinary, team, gain, i...  \n",
       "96  [work, fast-paced, environment, combine, techn...  \n",
       "97  [handling, incoming, request, assistance, busi...  \n",
       "98  [graduate, degree, information, technology, si...  \n",
       "99  [enter, existing, website, codebases, extend, ...  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Nos quedarán 10 x 10 = 100 filas.\n",
    "df_Jobs_and_Candidates = pd.merge(df_Candidates.assign(A=1), df_Jobs.assign(A=1), on='A').drop('A', 1)\n",
    "df_Jobs_and_Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Candidate_Name</th>\n",
       "      <th>Content_CV</th>\n",
       "      <th>clean_Content_CV</th>\n",
       "      <th>tokens_Content_CV</th>\n",
       "      <th>tfidf_cosine</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Job_Description</th>\n",
       "      <th>clean_Job_Description</th>\n",
       "      <th>tokens_Job_Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data_Scientist_Karla_Lewis</td>\n",
       "      <td>\\nKARLA LEWIS\\nData Scientist\\nCONTACT WORK EX...</td>\n",
       "      <td>karla lewis data scientist contact work experi...</td>\n",
       "      <td>[karla, lewis, data, scientist, contact, work,...</td>\n",
       "      <td>0.058337</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Master’s degree or above in a STEM field, incl...</td>\n",
       "      <td>master degree stem field including limited com...</td>\n",
       "      <td>[master, degree, stem, field, including, limit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data_Scientist_Karla_Lewis</td>\n",
       "      <td>\\nKARLA LEWIS\\nData Scientist\\nCONTACT WORK EX...</td>\n",
       "      <td>karla lewis data scientist contact work experi...</td>\n",
       "      <td>[karla, lewis, data, scientist, contact, work,...</td>\n",
       "      <td>0.099616</td>\n",
       "      <td>Data Scientist 2</td>\n",
       "      <td>\\nReporting to the Director, Data &amp; Analytics,...</td>\n",
       "      <td>reporting director data analytics senior data ...</td>\n",
       "      <td>[reporting, director, data, analytics, senior,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data_Scientist_Karla_Lewis</td>\n",
       "      <td>\\nKARLA LEWIS\\nData Scientist\\nCONTACT WORK EX...</td>\n",
       "      <td>karla lewis data scientist contact work experi...</td>\n",
       "      <td>[karla, lewis, data, scientist, contact, work,...</td>\n",
       "      <td>0.028673</td>\n",
       "      <td>HCM Consultant</td>\n",
       "      <td>\\nThe Oracle Cloud HCM Absence Consultant will...</td>\n",
       "      <td>oracle cloud hcm absence consultant responsibl...</td>\n",
       "      <td>[oracle, cloud, hcm, absence, consultant, resp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data_Scientist_Karla_Lewis</td>\n",
       "      <td>\\nKARLA LEWIS\\nData Scientist\\nCONTACT WORK EX...</td>\n",
       "      <td>karla lewis data scientist contact work experi...</td>\n",
       "      <td>[karla, lewis, data, scientist, contact, work,...</td>\n",
       "      <td>0.020506</td>\n",
       "      <td>HCM Consultant 2</td>\n",
       "      <td>4+ years of experience in PeopleSoft or Oracle...</td>\n",
       "      <td>years experience peoplesoft oracle ebs impleme...</td>\n",
       "      <td>[year, experience, peoplesoft, oracle, eb, imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data_Scientist_Karla_Lewis</td>\n",
       "      <td>\\nKARLA LEWIS\\nData Scientist\\nCONTACT WORK EX...</td>\n",
       "      <td>karla lewis data scientist contact work experi...</td>\n",
       "      <td>[karla, lewis, data, scientist, contact, work,...</td>\n",
       "      <td>0.051409</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Leveraging the latest machine and deep learnin...</td>\n",
       "      <td>leveraging latest machine deep learning techni...</td>\n",
       "      <td>[leveraging, latest, machine, deep, learning, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Web_Dev_Karen_Higgins</td>\n",
       "      <td>\\nKaren Higgins \\n        We b Developer \\n \\n...</td>\n",
       "      <td>karen higgins b developer areas expertise pers...</td>\n",
       "      <td>[karen, higgins, b, developer, area, expertise...</td>\n",
       "      <td>0.074330</td>\n",
       "      <td>Machine Learning Engineer 2</td>\n",
       "      <td>Collaborate with a multidisciplinary team to g...</td>\n",
       "      <td>collaborate multidisciplinary team gain insigh...</td>\n",
       "      <td>[collaborate, multidisciplinary, team, gain, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Web_Dev_Karen_Higgins</td>\n",
       "      <td>\\nKaren Higgins \\n        We b Developer \\n \\n...</td>\n",
       "      <td>karen higgins b developer areas expertise pers...</td>\n",
       "      <td>[karen, higgins, b, developer, area, expertise...</td>\n",
       "      <td>0.081982</td>\n",
       "      <td>Security Specialist</td>\n",
       "      <td>Work in a fast-paced environment that combine ...</td>\n",
       "      <td>work fast-paced environment combine technical ...</td>\n",
       "      <td>[work, fast-paced, environment, combine, techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Web_Dev_Karen_Higgins</td>\n",
       "      <td>\\nKaren Higgins \\n        We b Developer \\n \\n...</td>\n",
       "      <td>karen higgins b developer areas expertise pers...</td>\n",
       "      <td>[karen, higgins, b, developer, area, expertise...</td>\n",
       "      <td>0.051793</td>\n",
       "      <td>Security Specialist 2</td>\n",
       "      <td>\\n    Handling incoming requests for assistanc...</td>\n",
       "      <td>handling incoming requests assistance business...</td>\n",
       "      <td>[handling, incoming, request, assistance, busi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Web_Dev_Karen_Higgins</td>\n",
       "      <td>\\nKaren Higgins \\n        We b Developer \\n \\n...</td>\n",
       "      <td>karen higgins b developer areas expertise pers...</td>\n",
       "      <td>[karen, higgins, b, developer, area, expertise...</td>\n",
       "      <td>0.100100</td>\n",
       "      <td>Web Developer Full Stack</td>\n",
       "      <td>\\n\\n    Graduate Degree in Information Technol...</td>\n",
       "      <td>graduate degree information technology similar...</td>\n",
       "      <td>[graduate, degree, information, technology, si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Web_Dev_Karen_Higgins</td>\n",
       "      <td>\\nKaren Higgins \\n        We b Developer \\n \\n...</td>\n",
       "      <td>karen higgins b developer areas expertise pers...</td>\n",
       "      <td>[karen, higgins, b, developer, area, expertise...</td>\n",
       "      <td>0.127268</td>\n",
       "      <td>Web Developer Full Stack 2</td>\n",
       "      <td>\\n· Enter existing website codebases and exten...</td>\n",
       "      <td>enter existing website codebases extend functi...</td>\n",
       "      <td>[enter, existing, website, codebases, extend, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Candidate_Name  \\\n",
       "0   Data_Scientist_Karla_Lewis   \n",
       "1   Data_Scientist_Karla_Lewis   \n",
       "2   Data_Scientist_Karla_Lewis   \n",
       "3   Data_Scientist_Karla_Lewis   \n",
       "4   Data_Scientist_Karla_Lewis   \n",
       "..                         ...   \n",
       "95       Web_Dev_Karen_Higgins   \n",
       "96       Web_Dev_Karen_Higgins   \n",
       "97       Web_Dev_Karen_Higgins   \n",
       "98       Web_Dev_Karen_Higgins   \n",
       "99       Web_Dev_Karen_Higgins   \n",
       "\n",
       "                                           Content_CV  \\\n",
       "0   \\nKARLA LEWIS\\nData Scientist\\nCONTACT WORK EX...   \n",
       "1   \\nKARLA LEWIS\\nData Scientist\\nCONTACT WORK EX...   \n",
       "2   \\nKARLA LEWIS\\nData Scientist\\nCONTACT WORK EX...   \n",
       "3   \\nKARLA LEWIS\\nData Scientist\\nCONTACT WORK EX...   \n",
       "4   \\nKARLA LEWIS\\nData Scientist\\nCONTACT WORK EX...   \n",
       "..                                                ...   \n",
       "95  \\nKaren Higgins \\n        We b Developer \\n \\n...   \n",
       "96  \\nKaren Higgins \\n        We b Developer \\n \\n...   \n",
       "97  \\nKaren Higgins \\n        We b Developer \\n \\n...   \n",
       "98  \\nKaren Higgins \\n        We b Developer \\n \\n...   \n",
       "99  \\nKaren Higgins \\n        We b Developer \\n \\n...   \n",
       "\n",
       "                                     clean_Content_CV  \\\n",
       "0   karla lewis data scientist contact work experi...   \n",
       "1   karla lewis data scientist contact work experi...   \n",
       "2   karla lewis data scientist contact work experi...   \n",
       "3   karla lewis data scientist contact work experi...   \n",
       "4   karla lewis data scientist contact work experi...   \n",
       "..                                                ...   \n",
       "95  karen higgins b developer areas expertise pers...   \n",
       "96  karen higgins b developer areas expertise pers...   \n",
       "97  karen higgins b developer areas expertise pers...   \n",
       "98  karen higgins b developer areas expertise pers...   \n",
       "99  karen higgins b developer areas expertise pers...   \n",
       "\n",
       "                                    tokens_Content_CV  tfidf_cosine  \\\n",
       "0   [karla, lewis, data, scientist, contact, work,...      0.058337   \n",
       "1   [karla, lewis, data, scientist, contact, work,...      0.099616   \n",
       "2   [karla, lewis, data, scientist, contact, work,...      0.028673   \n",
       "3   [karla, lewis, data, scientist, contact, work,...      0.020506   \n",
       "4   [karla, lewis, data, scientist, contact, work,...      0.051409   \n",
       "..                                                ...           ...   \n",
       "95  [karen, higgins, b, developer, area, expertise...      0.074330   \n",
       "96  [karen, higgins, b, developer, area, expertise...      0.081982   \n",
       "97  [karen, higgins, b, developer, area, expertise...      0.051793   \n",
       "98  [karen, higgins, b, developer, area, expertise...      0.100100   \n",
       "99  [karen, higgins, b, developer, area, expertise...      0.127268   \n",
       "\n",
       "                      Job_Title  \\\n",
       "0                Data Scientist   \n",
       "1              Data Scientist 2   \n",
       "2                HCM Consultant   \n",
       "3              HCM Consultant 2   \n",
       "4     Machine Learning Engineer   \n",
       "..                          ...   \n",
       "95  Machine Learning Engineer 2   \n",
       "96          Security Specialist   \n",
       "97        Security Specialist 2   \n",
       "98     Web Developer Full Stack   \n",
       "99   Web Developer Full Stack 2   \n",
       "\n",
       "                                      Job_Description  \\\n",
       "0   Master’s degree or above in a STEM field, incl...   \n",
       "1   \\nReporting to the Director, Data & Analytics,...   \n",
       "2   \\nThe Oracle Cloud HCM Absence Consultant will...   \n",
       "3   4+ years of experience in PeopleSoft or Oracle...   \n",
       "4   Leveraging the latest machine and deep learnin...   \n",
       "..                                                ...   \n",
       "95  Collaborate with a multidisciplinary team to g...   \n",
       "96  Work in a fast-paced environment that combine ...   \n",
       "97  \\n    Handling incoming requests for assistanc...   \n",
       "98  \\n\\n    Graduate Degree in Information Technol...   \n",
       "99  \\n· Enter existing website codebases and exten...   \n",
       "\n",
       "                                clean_Job_Description  \\\n",
       "0   master degree stem field including limited com...   \n",
       "1   reporting director data analytics senior data ...   \n",
       "2   oracle cloud hcm absence consultant responsibl...   \n",
       "3   years experience peoplesoft oracle ebs impleme...   \n",
       "4   leveraging latest machine deep learning techni...   \n",
       "..                                                ...   \n",
       "95  collaborate multidisciplinary team gain insigh...   \n",
       "96  work fast-paced environment combine technical ...   \n",
       "97  handling incoming requests assistance business...   \n",
       "98  graduate degree information technology similar...   \n",
       "99  enter existing website codebases extend functi...   \n",
       "\n",
       "                               tokens_Job_Description  \n",
       "0   [master, degree, stem, field, including, limit...  \n",
       "1   [reporting, director, data, analytics, senior,...  \n",
       "2   [oracle, cloud, hcm, absence, consultant, resp...  \n",
       "3   [year, experience, peoplesoft, oracle, eb, imp...  \n",
       "4   [leveraging, latest, machine, deep, learning, ...  \n",
       "..                                                ...  \n",
       "95  [collaborate, multidisciplinary, team, gain, i...  \n",
       "96  [work, fast-paced, environment, combine, techn...  \n",
       "97  [handling, incoming, request, assistance, busi...  \n",
       "98  [graduate, degree, information, technology, si...  \n",
       "99  [enter, existing, website, codebases, extend, ...  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://www.py4u.net/discuss/188191\n",
    "    \n",
    "#Calculate cosine similarity using tf-idf vectors, between search queries and matched documents.\n",
    "#Acá mi search query es la columna clean_Content_CV y el matched documents son los clean_Job_Description.\n",
    "#Cuando hacemos un transform estamos pasandole la query para que se fije los TF-IDF que tiene ya entrenados\n",
    "#del modelo (cuando hicimos fit ya lo entrenamos... y lo hicimos con los cvs y los job descriptions). \n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import paired_cosine_distances as pcd\n",
    "\n",
    "# Initialize an instance of tf-idf Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Generate the tf-idf vectors for the corpus\n",
    "tfidf_vectorizer.fit(df_Jobs_and_Candidates['clean_Content_CV'] + \" \" + df_Jobs_and_Candidates['clean_Job_Description'])\n",
    "\n",
    "A = tfidf_vectorizer.transform(df_Jobs_and_Candidates['clean_Content_CV'])\n",
    "B = tfidf_vectorizer.transform(df_Jobs_and_Candidates['clean_Job_Description'])\n",
    "\n",
    "# compute and the cosine similarity:\n",
    "cosine = 1 - pcd(A, B)\n",
    "\n",
    "df_Jobs_and_Candidates['tfidf_cosine'] = cosine\n",
    "\n",
    "df_Jobs_and_Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08198229])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SI se agrega un Candidato nuevo, se agrega al DF y hago que me devuelva la columna en la que se insertó. \n",
    "#Y con esa columna hago el cálculo que hice arriba.. por ejemplo ahora para la de indice 96:\n",
    "A = clf.transform([df_Jobs_and_Candidates['clean_Content_CV'][96]])\n",
    "B = clf.transform([df_Jobs_and_Candidates['clean_Job_Description'][96]])\n",
    "\n",
    "cosine = 1 - pcd(A, B)\n",
    "cosine\n",
    "#df_Jobs_and_Candidates['tfidf_cosine'] = cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4- Realizando Comparaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1- Usamos el Word2vec descargado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Link del cual descargamos el archivo: https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
    "EMBEDDING_FILE = '/home/fedricio/Desktop/Embeddings_Utilizados/Word2vec/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1.4.2- Funciones necesarias para Cosine Sim y WDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/fedricio/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/fedricio/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "#Esto de arriba se descarga LOCALMENTE en home/user/nltk_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    #Convierte el texto recibido como entrada en una lista de tokens (palabras).\n",
    "    #Dentro pasamos todo a minusculas, se eliminan signos de puntuación, espacios en blanco y se eliminan las stop words.\n",
    "        #input  --> text: el documento como un STRING. \n",
    "        #output --> texts_tokens: cada palabra del texto en una LISTA de string. \n",
    "    texts_tokens=[]\n",
    "    for line in text:\n",
    "        tokens=word_tokenize(line)\n",
    "        tok=[w.lower() for w in tokens]\n",
    "        table=str.maketrans('','',string.punctuation)\n",
    "        strpp=[w.translate(table) for w in tok]\n",
    "        words=[word for word in strpp if word.isalpha()]\n",
    "        stop_words=set(stopwords.words('english'))\n",
    "        words=[w for w in words if not w in stop_words]\n",
    "        texts_tokens.append(words)\n",
    "    return texts_tokens\n",
    "\n",
    "def text_to_vector(text):\n",
    "    #Convierte el texto del documento en una \"term matrix\" donde todas las palabras estan listadas junto a \n",
    "    #la frecuencia en que aparecen en el texto.\n",
    "        #input  --> text: el documento como una LISTA de string. \n",
    "        #output --> Term matrix: una MATRIZ con cada palabra del documento junto a su frecuencia. \n",
    "        \n",
    "    texts_tokens = tokenize(text)\n",
    "    #print(texts_tokens)\n",
    "    return Counter(texts_tokens[0]) #[0] porque es una lista dentro de otra lista.\n",
    "\n",
    "def get_cosine(doc1, doc2):\n",
    "    #Get the cosine similarity between two documents.\n",
    "    #Depends on the angle between two non zero vectors which are constructed by each word frequency in the two documents.\n",
    "        #input  --> doc1: the first document as STRING.\n",
    "                    #doc2: the second document as STRING.\n",
    "        #output --> cosine similarity score\n",
    "\n",
    "    vec1 = text_to_vector([doc1])\n",
    "    vec2 = text_to_vector([doc2])\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "    sum1 = sum([vec1[x] ** 2 for x in list(vec1.keys())])\n",
    "    sum2 = sum([vec2[x] ** 2 for x in list(vec2.keys())])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator\n",
    "    \n",
    "def WMD(doc1,doc2):\n",
    "      #Preprocess the document first and remove english stopwords then call the function that calculates the word mover distance\n",
    "      #input --> doc1: the first document as STRING.\n",
    "                 #doc2: the second document as STRING.\n",
    "      #output --> Word Mover's Distance score\n",
    "    #print(doc1)\n",
    "    first_doc = tokenize([doc1])[0]     #[0] porque es una lista dentro de otra lista.\n",
    "    #print(first_doc)\n",
    "    second_doc = tokenize([doc2])[0]    #[0] porque es una lista dentro de otra lista.\n",
    "    return (word2vec.wmdistance(first_doc, second_doc))  #'wmdistance' return the word mover distance between two documents. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1.4.3- Comparaciones.\n",
    "\n",
    "Las comparaciones a realizar son:\n",
    "\n",
    "    1-Entre el contenido de los CVs y las descripciones de los puestos.\n",
    "    2-Entre el contenido de los CVs y las keywords de puestos obtenidas mediante Keyword extraction.\n",
    "    3-Entre el contenido de los CVs y keywords de puestos puestas \"a mano\" /personalizadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.3.1-Entre el contenido de los CVs y las descripciones de los puestos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Job_Description</th>\n",
       "      <th>clean_Job_Description</th>\n",
       "      <th>tokens_Job_Description</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>master’s degree or above in a stem field, incl...</td>\n",
       "      <td>master degree stem field including limited com...</td>\n",
       "      <td>[master, degree, stem, field, including, limit...</td>\n",
       "      <td>master’s, degree, or, above, in, a, stem, fiel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist 2</td>\n",
       "      <td>\\nreporting to the director, data &amp; analytics,...</td>\n",
       "      <td>reporting director data analytics senior data ...</td>\n",
       "      <td>[reporting, director, data, analytics, senior,...</td>\n",
       "      <td>projects, techniques, skills, organization’s, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HCM Consultant</td>\n",
       "      <td>\\nthe oracle cloud hcm absence consultant will...</td>\n",
       "      <td>oracle cloud hcm absence consultant responsibl...</td>\n",
       "      <td>[oracle, cloud, hcm, absence, consultant, resp...</td>\n",
       "      <td>requirements, experience, work, consulting, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HCM Consultant 2</td>\n",
       "      <td>4+ years of experience in peoplesoft or oracle...</td>\n",
       "      <td>years experience peoplesoft oracle ebs impleme...</td>\n",
       "      <td>[year, experience, peoplesoft, oracle, eb, imp...</td>\n",
       "      <td>*, project, management, &amp;, experience, stakeho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>leveraging the latest machine and deep learnin...</td>\n",
       "      <td>leveraging latest machine deep learning techni...</td>\n",
       "      <td>[leveraging, latest, machine, deep, learning, ...</td>\n",
       "      <td>experience, projects, leveraging, latest, tech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Machine Learning Engineer 2</td>\n",
       "      <td>collaborate with a multidisciplinary team to g...</td>\n",
       "      <td>collaborate multidisciplinary team gain insigh...</td>\n",
       "      <td>[collaborate, multidisciplinary, team, gain, i...</td>\n",
       "      <td>2+, knowledge, of, with, experience, collabora...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Security Specialist</td>\n",
       "      <td>work in a fast-paced environment that combine ...</td>\n",
       "      <td>work fast-paced environment combine technical ...</td>\n",
       "      <td>[work, fast-paced, environment, combine, techn...</td>\n",
       "      <td>experience, with, work, fast-paced, combine, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Security Specialist 2</td>\n",
       "      <td>\\n    handling incoming requests for assistanc...</td>\n",
       "      <td>handling incoming requests assistance business...</td>\n",
       "      <td>[handling, incoming, request, assistance, busi...</td>\n",
       "      <td>security, of, handling, incoming, requests, fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Web Developer Full Stack</td>\n",
       "      <td>\\n\\n    graduate degree in information technol...</td>\n",
       "      <td>graduate degree information technology similar...</td>\n",
       "      <td>[graduate, degree, information, technology, si...</td>\n",
       "      <td>experience, written, typescript), skills, and,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Web Developer Full Stack 2</td>\n",
       "      <td>\\n· enter existing website codebases and exten...</td>\n",
       "      <td>enter existing website codebases extend functi...</td>\n",
       "      <td>[enter, existing, website, codebases, extend, ...</td>\n",
       "      <td>5, (required), enter, existing, website, codeb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Job_Title  \\\n",
       "2               Data Scientist   \n",
       "3             Data Scientist 2   \n",
       "6               HCM Consultant   \n",
       "7             HCM Consultant 2   \n",
       "0    Machine Learning Engineer   \n",
       "1  Machine Learning Engineer 2   \n",
       "8          Security Specialist   \n",
       "9        Security Specialist 2   \n",
       "4     Web Developer Full Stack   \n",
       "5   Web Developer Full Stack 2   \n",
       "\n",
       "                                     Job_Description  \\\n",
       "2  master’s degree or above in a stem field, incl...   \n",
       "3  \\nreporting to the director, data & analytics,...   \n",
       "6  \\nthe oracle cloud hcm absence consultant will...   \n",
       "7  4+ years of experience in peoplesoft or oracle...   \n",
       "0  leveraging the latest machine and deep learnin...   \n",
       "1  collaborate with a multidisciplinary team to g...   \n",
       "8  work in a fast-paced environment that combine ...   \n",
       "9  \\n    handling incoming requests for assistanc...   \n",
       "4  \\n\\n    graduate degree in information technol...   \n",
       "5  \\n· enter existing website codebases and exten...   \n",
       "\n",
       "                               clean_Job_Description  \\\n",
       "2  master degree stem field including limited com...   \n",
       "3  reporting director data analytics senior data ...   \n",
       "6  oracle cloud hcm absence consultant responsibl...   \n",
       "7  years experience peoplesoft oracle ebs impleme...   \n",
       "0  leveraging latest machine deep learning techni...   \n",
       "1  collaborate multidisciplinary team gain insigh...   \n",
       "8  work fast-paced environment combine technical ...   \n",
       "9  handling incoming requests assistance business...   \n",
       "4  graduate degree information technology similar...   \n",
       "5  enter existing website codebases extend functi...   \n",
       "\n",
       "                              tokens_Job_Description  \\\n",
       "2  [master, degree, stem, field, including, limit...   \n",
       "3  [reporting, director, data, analytics, senior,...   \n",
       "6  [oracle, cloud, hcm, absence, consultant, resp...   \n",
       "7  [year, experience, peoplesoft, oracle, eb, imp...   \n",
       "0  [leveraging, latest, machine, deep, learning, ...   \n",
       "1  [collaborate, multidisciplinary, team, gain, i...   \n",
       "8  [work, fast-paced, environment, combine, techn...   \n",
       "9  [handling, incoming, request, assistance, busi...   \n",
       "4  [graduate, degree, information, technology, si...   \n",
       "5  [enter, existing, website, codebases, extend, ...   \n",
       "\n",
       "                                            Keywords  \n",
       "2  master’s, degree, or, above, in, a, stem, fiel...  \n",
       "3  projects, techniques, skills, organization’s, ...  \n",
       "6  requirements, experience, work, consulting, co...  \n",
       "7  *, project, management, &, experience, stakeho...  \n",
       "0  experience, projects, leveraging, latest, tech...  \n",
       "1  2+, knowledge, of, with, experience, collabora...  \n",
       "8  experience, with, work, fast-paced, combine, o...  \n",
       "9  security, of, handling, incoming, requests, fo...  \n",
       "4  experience, written, typescript), skills, and,...  \n",
       "5  5, (required), enter, existing, website, codeb...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Candidate_Name</th>\n",
       "      <th>Content_CV</th>\n",
       "      <th>clean_Content_CV</th>\n",
       "      <th>tokens_Content_CV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data_Scientist_Karla_Lewis</td>\n",
       "      <td>\\nKARLA LEWIS\\nData Scientist\\nCONTACT WORK EX...</td>\n",
       "      <td>karla lewis data scientist contact work experi...</td>\n",
       "      <td>[karla, lewis, data, scientist, contact, work,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data_Scientist_Rahul_Malik</td>\n",
       "      <td>\\nRAHUL MALIK\\nNLP Data Scientist\\nCONTACT WOR...</td>\n",
       "      <td>rahul malik nlp data scientist contact work ex...</td>\n",
       "      <td>[rahul, malik, nlp, data, scientist, contact, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HCM_Federico_Calonge</td>\n",
       "      <td>\\n                                            ...</td>\n",
       "      <td>calonge federico matías hcm technical consulta...</td>\n",
       "      <td>[calonge, federico, matías, hcm, technical, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HCM_Robert_Smith</td>\n",
       "      <td>\\nSap Hcm Consultant Phone: (123) 456 78 99\\nE...</td>\n",
       "      <td>sap hcm consultant phone email info qwikresume...</td>\n",
       "      <td>[sap, hcm, consultant, phone, email, info, qwi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ML_Engineer_Bradly_Johnston</td>\n",
       "      <td>\\nBradly Johnston\\n435 Kasey Vista, Detroit\\n+...</td>\n",
       "      <td>bradly johnston kasey vista detroit work exper...</td>\n",
       "      <td>[bradly, johnston, kasey, vista, detroit, work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ML_Engineer_Jonathon_Price</td>\n",
       "      <td>\\nJonathon Price \\n4587 Terry Groves, Boston\\n...</td>\n",
       "      <td>jonathon price terry groves boston experience ...</td>\n",
       "      <td>[jonathon, price, terry, grove, boston, experi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Security_Specialist_Ahmed Wayne</td>\n",
       "      <td>\\nAhmed Wayne\\nAddress: Abu Dhabi, UAE\\nNation...</td>\n",
       "      <td>ahmed wayne address abu dhabi uae nationality ...</td>\n",
       "      <td>[ahmed, wayne, address, abu, dhabi, uae, natio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Security_Specialist_Denis Banik</td>\n",
       "      <td>\\nDenis Banik\\nEmail address: hello@kickresume...</td>\n",
       "      <td>denis banik email address hello kickresume com...</td>\n",
       "      <td>[denis, banik, email, address, hello, kickresu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Web_Dev_Alec_Dionisio</td>\n",
       "      <td>\\nChestertown, MD 4107083942\\nhi@alecdionis.io...</td>\n",
       "      <td>chestertown md hi alecdionis io alecdionis io ...</td>\n",
       "      <td>[chestertown, md, hi, alecdionis, io, alecdion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Web_Dev_Karen_Higgins</td>\n",
       "      <td>\\nKaren Higgins \\n        We b Developer \\n \\n...</td>\n",
       "      <td>karen higgins b developer areas expertise pers...</td>\n",
       "      <td>[karen, higgins, b, developer, area, expertise...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Candidate_Name  \\\n",
       "6       Data_Scientist_Karla_Lewis   \n",
       "2       Data_Scientist_Rahul_Malik   \n",
       "4             HCM_Federico_Calonge   \n",
       "7                 HCM_Robert_Smith   \n",
       "0      ML_Engineer_Bradly_Johnston   \n",
       "1       ML_Engineer_Jonathon_Price   \n",
       "8  Security_Specialist_Ahmed Wayne   \n",
       "3  Security_Specialist_Denis Banik   \n",
       "5            Web_Dev_Alec_Dionisio   \n",
       "9            Web_Dev_Karen_Higgins   \n",
       "\n",
       "                                          Content_CV  \\\n",
       "6  \\nKARLA LEWIS\\nData Scientist\\nCONTACT WORK EX...   \n",
       "2  \\nRAHUL MALIK\\nNLP Data Scientist\\nCONTACT WOR...   \n",
       "4  \\n                                            ...   \n",
       "7  \\nSap Hcm Consultant Phone: (123) 456 78 99\\nE...   \n",
       "0  \\nBradly Johnston\\n435 Kasey Vista, Detroit\\n+...   \n",
       "1  \\nJonathon Price \\n4587 Terry Groves, Boston\\n...   \n",
       "8  \\nAhmed Wayne\\nAddress: Abu Dhabi, UAE\\nNation...   \n",
       "3  \\nDenis Banik\\nEmail address: hello@kickresume...   \n",
       "5  \\nChestertown, MD 4107083942\\nhi@alecdionis.io...   \n",
       "9  \\nKaren Higgins \\n        We b Developer \\n \\n...   \n",
       "\n",
       "                                    clean_Content_CV  \\\n",
       "6  karla lewis data scientist contact work experi...   \n",
       "2  rahul malik nlp data scientist contact work ex...   \n",
       "4  calonge federico matías hcm technical consulta...   \n",
       "7  sap hcm consultant phone email info qwikresume...   \n",
       "0  bradly johnston kasey vista detroit work exper...   \n",
       "1  jonathon price terry groves boston experience ...   \n",
       "8  ahmed wayne address abu dhabi uae nationality ...   \n",
       "3  denis banik email address hello kickresume com...   \n",
       "5  chestertown md hi alecdionis io alecdionis io ...   \n",
       "9  karen higgins b developer areas expertise pers...   \n",
       "\n",
       "                                   tokens_Content_CV  \n",
       "6  [karla, lewis, data, scientist, contact, work,...  \n",
       "2  [rahul, malik, nlp, data, scientist, contact, ...  \n",
       "4  [calonge, federico, matías, hcm, technical, co...  \n",
       "7  [sap, hcm, consultant, phone, email, info, qwi...  \n",
       "0  [bradly, johnston, kasey, vista, detroit, work...  \n",
       "1  [jonathon, price, terry, grove, boston, experi...  \n",
       "8  [ahmed, wayne, address, abu, dhabi, uae, natio...  \n",
       "3  [denis, banik, email, address, hello, kickresu...  \n",
       "5  [chestertown, md, hi, alecdionis, io, alecdion...  \n",
       "9  [karen, higgins, b, developer, area, expertise...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Creamos un nuevo DF concatenando los 2 dataframe de manera que se comparen todos los CVs con todos los Jobs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nos quedarán 10 x 10 = 100 filas.\n",
    "df_Jobs_and_Candidates = pd.merge(df_Candidates.assign(A=1), df_Jobs.assign(A=1), on='A').drop('A', 1)\n",
    "df_Jobs_and_Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_Jobs_and_Candidates' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-1d53d52187f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Como prueba obtenemos el WMD y Cosine Sim comparando para la 1ra fila (entre las columnas Content_CV y Job_Description)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfirst_job_descr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_Jobs_and_Candidates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'clean_Job_Description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfirst_content_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_Jobs_and_Candidates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'clean_Content_CV'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcosine_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_cosine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_job_descr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfirst_content_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_Jobs_and_Candidates' is not defined"
     ]
    }
   ],
   "source": [
    "#Como prueba obtenemos el WMD y Cosine Sim comparando para la 1ra fila (entre las columnas Content_CV y Job_Description)\n",
    "first_job_descr = df_Jobs_and_Candidates.loc[0,'clean_Job_Description']\n",
    "first_content_cv = df_Jobs_and_Candidates.loc[0,'clean_Content_CV']\n",
    "\n",
    "cosine_result = round(get_cosine(first_job_descr,first_content_cv),3)\n",
    "wmd_result = round(WMD(first_job_descr,first_content_cv),3)\n",
    "print(cosine_result)\n",
    "print(wmd_result)\n",
    " \n",
    "similarity_wdm = round((1/(1+wmd_result)),3)  #similarity = 1 / (1 + distance) https://groups.google.com/g/gensim/c/-pRZnsOEaPQ \n",
    "print(similarity_wdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46358704566955566\n",
      "116.4919548034668\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Candidate_Name</th>\n",
       "      <th>Content_CV</th>\n",
       "      <th>clean_Content_CV</th>\n",
       "      <th>tokens_Content_CV</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Job_Description</th>\n",
       "      <th>clean_Job_Description</th>\n",
       "      <th>tokens_Job_Description</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Cosine_Job_Desc</th>\n",
       "      <th>WMD_Job_Desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data_Scientist_Karla_Lewis</td>\n",
       "      <td>\\nKARLA LEWIS\\nData Scientist\\nCONTACT WORK EX...</td>\n",
       "      <td>karla lewis data scientist contact work experi...</td>\n",
       "      <td>[karla, lewis, data, scientist, contact, work,...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>master’s degree or above in a stem field, incl...</td>\n",
       "      <td>master degree stem field including limited com...</td>\n",
       "      <td>[master, degree, stem, field, including, limit...</td>\n",
       "      <td>master’s, degree, or, above, in, a, stem, fiel...</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data_Scientist_Karla_Lewis</td>\n",
       "      <td>\\nKARLA LEWIS\\nData Scientist\\nCONTACT WORK EX...</td>\n",
       "      <td>karla lewis data scientist contact work experi...</td>\n",
       "      <td>[karla, lewis, data, scientist, contact, work,...</td>\n",
       "      <td>Data Scientist 2</td>\n",
       "      <td>\\nreporting to the director, data &amp; analytics,...</td>\n",
       "      <td>reporting director data analytics senior data ...</td>\n",
       "      <td>[reporting, director, data, analytics, senior,...</td>\n",
       "      <td>projects, techniques, skills, organization’s, ...</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data_Scientist_Karla_Lewis</td>\n",
       "      <td>\\nKARLA LEWIS\\nData Scientist\\nCONTACT WORK EX...</td>\n",
       "      <td>karla lewis data scientist contact work experi...</td>\n",
       "      <td>[karla, lewis, data, scientist, contact, work,...</td>\n",
       "      <td>HCM Consultant</td>\n",
       "      <td>\\nthe oracle cloud hcm absence consultant will...</td>\n",
       "      <td>oracle cloud hcm absence consultant responsibl...</td>\n",
       "      <td>[oracle, cloud, hcm, absence, consultant, resp...</td>\n",
       "      <td>requirements, experience, work, consulting, co...</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data_Scientist_Karla_Lewis</td>\n",
       "      <td>\\nKARLA LEWIS\\nData Scientist\\nCONTACT WORK EX...</td>\n",
       "      <td>karla lewis data scientist contact work experi...</td>\n",
       "      <td>[karla, lewis, data, scientist, contact, work,...</td>\n",
       "      <td>HCM Consultant 2</td>\n",
       "      <td>4+ years of experience in peoplesoft or oracle...</td>\n",
       "      <td>years experience peoplesoft oracle ebs impleme...</td>\n",
       "      <td>[year, experience, peoplesoft, oracle, eb, imp...</td>\n",
       "      <td>*, project, management, &amp;, experience, stakeho...</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data_Scientist_Karla_Lewis</td>\n",
       "      <td>\\nKARLA LEWIS\\nData Scientist\\nCONTACT WORK EX...</td>\n",
       "      <td>karla lewis data scientist contact work experi...</td>\n",
       "      <td>[karla, lewis, data, scientist, contact, work,...</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>leveraging the latest machine and deep learnin...</td>\n",
       "      <td>leveraging latest machine deep learning techni...</td>\n",
       "      <td>[leveraging, latest, machine, deep, learning, ...</td>\n",
       "      <td>experience, projects, leveraging, latest, tech...</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Web_Dev_Karen_Higgins</td>\n",
       "      <td>\\nKaren Higgins \\n        We b Developer \\n \\n...</td>\n",
       "      <td>karen higgins b developer areas expertise pers...</td>\n",
       "      <td>[karen, higgins, b, developer, area, expertise...</td>\n",
       "      <td>Machine Learning Engineer 2</td>\n",
       "      <td>collaborate with a multidisciplinary team to g...</td>\n",
       "      <td>collaborate multidisciplinary team gain insigh...</td>\n",
       "      <td>[collaborate, multidisciplinary, team, gain, i...</td>\n",
       "      <td>2+, knowledge, of, with, experience, collabora...</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Web_Dev_Karen_Higgins</td>\n",
       "      <td>\\nKaren Higgins \\n        We b Developer \\n \\n...</td>\n",
       "      <td>karen higgins b developer areas expertise pers...</td>\n",
       "      <td>[karen, higgins, b, developer, area, expertise...</td>\n",
       "      <td>Security Specialist</td>\n",
       "      <td>work in a fast-paced environment that combine ...</td>\n",
       "      <td>work fast-paced environment combine technical ...</td>\n",
       "      <td>[work, fast-paced, environment, combine, techn...</td>\n",
       "      <td>experience, with, work, fast-paced, combine, o...</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Web_Dev_Karen_Higgins</td>\n",
       "      <td>\\nKaren Higgins \\n        We b Developer \\n \\n...</td>\n",
       "      <td>karen higgins b developer areas expertise pers...</td>\n",
       "      <td>[karen, higgins, b, developer, area, expertise...</td>\n",
       "      <td>Security Specialist 2</td>\n",
       "      <td>\\n    handling incoming requests for assistanc...</td>\n",
       "      <td>handling incoming requests assistance business...</td>\n",
       "      <td>[handling, incoming, request, assistance, busi...</td>\n",
       "      <td>security, of, handling, incoming, requests, fo...</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Web_Dev_Karen_Higgins</td>\n",
       "      <td>\\nKaren Higgins \\n        We b Developer \\n \\n...</td>\n",
       "      <td>karen higgins b developer areas expertise pers...</td>\n",
       "      <td>[karen, higgins, b, developer, area, expertise...</td>\n",
       "      <td>Web Developer Full Stack</td>\n",
       "      <td>\\n\\n    graduate degree in information technol...</td>\n",
       "      <td>graduate degree information technology similar...</td>\n",
       "      <td>[graduate, degree, information, technology, si...</td>\n",
       "      <td>experience, written, typescript), skills, and,...</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Web_Dev_Karen_Higgins</td>\n",
       "      <td>\\nKaren Higgins \\n        We b Developer \\n \\n...</td>\n",
       "      <td>karen higgins b developer areas expertise pers...</td>\n",
       "      <td>[karen, higgins, b, developer, area, expertise...</td>\n",
       "      <td>Web Developer Full Stack 2</td>\n",
       "      <td>\\n· enter existing website codebases and exten...</td>\n",
       "      <td>enter existing website codebases extend functi...</td>\n",
       "      <td>[enter, existing, website, codebases, extend, ...</td>\n",
       "      <td>5, (required), enter, existing, website, codeb...</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Candidate_Name  \\\n",
       "0   Data_Scientist_Karla_Lewis   \n",
       "1   Data_Scientist_Karla_Lewis   \n",
       "2   Data_Scientist_Karla_Lewis   \n",
       "3   Data_Scientist_Karla_Lewis   \n",
       "4   Data_Scientist_Karla_Lewis   \n",
       "..                         ...   \n",
       "95       Web_Dev_Karen_Higgins   \n",
       "96       Web_Dev_Karen_Higgins   \n",
       "97       Web_Dev_Karen_Higgins   \n",
       "98       Web_Dev_Karen_Higgins   \n",
       "99       Web_Dev_Karen_Higgins   \n",
       "\n",
       "                                           Content_CV  \\\n",
       "0   \\nKARLA LEWIS\\nData Scientist\\nCONTACT WORK EX...   \n",
       "1   \\nKARLA LEWIS\\nData Scientist\\nCONTACT WORK EX...   \n",
       "2   \\nKARLA LEWIS\\nData Scientist\\nCONTACT WORK EX...   \n",
       "3   \\nKARLA LEWIS\\nData Scientist\\nCONTACT WORK EX...   \n",
       "4   \\nKARLA LEWIS\\nData Scientist\\nCONTACT WORK EX...   \n",
       "..                                                ...   \n",
       "95  \\nKaren Higgins \\n        We b Developer \\n \\n...   \n",
       "96  \\nKaren Higgins \\n        We b Developer \\n \\n...   \n",
       "97  \\nKaren Higgins \\n        We b Developer \\n \\n...   \n",
       "98  \\nKaren Higgins \\n        We b Developer \\n \\n...   \n",
       "99  \\nKaren Higgins \\n        We b Developer \\n \\n...   \n",
       "\n",
       "                                     clean_Content_CV  \\\n",
       "0   karla lewis data scientist contact work experi...   \n",
       "1   karla lewis data scientist contact work experi...   \n",
       "2   karla lewis data scientist contact work experi...   \n",
       "3   karla lewis data scientist contact work experi...   \n",
       "4   karla lewis data scientist contact work experi...   \n",
       "..                                                ...   \n",
       "95  karen higgins b developer areas expertise pers...   \n",
       "96  karen higgins b developer areas expertise pers...   \n",
       "97  karen higgins b developer areas expertise pers...   \n",
       "98  karen higgins b developer areas expertise pers...   \n",
       "99  karen higgins b developer areas expertise pers...   \n",
       "\n",
       "                                    tokens_Content_CV  \\\n",
       "0   [karla, lewis, data, scientist, contact, work,...   \n",
       "1   [karla, lewis, data, scientist, contact, work,...   \n",
       "2   [karla, lewis, data, scientist, contact, work,...   \n",
       "3   [karla, lewis, data, scientist, contact, work,...   \n",
       "4   [karla, lewis, data, scientist, contact, work,...   \n",
       "..                                                ...   \n",
       "95  [karen, higgins, b, developer, area, expertise...   \n",
       "96  [karen, higgins, b, developer, area, expertise...   \n",
       "97  [karen, higgins, b, developer, area, expertise...   \n",
       "98  [karen, higgins, b, developer, area, expertise...   \n",
       "99  [karen, higgins, b, developer, area, expertise...   \n",
       "\n",
       "                      Job_Title  \\\n",
       "0                Data Scientist   \n",
       "1              Data Scientist 2   \n",
       "2                HCM Consultant   \n",
       "3              HCM Consultant 2   \n",
       "4     Machine Learning Engineer   \n",
       "..                          ...   \n",
       "95  Machine Learning Engineer 2   \n",
       "96          Security Specialist   \n",
       "97        Security Specialist 2   \n",
       "98     Web Developer Full Stack   \n",
       "99   Web Developer Full Stack 2   \n",
       "\n",
       "                                      Job_Description  \\\n",
       "0   master’s degree or above in a stem field, incl...   \n",
       "1   \\nreporting to the director, data & analytics,...   \n",
       "2   \\nthe oracle cloud hcm absence consultant will...   \n",
       "3   4+ years of experience in peoplesoft or oracle...   \n",
       "4   leveraging the latest machine and deep learnin...   \n",
       "..                                                ...   \n",
       "95  collaborate with a multidisciplinary team to g...   \n",
       "96  work in a fast-paced environment that combine ...   \n",
       "97  \\n    handling incoming requests for assistanc...   \n",
       "98  \\n\\n    graduate degree in information technol...   \n",
       "99  \\n· enter existing website codebases and exten...   \n",
       "\n",
       "                                clean_Job_Description  \\\n",
       "0   master degree stem field including limited com...   \n",
       "1   reporting director data analytics senior data ...   \n",
       "2   oracle cloud hcm absence consultant responsibl...   \n",
       "3   years experience peoplesoft oracle ebs impleme...   \n",
       "4   leveraging latest machine deep learning techni...   \n",
       "..                                                ...   \n",
       "95  collaborate multidisciplinary team gain insigh...   \n",
       "96  work fast-paced environment combine technical ...   \n",
       "97  handling incoming requests assistance business...   \n",
       "98  graduate degree information technology similar...   \n",
       "99  enter existing website codebases extend functi...   \n",
       "\n",
       "                               tokens_Job_Description  \\\n",
       "0   [master, degree, stem, field, including, limit...   \n",
       "1   [reporting, director, data, analytics, senior,...   \n",
       "2   [oracle, cloud, hcm, absence, consultant, resp...   \n",
       "3   [year, experience, peoplesoft, oracle, eb, imp...   \n",
       "4   [leveraging, latest, machine, deep, learning, ...   \n",
       "..                                                ...   \n",
       "95  [collaborate, multidisciplinary, team, gain, i...   \n",
       "96  [work, fast-paced, environment, combine, techn...   \n",
       "97  [handling, incoming, request, assistance, busi...   \n",
       "98  [graduate, degree, information, technology, si...   \n",
       "99  [enter, existing, website, codebases, extend, ...   \n",
       "\n",
       "                                             Keywords  Cosine_Job_Desc  \\\n",
       "0   master’s, degree, or, above, in, a, stem, fiel...            0.139   \n",
       "1   projects, techniques, skills, organization’s, ...            0.210   \n",
       "2   requirements, experience, work, consulting, co...            0.085   \n",
       "3   *, project, management, &, experience, stakeho...            0.058   \n",
       "4   experience, projects, leveraging, latest, tech...            0.118   \n",
       "..                                                ...              ...   \n",
       "95  2+, knowledge, of, with, experience, collabora...            0.158   \n",
       "96  experience, with, work, fast-paced, combine, o...            0.154   \n",
       "97  security, of, handling, incoming, requests, fo...            0.115   \n",
       "98  experience, written, typescript), skills, and,...            0.188   \n",
       "99  5, (required), enter, existing, website, codeb...            0.204   \n",
       "\n",
       "    WMD_Job_Desc  \n",
       "0          0.489  \n",
       "1          0.494  \n",
       "2          0.480  \n",
       "3          0.475  \n",
       "4          0.485  \n",
       "..           ...  \n",
       "95         0.496  \n",
       "96         0.501  \n",
       "97         0.486  \n",
       "98         0.490  \n",
       "99         0.507  \n",
       "\n",
       "[100 rows x 11 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Aplicamos las funciones get_cosine y WMD para TODO el DF... entre el contenido del CV y la descripcion del \n",
    "#puesto; y el resultado lo guardamos en  las columnas 'Cosine_Job_Desc' y 'WMD_Job_Desc'.\n",
    "\n",
    "import time\n",
    "\n",
    "inicio_cosine = time.time()\n",
    "df_Jobs_and_Candidates['Cosine_Job_Desc'] = df_Jobs_and_Candidates.apply(lambda row: round(get_cosine(row['clean_Content_CV'],row['clean_Job_Description']),3), axis=1)\n",
    "fin_cosine = time.time()\n",
    "print(fin_cosine-inicio_cosine)\n",
    "\n",
    "inicio_WMD = time.time()\n",
    "#df_Jobs_and_Candidates['WMD_Job_Desc'] = df_Jobs_and_Candidates.apply(lambda row: round(WMD(row['Content_CV'],row['Job_Description']),3), axis=1)\n",
    "#APlicando lo de  --> similarity = 1 / (1 + distance):\n",
    "df_Jobs_and_Candidates['WMD_Job_Desc'] = df_Jobs_and_Candidates.apply(lambda row: round((1/(1+(WMD(row['clean_Content_CV'],row['clean_Job_Description'])))),3), axis=1)\n",
    "fin_WMD = time.time()\n",
    "print(fin_WMD-inicio_WMD)\n",
    "\n",
    "df_Jobs_and_Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Candidate_Name</th>\n",
       "      <th>Content_CV</th>\n",
       "      <th>clean_Content_CV</th>\n",
       "      <th>tokens_Content_CV</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Job_Description</th>\n",
       "      <th>clean_Job_Description</th>\n",
       "      <th>tokens_Job_Description</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Cosine_Job_Desc</th>\n",
       "      <th>WMD_Job_Desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Security_Specialist_Denis Banik</td>\n",
       "      <td>\\nDenis Banik\\nEmail address: hello@kickresume...</td>\n",
       "      <td>denis banik email address hello kickresume com...</td>\n",
       "      <td>[denis, banik, email, address, hello, kickresu...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>master’s degree or above in a stem field, incl...</td>\n",
       "      <td>master degree stem field including limited com...</td>\n",
       "      <td>[master, degree, stem, field, including, limit...</td>\n",
       "      <td>master’s, degree, or, above, in, a, stem, fiel...</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Security_Specialist_Denis Banik</td>\n",
       "      <td>\\nDenis Banik\\nEmail address: hello@kickresume...</td>\n",
       "      <td>denis banik email address hello kickresume com...</td>\n",
       "      <td>[denis, banik, email, address, hello, kickresu...</td>\n",
       "      <td>Data Scientist 2</td>\n",
       "      <td>\\nreporting to the director, data &amp; analytics,...</td>\n",
       "      <td>reporting director data analytics senior data ...</td>\n",
       "      <td>[reporting, director, data, analytics, senior,...</td>\n",
       "      <td>projects, techniques, skills, organization’s, ...</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Security_Specialist_Denis Banik</td>\n",
       "      <td>\\nDenis Banik\\nEmail address: hello@kickresume...</td>\n",
       "      <td>denis banik email address hello kickresume com...</td>\n",
       "      <td>[denis, banik, email, address, hello, kickresu...</td>\n",
       "      <td>HCM Consultant</td>\n",
       "      <td>\\nthe oracle cloud hcm absence consultant will...</td>\n",
       "      <td>oracle cloud hcm absence consultant responsibl...</td>\n",
       "      <td>[oracle, cloud, hcm, absence, consultant, resp...</td>\n",
       "      <td>requirements, experience, work, consulting, co...</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Security_Specialist_Denis Banik</td>\n",
       "      <td>\\nDenis Banik\\nEmail address: hello@kickresume...</td>\n",
       "      <td>denis banik email address hello kickresume com...</td>\n",
       "      <td>[denis, banik, email, address, hello, kickresu...</td>\n",
       "      <td>HCM Consultant 2</td>\n",
       "      <td>4+ years of experience in peoplesoft or oracle...</td>\n",
       "      <td>years experience peoplesoft oracle ebs impleme...</td>\n",
       "      <td>[year, experience, peoplesoft, oracle, eb, imp...</td>\n",
       "      <td>*, project, management, &amp;, experience, stakeho...</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Security_Specialist_Denis Banik</td>\n",
       "      <td>\\nDenis Banik\\nEmail address: hello@kickresume...</td>\n",
       "      <td>denis banik email address hello kickresume com...</td>\n",
       "      <td>[denis, banik, email, address, hello, kickresu...</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>leveraging the latest machine and deep learnin...</td>\n",
       "      <td>leveraging latest machine deep learning techni...</td>\n",
       "      <td>[leveraging, latest, machine, deep, learning, ...</td>\n",
       "      <td>experience, projects, leveraging, latest, tech...</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Security_Specialist_Denis Banik</td>\n",
       "      <td>\\nDenis Banik\\nEmail address: hello@kickresume...</td>\n",
       "      <td>denis banik email address hello kickresume com...</td>\n",
       "      <td>[denis, banik, email, address, hello, kickresu...</td>\n",
       "      <td>Machine Learning Engineer 2</td>\n",
       "      <td>collaborate with a multidisciplinary team to g...</td>\n",
       "      <td>collaborate multidisciplinary team gain insigh...</td>\n",
       "      <td>[collaborate, multidisciplinary, team, gain, i...</td>\n",
       "      <td>2+, knowledge, of, with, experience, collabora...</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Security_Specialist_Denis Banik</td>\n",
       "      <td>\\nDenis Banik\\nEmail address: hello@kickresume...</td>\n",
       "      <td>denis banik email address hello kickresume com...</td>\n",
       "      <td>[denis, banik, email, address, hello, kickresu...</td>\n",
       "      <td>Security Specialist</td>\n",
       "      <td>work in a fast-paced environment that combine ...</td>\n",
       "      <td>work fast-paced environment combine technical ...</td>\n",
       "      <td>[work, fast-paced, environment, combine, techn...</td>\n",
       "      <td>experience, with, work, fast-paced, combine, o...</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Security_Specialist_Denis Banik</td>\n",
       "      <td>\\nDenis Banik\\nEmail address: hello@kickresume...</td>\n",
       "      <td>denis banik email address hello kickresume com...</td>\n",
       "      <td>[denis, banik, email, address, hello, kickresu...</td>\n",
       "      <td>Security Specialist 2</td>\n",
       "      <td>\\n    handling incoming requests for assistanc...</td>\n",
       "      <td>handling incoming requests assistance business...</td>\n",
       "      <td>[handling, incoming, request, assistance, busi...</td>\n",
       "      <td>security, of, handling, incoming, requests, fo...</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Security_Specialist_Denis Banik</td>\n",
       "      <td>\\nDenis Banik\\nEmail address: hello@kickresume...</td>\n",
       "      <td>denis banik email address hello kickresume com...</td>\n",
       "      <td>[denis, banik, email, address, hello, kickresu...</td>\n",
       "      <td>Web Developer Full Stack</td>\n",
       "      <td>\\n\\n    graduate degree in information technol...</td>\n",
       "      <td>graduate degree information technology similar...</td>\n",
       "      <td>[graduate, degree, information, technology, si...</td>\n",
       "      <td>experience, written, typescript), skills, and,...</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Security_Specialist_Denis Banik</td>\n",
       "      <td>\\nDenis Banik\\nEmail address: hello@kickresume...</td>\n",
       "      <td>denis banik email address hello kickresume com...</td>\n",
       "      <td>[denis, banik, email, address, hello, kickresu...</td>\n",
       "      <td>Web Developer Full Stack 2</td>\n",
       "      <td>\\n· enter existing website codebases and exten...</td>\n",
       "      <td>enter existing website codebases extend functi...</td>\n",
       "      <td>[enter, existing, website, codebases, extend, ...</td>\n",
       "      <td>5, (required), enter, existing, website, codeb...</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Candidate_Name  \\\n",
       "70  Security_Specialist_Denis Banik   \n",
       "71  Security_Specialist_Denis Banik   \n",
       "72  Security_Specialist_Denis Banik   \n",
       "73  Security_Specialist_Denis Banik   \n",
       "74  Security_Specialist_Denis Banik   \n",
       "75  Security_Specialist_Denis Banik   \n",
       "76  Security_Specialist_Denis Banik   \n",
       "77  Security_Specialist_Denis Banik   \n",
       "78  Security_Specialist_Denis Banik   \n",
       "79  Security_Specialist_Denis Banik   \n",
       "\n",
       "                                           Content_CV  \\\n",
       "70  \\nDenis Banik\\nEmail address: hello@kickresume...   \n",
       "71  \\nDenis Banik\\nEmail address: hello@kickresume...   \n",
       "72  \\nDenis Banik\\nEmail address: hello@kickresume...   \n",
       "73  \\nDenis Banik\\nEmail address: hello@kickresume...   \n",
       "74  \\nDenis Banik\\nEmail address: hello@kickresume...   \n",
       "75  \\nDenis Banik\\nEmail address: hello@kickresume...   \n",
       "76  \\nDenis Banik\\nEmail address: hello@kickresume...   \n",
       "77  \\nDenis Banik\\nEmail address: hello@kickresume...   \n",
       "78  \\nDenis Banik\\nEmail address: hello@kickresume...   \n",
       "79  \\nDenis Banik\\nEmail address: hello@kickresume...   \n",
       "\n",
       "                                     clean_Content_CV  \\\n",
       "70  denis banik email address hello kickresume com...   \n",
       "71  denis banik email address hello kickresume com...   \n",
       "72  denis banik email address hello kickresume com...   \n",
       "73  denis banik email address hello kickresume com...   \n",
       "74  denis banik email address hello kickresume com...   \n",
       "75  denis banik email address hello kickresume com...   \n",
       "76  denis banik email address hello kickresume com...   \n",
       "77  denis banik email address hello kickresume com...   \n",
       "78  denis banik email address hello kickresume com...   \n",
       "79  denis banik email address hello kickresume com...   \n",
       "\n",
       "                                    tokens_Content_CV  \\\n",
       "70  [denis, banik, email, address, hello, kickresu...   \n",
       "71  [denis, banik, email, address, hello, kickresu...   \n",
       "72  [denis, banik, email, address, hello, kickresu...   \n",
       "73  [denis, banik, email, address, hello, kickresu...   \n",
       "74  [denis, banik, email, address, hello, kickresu...   \n",
       "75  [denis, banik, email, address, hello, kickresu...   \n",
       "76  [denis, banik, email, address, hello, kickresu...   \n",
       "77  [denis, banik, email, address, hello, kickresu...   \n",
       "78  [denis, banik, email, address, hello, kickresu...   \n",
       "79  [denis, banik, email, address, hello, kickresu...   \n",
       "\n",
       "                      Job_Title  \\\n",
       "70               Data Scientist   \n",
       "71             Data Scientist 2   \n",
       "72               HCM Consultant   \n",
       "73             HCM Consultant 2   \n",
       "74    Machine Learning Engineer   \n",
       "75  Machine Learning Engineer 2   \n",
       "76          Security Specialist   \n",
       "77        Security Specialist 2   \n",
       "78     Web Developer Full Stack   \n",
       "79   Web Developer Full Stack 2   \n",
       "\n",
       "                                      Job_Description  \\\n",
       "70  master’s degree or above in a stem field, incl...   \n",
       "71  \\nreporting to the director, data & analytics,...   \n",
       "72  \\nthe oracle cloud hcm absence consultant will...   \n",
       "73  4+ years of experience in peoplesoft or oracle...   \n",
       "74  leveraging the latest machine and deep learnin...   \n",
       "75  collaborate with a multidisciplinary team to g...   \n",
       "76  work in a fast-paced environment that combine ...   \n",
       "77  \\n    handling incoming requests for assistanc...   \n",
       "78  \\n\\n    graduate degree in information technol...   \n",
       "79  \\n· enter existing website codebases and exten...   \n",
       "\n",
       "                                clean_Job_Description  \\\n",
       "70  master degree stem field including limited com...   \n",
       "71  reporting director data analytics senior data ...   \n",
       "72  oracle cloud hcm absence consultant responsibl...   \n",
       "73  years experience peoplesoft oracle ebs impleme...   \n",
       "74  leveraging latest machine deep learning techni...   \n",
       "75  collaborate multidisciplinary team gain insigh...   \n",
       "76  work fast-paced environment combine technical ...   \n",
       "77  handling incoming requests assistance business...   \n",
       "78  graduate degree information technology similar...   \n",
       "79  enter existing website codebases extend functi...   \n",
       "\n",
       "                               tokens_Job_Description  \\\n",
       "70  [master, degree, stem, field, including, limit...   \n",
       "71  [reporting, director, data, analytics, senior,...   \n",
       "72  [oracle, cloud, hcm, absence, consultant, resp...   \n",
       "73  [year, experience, peoplesoft, oracle, eb, imp...   \n",
       "74  [leveraging, latest, machine, deep, learning, ...   \n",
       "75  [collaborate, multidisciplinary, team, gain, i...   \n",
       "76  [work, fast-paced, environment, combine, techn...   \n",
       "77  [handling, incoming, request, assistance, busi...   \n",
       "78  [graduate, degree, information, technology, si...   \n",
       "79  [enter, existing, website, codebases, extend, ...   \n",
       "\n",
       "                                             Keywords  Cosine_Job_Desc  \\\n",
       "70  master’s, degree, or, above, in, a, stem, fiel...            0.088   \n",
       "71  projects, techniques, skills, organization’s, ...            0.103   \n",
       "72  requirements, experience, work, consulting, co...            0.108   \n",
       "73  *, project, management, &, experience, stakeho...            0.127   \n",
       "74  experience, projects, leveraging, latest, tech...            0.169   \n",
       "75  2+, knowledge, of, with, experience, collabora...            0.131   \n",
       "76  experience, with, work, fast-paced, combine, o...            0.345   \n",
       "77  security, of, handling, incoming, requests, fo...            0.349   \n",
       "78  experience, written, typescript), skills, and,...            0.128   \n",
       "79  5, (required), enter, existing, website, codeb...            0.094   \n",
       "\n",
       "    WMD_Job_Desc  \n",
       "70         0.491  \n",
       "71         0.490  \n",
       "72         0.490  \n",
       "73         0.493  \n",
       "74         0.500  \n",
       "75         0.494  \n",
       "76         0.507  \n",
       "77         0.504  \n",
       "78         0.486  \n",
       "79         0.489  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_Bradly_Johnston =  df_Jobs_and_Candidates['Candidate_Name']=='Security_Specialist_Denis Banik'\n",
    "new_DF = df_Jobs_and_Candidates[is_Bradly_Johnston]\n",
    "print(new_DF.shape)\n",
    "new_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Candidate_Name</th>\n",
       "      <th>Content_CV</th>\n",
       "      <th>clean_Content_CV</th>\n",
       "      <th>tokens_Content_CV</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Job_Description</th>\n",
       "      <th>clean_Job_Description</th>\n",
       "      <th>tokens_Job_Description</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Cosine_Job_Desc</th>\n",
       "      <th>WMD_Job_Desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Web_Dev_Karen_Higgins</td>\n",
       "      <td>\\nKaren Higgins \\n        We b Developer \\n \\n...</td>\n",
       "      <td>karen higgins b developer areas expertise pers...</td>\n",
       "      <td>['karen', 'higgins', 'b', 'developer', 'area',...</td>\n",
       "      <td>Machine Learning Engineer 2</td>\n",
       "      <td>collaborate with a multidisciplinary team to g...</td>\n",
       "      <td>collaborate multidisciplinary team gain insigh...</td>\n",
       "      <td>['collaborate', 'multidisciplinary', 'team', '...</td>\n",
       "      <td>2+, knowledge, of, with, experience, collabora...</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Web_Dev_Karen_Higgins</td>\n",
       "      <td>\\nKaren Higgins \\n        We b Developer \\n \\n...</td>\n",
       "      <td>karen higgins b developer areas expertise pers...</td>\n",
       "      <td>['karen', 'higgins', 'b', 'developer', 'area',...</td>\n",
       "      <td>Security Specialist</td>\n",
       "      <td>work in a fast-paced environment that combine ...</td>\n",
       "      <td>work fast-paced environment combine technical ...</td>\n",
       "      <td>['work', 'fast-paced', 'environment', 'combine...</td>\n",
       "      <td>experience, with, work, fast-paced, combine, o...</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Web_Dev_Karen_Higgins</td>\n",
       "      <td>\\nKaren Higgins \\n        We b Developer \\n \\n...</td>\n",
       "      <td>karen higgins b developer areas expertise pers...</td>\n",
       "      <td>['karen', 'higgins', 'b', 'developer', 'area',...</td>\n",
       "      <td>Security Specialist 2</td>\n",
       "      <td>\\n    handling incoming requests for assistanc...</td>\n",
       "      <td>handling incoming requests assistance business...</td>\n",
       "      <td>['handling', 'incoming', 'request', 'assistanc...</td>\n",
       "      <td>security, of, handling, incoming, requests, fo...</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Web_Dev_Karen_Higgins</td>\n",
       "      <td>\\nKaren Higgins \\n        We b Developer \\n \\n...</td>\n",
       "      <td>karen higgins b developer areas expertise pers...</td>\n",
       "      <td>['karen', 'higgins', 'b', 'developer', 'area',...</td>\n",
       "      <td>Web Developer Full Stack</td>\n",
       "      <td>\\n\\n    graduate degree in information technol...</td>\n",
       "      <td>graduate degree information technology similar...</td>\n",
       "      <td>['graduate', 'degree', 'information', 'technol...</td>\n",
       "      <td>experience, written, typescript), skills, and,...</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Web_Dev_Karen_Higgins</td>\n",
       "      <td>\\nKaren Higgins \\n        We b Developer \\n \\n...</td>\n",
       "      <td>karen higgins b developer areas expertise pers...</td>\n",
       "      <td>['karen', 'higgins', 'b', 'developer', 'area',...</td>\n",
       "      <td>Web Developer Full Stack 2</td>\n",
       "      <td>\\n· enter existing website codebases and exten...</td>\n",
       "      <td>enter existing website codebases extend functi...</td>\n",
       "      <td>['enter', 'existing', 'website', 'codebases', ...</td>\n",
       "      <td>5, (required), enter, existing, website, codeb...</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Candidate_Name                                         Content_CV  \\\n",
       "95  Web_Dev_Karen_Higgins  \\nKaren Higgins \\n        We b Developer \\n \\n...   \n",
       "96  Web_Dev_Karen_Higgins  \\nKaren Higgins \\n        We b Developer \\n \\n...   \n",
       "97  Web_Dev_Karen_Higgins  \\nKaren Higgins \\n        We b Developer \\n \\n...   \n",
       "98  Web_Dev_Karen_Higgins  \\nKaren Higgins \\n        We b Developer \\n \\n...   \n",
       "99  Web_Dev_Karen_Higgins  \\nKaren Higgins \\n        We b Developer \\n \\n...   \n",
       "\n",
       "                                     clean_Content_CV  \\\n",
       "95  karen higgins b developer areas expertise pers...   \n",
       "96  karen higgins b developer areas expertise pers...   \n",
       "97  karen higgins b developer areas expertise pers...   \n",
       "98  karen higgins b developer areas expertise pers...   \n",
       "99  karen higgins b developer areas expertise pers...   \n",
       "\n",
       "                                    tokens_Content_CV  \\\n",
       "95  ['karen', 'higgins', 'b', 'developer', 'area',...   \n",
       "96  ['karen', 'higgins', 'b', 'developer', 'area',...   \n",
       "97  ['karen', 'higgins', 'b', 'developer', 'area',...   \n",
       "98  ['karen', 'higgins', 'b', 'developer', 'area',...   \n",
       "99  ['karen', 'higgins', 'b', 'developer', 'area',...   \n",
       "\n",
       "                      Job_Title  \\\n",
       "95  Machine Learning Engineer 2   \n",
       "96          Security Specialist   \n",
       "97        Security Specialist 2   \n",
       "98     Web Developer Full Stack   \n",
       "99   Web Developer Full Stack 2   \n",
       "\n",
       "                                      Job_Description  \\\n",
       "95  collaborate with a multidisciplinary team to g...   \n",
       "96  work in a fast-paced environment that combine ...   \n",
       "97  \\n    handling incoming requests for assistanc...   \n",
       "98  \\n\\n    graduate degree in information technol...   \n",
       "99  \\n· enter existing website codebases and exten...   \n",
       "\n",
       "                                clean_Job_Description  \\\n",
       "95  collaborate multidisciplinary team gain insigh...   \n",
       "96  work fast-paced environment combine technical ...   \n",
       "97  handling incoming requests assistance business...   \n",
       "98  graduate degree information technology similar...   \n",
       "99  enter existing website codebases extend functi...   \n",
       "\n",
       "                               tokens_Job_Description  \\\n",
       "95  ['collaborate', 'multidisciplinary', 'team', '...   \n",
       "96  ['work', 'fast-paced', 'environment', 'combine...   \n",
       "97  ['handling', 'incoming', 'request', 'assistanc...   \n",
       "98  ['graduate', 'degree', 'information', 'technol...   \n",
       "99  ['enter', 'existing', 'website', 'codebases', ...   \n",
       "\n",
       "                                             Keywords  Cosine_Job_Desc  \\\n",
       "95  2+, knowledge, of, with, experience, collabora...            0.158   \n",
       "96  experience, with, work, fast-paced, combine, o...            0.154   \n",
       "97  security, of, handling, incoming, requests, fo...            0.115   \n",
       "98  experience, written, typescript), skills, and,...            0.188   \n",
       "99  5, (required), enter, existing, website, codeb...            0.204   \n",
       "\n",
       "    WMD_Job_Desc  \n",
       "95         0.496  \n",
       "96         0.501  \n",
       "97         0.486  \n",
       "98         0.490  \n",
       "99         0.507  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exportamos el csv:\n",
    "df_Jobs_and_Candidates.to_csv('DF_Exportado_Jobs_And_Candidates.csv',index = False)\n",
    "#Si lo queremos importar:\n",
    "DF_J_and_C = pd.read_csv('DF_Exportado_Jobs_And_Candidates.csv')\n",
    "DF_J_and_C.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.3.2-Entre el contenido de los CVs y las keywords de puestos obtenidas mediante Keyword extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#APlicamos las funciones get_cosine y WMD entre el contenido del CV y las keywords que obtuvimos previamente \n",
    "#del puesto y el resultado lo guardamos en  las columnas 'Cosine_Job_Keywords' y 'WMD_Job_Keywords'.\n",
    "df_Jobs_and_Candidates['Cosine_Job_Keywords'] = df_Jobs_and_Candidates.apply(lambda row: round(get_cosine(row['clean_Content_CV'],row['Keywords']),3), axis=1)\n",
    "#df_Jobs_and_Candidates['WMD_Job_Keywords'] = df_Jobs_and_Candidates.apply(lambda row: round(WMD(row['Content_CV'],row['Keywords']),3), axis=1)\n",
    "#APlicando lo de  --> similarity = 1 / (1 + distance):\n",
    "df_Jobs_and_Candidates['WMD_Job_Keywords'] = df_Jobs_and_Candidates.apply(lambda row: round((1/(1+(WMD(row['clean_Content_CV'],row['Keywords'])))),3), axis=1)\n",
    "\n",
    "df_Jobs_and_Candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.3.3-Entre el contenido de los CVs y keywords de puestos puestas \"a mano\" / personalizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "karen higgins b developer areas expertise personal summary ambitious problem solver passion online businesses search engine optimisation would like join team like-minded developers karen much experience creating logical innovative solutions complex problems identifying technical thorough precise everything keen interest solutions technology mobile applications user experience someone takes responsibility personal development continually evaluating client facing skills upgrading skills stays cutting edge web development natural problem solver proven successfully completing projects consultancies software houses web troubleshooting design agencies departments javascript right karen looking suitable position company outstanding performance recognised work variety web graphi cs high profile projects bug fixing career history web design company - birmingham building tem plates web developer jul - present image cropping responsible working range projects designing appealing websites interacting daily basis graphic designers back-end developers marketers maintaining data integrity developing maintaining front end functionality websites building functionality participating discussions clients clarify want designing prototypes apps websites web application developmen creating logos banners buttons websites writing cross-browser compliant xhtml css javascript simultaneously managing several databases reporting tools mobile app lications contacting external webmasters confirm link placements provide guidance team members web development issues developing websites consistent feel look throughout web properties providing technical support end users identifying correcting software deficiencies career statement devising seo strategies based around specific keywords feel greatest strengths firstly strong seo company - coventry commitment providing trainee web developer feb - jul professional service worked part multi-disciplinary team carrying ad-hoc tasks colleagues work requested manager specific brief ensure websites build secondly skill developing customer precisely matched requirements maintain ing close working relationship every wrote internal external design specifications company client something turn helps gain performed maintenance updates existing client web sites in-depth understanding involved creating comparison site scratch individu al needs thirdly helped end users solve operating problems real pass ion web participated brainstorming sessions come ideas development whole documented software technical specifications obsession allows provided guidance advice less experienced staff spot trends develop best worked multiple projects simultaneously high standard practise processes escalated operational issues senior management involved project develop large online gaming website karen higgins addressed cross-browser compatibility issues integrated websites facebook twitter youtube local school west midlands personal skills office junior aug feb creative thinker government office west bromwich imaginative office assistant jun aug energetic clothes store - dudley sales assistant oct may deadline led local charity - birmingham initiative volunteer jul oct attention detail key competencies skills innovative web development knowledge php xhtml css xml javascript jquery tactful articulate awareness web development industry new technologies social media monetisation strategies problem solving developing multi-user applications within soa service orientated architecture reliable writing technical manuals user instructions strategically thinking parts design process team player knowledge payment processing customs clearance multi-currency pricing project management knowledge international web standards protocols analytical professional able organise workload effectively prioritise tasks quickly understand business requirements translate functional requirements professi onal passion customer service responding quickly enquiries manage multiple projects fast-paced deadline-driven environment advanced f irst aid adaptable able quickly pick new techniques understanding w c standards web accessibility best practice french speaker personal german spe aker passionate good job first rate interpersonal communication skills able easily interact fellow developers customers alike comfortable go person company strongly committed projects inception right end confident friendly easy get along academic qualifications university birmingham - ba hons graphic design central college birmingham - persona l details diploma business studies karen higgins north birmingham school - dayjob ltd levels big pe g geography birmingham maths b nf english literature communication b history teh modern world b physics science combined e info dayjob com references available request copyright information - please read web developer resume template copyright dayjob ltd job seekers may download use particular resume example personal use help write one also welcome link page site www dayjob com however cv template must distributed made available websites without prior permission questions relating use template please email info dayjob com\n"
     ]
    }
   ],
   "source": [
    "Content_CV_Phoebe_Buffay = df_Jobs_and_Candidates.loc[17,'clean_Content_CV']\n",
    "print(Content_CV_Phoebe_Buffay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must have equal len keys and value when setting with an iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-2fe9bb7f16b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#al contenido del CV). Y luego aplicamos sim cosine y WDM para estos casos y vemos los resultados.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf_Jobs_and_Candidates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Test'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mContent_CV_Phoebe_Buffay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'data science, machine learning, pandas, python, sql'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#Es lo mismo poner las Keywords con o sin comas (da igual el resultado, ya que el procesamiento se encarga de esto).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf_Jobs_and_Candidates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Test'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mContent_CV_Phoebe_Buffay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'football, tennis, spanish'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0miloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iloc\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m         \u001b[0miloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtake_split_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1634\u001b[0m             \u001b[0;31m# We have to operate column-wise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1635\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer_split_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1636\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1637\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_single_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer_split_path\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1711\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1712\u001b[0m                     \u001b[0;34m\"Must have equal len keys and value \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1713\u001b[0m                     \u001b[0;34m\"when setting with an iterable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Must have equal len keys and value when setting with an iterable"
     ]
    }
   ],
   "source": [
    "#Agregamos 2 filas más al DF con las keywords personalizadas (las segundas keywords no tendrán nada que ver\n",
    "#al contenido del CV). Y luego aplicamos sim cosine y WDM para estos casos y vemos los resultados.\n",
    "\n",
    "df_Jobs_and_Candidates.loc[18] = ['Test',Content_CV_Phoebe_Buffay,'','','data science, machine learning, pandas, python, sql','','','',''] \n",
    "#Es lo mismo poner las Keywords con o sin comas (da igual el resultado, ya que el procesamiento se encarga de esto). \n",
    "df_Jobs_and_Candidates.loc[19] = ['Test',Content_CV_Phoebe_Buffay,'','','football, tennis, spanish','','','',''] \n",
    "\n",
    "df_Jobs_and_Candidates.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST: Usamos la funcion text_to_vector() para las keywords:\n",
    "vector_test_description = text_to_vector(df_Jobs_and_Candidates.iloc[18]['Keywords'])\n",
    "vector_test_description\n",
    "\n",
    "#Ahora si aplicamos sim cosine y WDM para estos casos y vemos los resultados. \n",
    "df_Jobs_and_Candidates.loc[18,'Cosine_Job_Keywords'] = round(get_cosine(df_Jobs_and_Candidates.loc[18,'Content_CV'],df_Jobs_and_Candidates.loc[18,'Keywords']),3)\n",
    "\n",
    "#df_Jobs_and_Candidates.loc[18,'WMD_Job_Keywords'] = round(WMD(df_Jobs_and_Candidates.loc[18,'Content_CV'],df_Jobs_and_Candidates.loc[18,'Keywords']),3)\n",
    "#APlicando lo de  --> similarity = 1 / (1 + distance):\n",
    "df_Jobs_and_Candidates.loc[18,'WMD_Job_Keywords'] = round((1/(1+(WMD(df_Jobs_and_Candidates.loc[18,'Content_CV'],df_Jobs_and_Candidates.loc[18,'Keywords'])))),3)\n",
    "\n",
    "df_Jobs_and_Candidates.loc[19,'Cosine_Job_Keywords'] = round(get_cosine(df_Jobs_and_Candidates.loc[19,'Content_CV'],df_Jobs_and_Candidates.loc[19,'Keywords']),3)\n",
    "\n",
    "#df_Jobs_and_Candidates.loc[19,'WMD_Job_Keywords'] = round(WMD(df_Jobs_and_Candidates.loc[19,'Content_CV'],df_Jobs_and_Candidates.loc[19,'Keywords']),3)\n",
    "#APlicando lo de  --> similarity = 1 / (1 + distance):\n",
    "df_Jobs_and_Candidates.loc[19,'WMD_Job_Keywords'] = round((1/(1+(WMD(df_Jobs_and_Candidates.loc[19,'Content_CV'],df_Jobs_and_Candidates.loc[19,'Keywords'])))),3)\n",
    "\n",
    "df_Jobs_and_Candidates.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5- Utilizando glove en lugar de word2vec para aplicar WDM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gensim version: 4.0.0\n"
     ]
    }
   ],
   "source": [
    "# Load Word Embedding Model\n",
    "import gensim\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "print('gensim version: %s' % gensim.__version__)\n",
    "#glove_model = gensim.models.KeyedVectors.load_word2vec_format('../model/text/stanford/glove/glove.6B.50d.vec')\n",
    "glove_model = KeyedVectors.load_word2vec_format('/home/fedricio/Desktop/Embeddings_Utilizados/Glove/glove.6B.50d.txt', binary=False, no_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'calonge federico matias oracle consultant page hcm technical consultant federico ha working oracle tools since october march participated erp cloud projects performing reporting tasks working modules ap ar gl since march participating hcm cloud projects performing reporting extractions integrations tasks working modules core nd recruitment ince october h e member artificial intelligence ai committee oracle strong interest data science machine learning last year computer engineering degree studying th year english personal ac ademic programming projects https github com federicocalonge skills summary oracle hcm cloud core recruitment oracle erp cloud accounts receivable ar accounts payable ap general ledger gl main experience points reporting sql bi publisher intermediate - advanced technical documentation extractions api rest hcm extract web services soap basic - intermediate integrations hdl basic - intermediate extra data analysis implementation machine learning algorithms python intermediate calonge federico matias - oracle consultant page professional e xperience oracle hcm mplementation dos pinos cr may - technical consultant reports core assembling technical documentation extractions web services soap hcm extract absences times extractions rest api integrations hdl oracle hcm mplementation usta col ap r - technical consultant reports core personal profile data recruitment selection candidates - feedbacks oracle hcm mplementation consorcio chi jan - technical consultant bank reconciliation reports oracle hcm mplementation sky airlines chi de c - technical consultant daily book purchase book r eports taking account taxes withholdings applied accomplishments education national university avellaneda undav - computer engineering orientation distributed systems - progress approved subjects thesis progress oriented machine learning applied human resources languages spanish native english intermediate - dvanced th year cambridge institute approved'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_text = df_Jobs_and_Candidates.loc[32,'clean_Content_CV']\n",
    "CV_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['bsc', 'msc', 'phd', 'physics', 'mathematics', 'biomedical', 'software', 'engineering', 'computer', 'science', 'years', 'experience', 'developing', 'image', 'processing', 'machine', 'learning', 'products', 'pipelines', 'advantage', 'familiarity', 'web', 'development', 'e', 'g', 'flask', 'serverless', 'deployment', 'e', 'g', 'docker', 'cloud', 'services', 'e', 'g', 'aws', 'entrepreneurial', 'experience', 'passion', 'working', 'small', 'teams', 'peerreviewed', 'academic', 'publications'], ['chandler', 'bing', 'chandler', 'bing', 'vit', 'ac', 'education', 'l', 'date', 'birth', 'may', 'languages', 'known', 'hindi', 'english', 'spanish', 'coursework', 'machine', 'learning', 'data', 'visualization', 'perating', 'systems', 'database', 'management', 'system', 'discrete', 'maths', 'skills', 'c', 'java', 'python', 'arduino', 'android', 'html', 'php', 'javascript', 'mysql', 'r', 'studio', 'keras', 'nltk', 'parser', 'sql', 'experience', 'android', 'club', 'coordinator', 'front', 'end', 'developer', 'technovit', 'website', 'team', 'key', 'entertainer', 'friends', 'projects', 'good', 'females', 'android', 'application', 'w', 'omen', 'health', 'safety', 'emergency', 'mode', 'using', 'android', 'modules', 'safest', 'route', 'using', 'image', 'processing', 'disease', 'prediction', 'using', 'svm', 'linear', 'regression', 'face', 'detection', 'recognition', 'using', 'openmp', 'opencv', 'openmp', 'cuda', 'smart', 'farming', 'arduino', 'coding', 'sensors', 'thingspeak', 'nlp', 'resume', 'parsing', 'made', 'resume', 'parser', 'based', 'n', 'nltk', 'spacy', 'nlp', 'tools', 'co', 'curricular', 'activities', 'reading', 'novels', 'painting'], ['meghna', 'lohani', 'campus', 'address', 'meghna', 'lohani', 'vitstudent', 'ac', 'permanent', 'address', 'l', 'ha', 'vit', 'chennai', 'cell', 'f', 'shangri', 'la', 'chennai', 'apartments', 'tamil', 'nadu', 'vadodara', 'objective', 'ap', 'ply', 'technical', 'skills', 'growth', 'co', 'mpany', 'education', 'vellore', 'institute', 'technology', 'chennai', 'n', 'bachelor', 'computing', 'science', 'engineering', 'c', 'gpa', 'till', 'v', 'semester', 'awarded', 'may', 'st', 'p', 'trick', 'junior', 'college', 'agra', 'hsc', 'class', 'xii', 'icse', 'percentage', 'awa', 'rded', 'may', 'st', 'patrick', 'junior', 'college', 'agra', 'ssc', 'class', 'x', 'icse', 'per', 'centage', 'awarded', 'may', 'date', 'birth', 'may', 'languages', 'hindi', 'english', 'known', 'coursework', 'object', 'oriented', 'progr', 'amming', 'digital', 'logic', 'design', 'database', 'man', 'agement', 'systems', 'software', 'engineering', 'data', 'structures', 'algorithms', 'computer', 'architecture', 'discrete', 'mathematics', 'chine', 'learning', 'statistics', 'engineer', 'computer', 'languages', 'python', 'c', 'c', 'r', 'beginner', 'java', 'skills', 'skills', 'html', 'php', 'javascript', 'sql', 'data', 'structures', 'data', 'science', 'chine', 'learning', 'ndroid', 'experience', 'developer', 'vit', 'technovit', 'website', 'team', 'two', 'hac', 'kathons', 'co', 'ordi', 'nator', 'android', 'club', 'activities', 'drawing', 'painting', 'p', 'laying', 'chess', 'projects', 'campus', 'commune', 'jav', 'netbeans', 'ide', 'mysql', 'jdbc', 'application', 'provides', 'platform', 'students', 'various', 'colleges', 'interact', 'share', 'knowledge', 'projects', 'courses', 'good', 'female', 'gff', 'android', 'studio', 'php', 'machine', 'learni', 'ng', 'android', 'application', 'caters', 'women', 'health', 'safety', 'winner', 'best', 'problem', 'addressed', 'award', 'social', 'welfare', 'smart', 'farming', 'sensors', 'actuators', 'arduino', 'thingspeak', 'mit', 'apps', 'smart', 'farming', 'application', 'allows', 'remote', 'automation', 'onitoring', 'farming', 'activities', 'data', 'sensed', 'pushed', 'cloud', 'thingspeak', 'controlled', 'using', 'app', 'face', 'detection', 'identification', 'c', 'openmp', 'opencv', 'c', 'application', 'detects', 'recognizes', 'faces', 'input', 'image', 'input', 'video', 'liv', 'e', 'streaming', 'video', 'voice', 'automated', 'cl', 'oud', 'face', 'authentication', 'docker', 'speech', 'recognition', 'opencv', 'created', 'cloud', 'authorizes', 'user', 'using', 'face', 'detection', 'provides', 'various', 'services', 'saas', 'paas', 'iaas', 'using', 'voice', 'commands'], ['calonge', 'federico', 'matias', 'oracle', 'consultant', 'page', 'hcm', 'technical', 'consultant', 'federico', 'ha', 'working', 'oracle', 'tools', 'since', 'october', 'march', 'participated', 'erp', 'cloud', 'projects', 'performing', 'reporting', 'tasks', 'working', 'modules', 'ap', 'ar', 'gl', 'since', 'march', 'participating', 'hcm', 'cloud', 'projects', 'performing', 'reporting', 'extractions', 'integrations', 'tasks', 'working', 'modules', 'core', 'nd', 'recruitment', 'ince', 'october', 'h', 'e', 'member', 'artificial', 'intelligence', 'ai', 'committee', 'oracle', 'strong', 'interest', 'data', 'science', 'machine', 'learning', 'last', 'year', 'computer', 'engineering', 'degree', 'studying', 'th', 'year', 'english', 'personal', 'ac', 'ademic', 'programming', 'projects', 'https', 'github', 'com', 'federicocalonge', 'skills', 'summary', 'oracle', 'hcm', 'cloud', 'core', 'recruitment', 'oracle', 'erp', 'cloud', 'accounts', 'receivable', 'ar', 'accounts', 'payable', 'ap', 'general', 'ledger', 'gl', 'main', 'experience', 'points', 'reporting', 'sql', 'bi', 'publisher', 'intermediate', 'advanced', 'technical', 'documentation', 'extractions', 'api', 'rest', 'hcm', 'extract', 'web', 'services', 'soap', 'basic', 'intermediate', 'integrations', 'hdl', 'basic', 'intermediate', 'extra', 'data', 'analysis', 'implementation', 'machine', 'learning', 'algorithms', 'python', 'intermediate', 'calonge', 'federico', 'matias', 'oracle', 'consultant', 'page', 'professional', 'e', 'xperience', 'oracle', 'hcm', 'mplementation', 'dos', 'pinos', 'cr', 'may', 'technical', 'consultant', 'reports', 'core', 'assembling', 'technical', 'documentation', 'extractions', 'web', 'services', 'soap', 'hcm', 'extract', 'absences', 'times', 'extractions', 'rest', 'api', 'integrations', 'hdl', 'oracle', 'hcm', 'mplementation', 'usta', 'col', 'ap', 'r', 'technical', 'consultant', 'reports', 'core', 'personal', 'profile', 'data', 'recruitment', 'selection', 'candidates', 'feedbacks', 'oracle', 'hcm', 'mplementation', 'consorcio', 'chi', 'jan', 'technical', 'consultant', 'bank', 'reconciliation', 'reports', 'oracle', 'hcm', 'mplementation', 'sky', 'airlines', 'chi', 'de', 'c', 'technical', 'consultant', 'daily', 'book', 'purchase', 'book', 'r', 'eports', 'taking', 'account', 'taxes', 'withholdings', 'applied', 'accomplishments', 'education', 'national', 'university', 'avellaneda', 'undav', 'computer', 'engineering', 'orientation', 'distributed', 'systems', 'progress', 'approved', 'subjects', 'thesis', 'progress', 'oriented', 'machine', 'learning', 'applied', 'human', 'resources', 'languages', 'spanish', 'native', 'english', 'intermediate', 'dvanced', 'th', 'year', 'cambridge', 'institute', 'approved'], ['football', 'tennis', 'spanish']]\n"
     ]
    }
   ],
   "source": [
    "CV_text = df_Jobs_and_Candidates.loc[0,'clean_Content_CV']\n",
    "CV_text_2 = df_Jobs_and_Candidates.loc[11,'clean_Content_CV']\n",
    "CV_text_3 = df_Jobs_and_Candidates.loc[32,'clean_Content_CV']\n",
    "Job_Keyw_text = \"bsc msc phd physics mathematics biomedical software engineering computer science years experience developing image processing machine learning products pipelines advantage familiarity web development e g flask serverless deployment e g docker cloud services e g aws entrepreneurial experience passion working small teams peer-reviewed academic publications\"\n",
    "Job_Keyw_text_2 = \"football tennis spanish\"\n",
    "texts_to_compare = [Job_Keyw_text,CV_text,CV_text_2,CV_text_3,Job_Keyw_text_2]\n",
    "texts_tokens = tokenize(texts_to_compare)   #Función definida en las secciones anteriores. \n",
    "print(texts_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chandler',\n",
       " 'bing',\n",
       " 'chandler',\n",
       " 'bing',\n",
       " 'vit',\n",
       " 'ac',\n",
       " 'education',\n",
       " 'l',\n",
       " 'date',\n",
       " 'birth',\n",
       " 'may',\n",
       " 'languages',\n",
       " 'known',\n",
       " 'hindi',\n",
       " 'english',\n",
       " 'spanish',\n",
       " 'coursework',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'data',\n",
       " 'visualization',\n",
       " 'perating',\n",
       " 'systems',\n",
       " 'database',\n",
       " 'management',\n",
       " 'system',\n",
       " 'discrete',\n",
       " 'maths',\n",
       " 'skills',\n",
       " 'c',\n",
       " 'java',\n",
       " 'python',\n",
       " 'arduino',\n",
       " 'android',\n",
       " 'html',\n",
       " 'php',\n",
       " 'javascript',\n",
       " 'mysql',\n",
       " 'r',\n",
       " 'studio',\n",
       " 'keras',\n",
       " 'nltk',\n",
       " 'parser',\n",
       " 'sql',\n",
       " 'experience',\n",
       " 'android',\n",
       " 'club',\n",
       " 'coordinator',\n",
       " 'front',\n",
       " 'end',\n",
       " 'developer',\n",
       " 'technovit',\n",
       " 'website',\n",
       " 'team',\n",
       " 'key',\n",
       " 'entertainer',\n",
       " 'friends',\n",
       " 'projects',\n",
       " 'good',\n",
       " 'females',\n",
       " 'android',\n",
       " 'application',\n",
       " 'w',\n",
       " 'omen',\n",
       " 'health',\n",
       " 'safety',\n",
       " 'emergency',\n",
       " 'mode',\n",
       " 'using',\n",
       " 'android',\n",
       " 'modules',\n",
       " 'safest',\n",
       " 'route',\n",
       " 'using',\n",
       " 'image',\n",
       " 'processing',\n",
       " 'disease',\n",
       " 'prediction',\n",
       " 'using',\n",
       " 'svm',\n",
       " 'linear',\n",
       " 'regression',\n",
       " 'face',\n",
       " 'detection',\n",
       " 'recognition',\n",
       " 'using',\n",
       " 'openmp',\n",
       " 'opencv',\n",
       " 'openmp',\n",
       " 'cuda',\n",
       " 'smart',\n",
       " 'farming',\n",
       " 'arduino',\n",
       " 'coding',\n",
       " 'sensors',\n",
       " 'thingspeak',\n",
       " 'nlp',\n",
       " 'resume',\n",
       " 'parsing',\n",
       " 'made',\n",
       " 'resume',\n",
       " 'parser',\n",
       " 'based',\n",
       " 'n',\n",
       " 'nltk',\n",
       " 'spacy',\n",
       " 'nlp',\n",
       " 'tools',\n",
       " 'co',\n",
       " 'curricular',\n",
       " 'activities',\n",
       " 'reading',\n",
       " 'novels',\n",
       " 'painting']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_tokens[1]   #CV_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance with CV_1= 0.8981\n",
      "Distance with CV_2= 0.8440\n",
      "Distance with CV_3= 0.8419\n",
      "Distance keywords_2 with CV_1= 1.2049\n",
      "########################################\n",
      "Similarity with CV_1= 0.5270\n",
      "Similarity with CV_2= 0.5420\n",
      "Similarity with CV_3= 0.5430\n",
      "Similarity keywords_2 with CV_1= 0.4540\n"
     ]
    }
   ],
   "source": [
    "#Imprimimos las distancias entre Job_Keyw_text y los 3 CVs:\n",
    "\n",
    "tokens_job_keyw = texts_tokens[0]\n",
    "tokens_CV_1 = texts_tokens[1]\n",
    "tokens_CV_2 = texts_tokens[2]\n",
    "tokens_CV_3 = texts_tokens[3]\n",
    "tokens_job_keyw_2 = texts_tokens[4]\n",
    "\n",
    "distance_1 = glove_model.wmdistance(tokens_job_keyw, tokens_CV_1)\n",
    "print('Distance with CV_1= %.4f' % distance_1)\n",
    "\n",
    "distance_2 = glove_model.wmdistance(tokens_job_keyw, tokens_CV_2)\n",
    "print('Distance with CV_2= %.4f' % distance_2)\n",
    "\n",
    "distance_3 = glove_model.wmdistance(tokens_job_keyw, tokens_CV_3)\n",
    "print('Distance with CV_3= %.4f' % distance_3)\n",
    "\n",
    "#Esta última comparación no debe dar buen score, ya que las keywords no tienen nada que ver con el CV:\n",
    "distance_4 = glove_model.wmdistance(tokens_job_keyw_2, tokens_CV_1)\n",
    "print('Distance keywords_2 with CV_1= %.4f' % distance_4)\n",
    "\n",
    "print('#'*40)\n",
    "############################################################\n",
    "#Ahora aplicamos lo de --> similarity = 1 / (1 + distance):\n",
    "\n",
    "sim_1 = round((1 / (1 + distance_1)),3)\n",
    "print('Similarity with CV_1= %.4f' % sim_1)\n",
    "\n",
    "sim_2 = round((1 / (1 + distance_2)),3)\n",
    "print('Similarity with CV_2= %.4f' % sim_2)\n",
    "\n",
    "sim_3 = round((1 / (1 + distance_3)),3)\n",
    "print('Similarity with CV_3= %.4f' % sim_3)\n",
    "\n",
    "#Esta última comparación no debe dar buen score, ya que las keywords no tienen nada que ver con el CV:\n",
    "sim_4 = round((1 / (1 + distance_4)),3)\n",
    "print('Similarity keywords_2 with CV_1= %.4f' % sim_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6- Utilizando spacy en lugar de word2vec o glove para aplicar WDM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejemplo de la doc oficial modificado: doc oficial: https://spacy.io/universe/project/wmd-relax\n",
    "#Para esto descargue spacy: >conda install -c conda-forge spacy\n",
    "#Y el modelo: python -m spacy download en_core_web_lg\n",
    "import spacy\n",
    "import wmd\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg', create_pipeline=wmd.WMD.create_spacy_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8705018149808114\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#Ejemplo:\n",
    "doc1 = nlp(\"Politician speaks to the media in Illinois.\")\n",
    "doc2 = nlp(\"The president greets the press in Chicago.\")\n",
    "doc3 = nlp(\"The president greets the press in Chicago.\")\n",
    "print(doc1.similarity(doc2))\n",
    "print(doc2.similarity(doc3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7440745766755973\n"
     ]
    }
   ],
   "source": [
    "#Nuestro caso:\n",
    "\n",
    "#Preprocesamos el doc_1 a comparar (el doc_2 no hace falta porque son keywords):\n",
    "doc_1 = df_Jobs_and_Candidates.loc[19,'clean_Content_CV']\n",
    "doc_1_tokenize = tokenize([doc_1])              #Usando la funcion definida en las secciones previas.\n",
    "new_text_doc_1 = ' '.join(doc_1_tokenize[0])    #Pasamos la lista a string.\n",
    "new_text_doc_1                                  #Nuevo texto sin espacios, stop words y demas (ver todo lo que hace 'tokenize')\n",
    "\n",
    "doc1 = nlp(new_text_doc_1)\n",
    "doc2 = nlp('data science, machine learning, pandas, python, sql')\n",
    "print(doc1.similarity(doc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45084626580079523\n"
     ]
    }
   ],
   "source": [
    "#Hacemos lo mismo que arriba solo que ahora nuestras keywords serán otras que no tendrán que ver con el CV:\n",
    "\n",
    "doc_1 = df_Jobs_and_Candidates.loc[19,'clean_Content_CV']\n",
    "doc_1_tokenize = tokenize([doc_1])              \n",
    "new_text_doc_1 = ' '.join(doc_1_tokenize[0])    \n",
    "new_text_doc_1                                 \n",
    "\n",
    "doc1 = nlp(new_text_doc_1)\n",
    "doc2 = nlp('football tennis spanish')  #CAMBIAMOS ESTO.\n",
    "print(doc1.similarity(doc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
