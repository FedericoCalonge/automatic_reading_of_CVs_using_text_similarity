{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DS sacado de: https://www.kaggle.com/uciml/zoo-animal-classification\n",
    "\n",
    "##### Es el mismo DS que utilizamos para KNN_Ejemplo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "#LIbrerias de visualizacion:\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 18)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Carga de DS con los animales\n",
    "DF_Animals = pd.read_csv(\"DataSourceTL3/zoo.csv\") #Armamos un Data Frame con nuestros datos de entrada.\n",
    "#URL para descargar el CSV: https://www.aprendemachinelearning.com/articulos_ml/\n",
    "DF_Animals.shape #Vemos sus dimensiones (tiene 161 Filas/registros x 8 columnas/features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cargamos el DS con las clases (nombres):\n",
    "DF_Clases = pd.read_csv(\"DataSourceTL3/class.csv\")\n",
    "DF_Clases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a considerar TODAS las variables numéricas en nuestro DS para predecir la variable \"class_type\".\n",
    "#Por esto sacamos del DF a la variable animal_name que no nos interesa y tambien nuestra variable target (class_type):\n",
    "\n",
    "x_data = DF_Animals.drop([\"animal_name\",\"class_type\"],axis=1)\n",
    "\n",
    "#Y acá colocamos nuestra variable class_type que queremos predecir:\n",
    "y = DF_Animals[\"class_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión de Naive Bayes: 0.9047619047619048\n"
     ]
    }
   ],
   "source": [
    "#Entrenamiento... separamos 20% test y 80% para entrenamiento:\n",
    "X_train,X_test,y_train,y_test = train_test_split(x_data,y,test_size=0.2,random_state=4)\n",
    "nb = GaussianNB() #Definimos el algortimo de Naive Bayes.\n",
    "nb.fit(X_train,y_train) #Entrenamos el algoritmo con los  x_train e Y_train que elegimos previamente.\n",
    "y_pred=nb.predict(X_test) #Y ahora hacemos una predicción con los X_Test.\n",
    "\n",
    "#El modelo que nosotros creamos y entrenamos GaussianNB() implementa esta fórmula para obtener las \n",
    "#probabilidades para el valor que le damos y cada clase (calcula la probabilidad  de que una nueva muestra de datos D -animal- pertenezca a una clase en particular C):\n",
    "#P (C | D) = ( P (D | C) x P ( C) ) / P (D)\n",
    "\n",
    "#Asi calculamos P (C | D) para cada clase posible, ignorando el término P (D) por su característica de \"Naive Bayes\".\n",
    "\n",
    "#Y cuando hacemos la predicción SOLO nos devuelve la clase que obtuvo la mayor de estas probabilidades.\n",
    "\n",
    "#Naive Bayes utiliza datos anteriores para actualizar el modelo; nos permite que el modelo sea flexible y actualice nuevos datos e incorpore una creencia previa.\n",
    "#De esta manera no tenemos que calcular las probabilidades nuevaente.\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Precisión de Naive Bayes:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mammal\n",
      "Bird\n",
      "Mammal\n"
     ]
    }
   ],
   "source": [
    "#La Accuracy del modelo es el número total de predicciones correctas dividido por el número total de predicciones. \n",
    " ##--> Accuracy = predicciones correctas / número total de predicciones \n",
    "    \n",
    "dicClasses = {1:'Mammal',2:'Bird',3:'Reptile',4:'Fish',5:'Amphibian',6:'Bug',7:'Invertebrate'}\n",
    "\n",
    "x_new = [   [1,0,0,1,0,0,1,1,1,1,0,0,4,0,0,1],   #Oso.\n",
    "            [0,1,1,0,1,0,0,0,1,1,0,0,2,1,1,0],   #Pollo.\n",
    "            [0,1,1,0,0,0,1,1,1,1,0,0,4,0,1,1],   #Animal random.\n",
    "        ]\n",
    "\n",
    "y_predict = nb.predict(x_new)\n",
    "\n",
    "print(dicClasses[y_predict[0]]) \n",
    "print(dicClasses[y_predict[1]]) \n",
    "print(dicClasses[y_predict[2]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos que con Bayes clasificó bien los 2 primeros y clasificó que el último es \"Mammal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      1.00      1.00         7\n",
      "          2       1.00      1.00      1.00         5\n",
      "          4       1.00      1.00      1.00         1\n",
      "          5       1.00      1.00      1.00         1\n",
      "          6       1.00      0.33      0.50         3\n",
      "          7       0.67      1.00      0.80         4\n",
      "\n",
      "avg / total       0.94      0.90      0.89        21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Creamos un \"Reporte de clasificación\" y luego una \"Matriz de confusion\" que nos dará\n",
    "#una clara idea de la eficacia y el entrenamiento de nuestro modelo de Bayes:\n",
    "\n",
    "expected = y_test #Nuestros 21 valores reales (Son 21 ya que eran el 20% del y total cuando hicimos el split en train y test)\n",
    "predicted = y_pred #Nuestros 21 valores predichos.\n",
    "\n",
    "print(metrics.classification_report(expected, predicted)) #Analizamos las metricas para ver la eficacia del algoritmo en CADA CLASE.\n",
    "\n",
    "#Abajo muestra solo 6 filas y no 7 ya que de la clase 3 (reptile) no tenemos ninguna en nuestro set de entrenamiento.\n",
    "#support es la cantidad de clases en y_test (las reales)... teniamos 7 de clase 1, 5 de clase 2, etc.\n",
    "\n",
    "#2 animales que eran de categoría 6 los clasificó como 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7 0 0 0 0 0]\n",
      " [0 5 0 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 0 0 1 2]\n",
      " [0 0 0 0 0 4]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(expected, predicted))\n",
    "#Abajo muestra solo 6 filas y no 7 ya que de la clase 3 (reptile) no tenemos ninguna en nuestro set de entrenamiento.\n",
    "#Vemos que el 2 que está en la fila 5 es porque clasificó mal (osea que uno que era de clase 6 lo clasificó como clase 6)\n",
    "\n",
    "#En la diagonal de la matriz tenemos los casos que clasificó CORRECTAMENTE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1-La Precisión de una clase define cuan confiable es un modelo en responder si un punto pertenece a esa clase. \n",
    "\n",
    "#2-El Recall (o tambien llamado \"tasa de verdaderos positivos\" o SENSIBILIDAD) de una clase expresa cuan bien puede el\n",
    "#modelo detectar a esa clase.\n",
    "\n",
    "#3-El F1 Score de una clase es dada por la media harmonía de precisión y recall \n",
    "    #(2 x precision x recall / (precision+recall)) digamos que combina precisión y recall en una sola métrica. \n",
    "\n",
    "#Vemos que los valores de precisión, recall, y f1-score dieron valores cercanos a 1, \n",
    "#de esta manera podemos confiar en las predicciones de nuestro modelo.\n",
    "\n",
    "#Tenemos cuatro casos posibles para cada clase:\n",
    "#Alta precision y alto recall: el modelo maneja perfectamente esa clase --> para las clases 1,2,4,5.\n",
    "#Alta precision y bajo recall: el modelo no detecta la clase muy bien, pero cuando lo hace es altamente confiable. --> clase 6.\n",
    "#Baja precisión y alto recall: La clase detecta bien la clase pero también incluye muestras de otras clases. --> clase 7.\n",
    "#Baja precisión y bajo recall: El modelo no logra clasificar la clase correctamente.--> ninguna.\n",
    "    \n",
    "#Como mejora podríamos analizar esto de matriz de confusión y classification_report\n",
    "#para el ejemplo anterior con el modelo de KNN.\n",
    "#Como conclusión confiamos en que clasificó correctamente (Ya que tiene un score de 0.9)\n",
    "\n",
    "#MEJORA: Explicar bien los cálculos de Precisión y Recall y agregar el cálculo de Especificidad (explicando los VP, VN, FN, FP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
